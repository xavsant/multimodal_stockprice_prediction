[
    {
        "url": "https://www.nytimes.com/2024/12/13/technology/trump-tim-cook-mar-a-lago.html",
        "title": "Tim Cook Dines With Trump at Mar-a-Lago",
        "fulltext": "Tim Cook held a meeting on Friday with Donald J. Trump at Mar-a-Lago, marking the first time that Apple\u2019s chief executive has met with the president-elect since voters elected him to a second term last month.\nMr. Cook and Mr. Trump later dined on the patio at Mar-a-Lago, according to two people with knowledge of the meeting. The two men had a warm relationship during Mr. Trump\u2019s first term \u2014 much warmer than Mr. Trump\u2019s with other tech executives, like Meta\u2019s Mark Zuckerberg or Google\u2019s Sundar Pichai, both of whom recently had their own meals with Mr. Trump.\nAn Apple spokesman declined to comment. A spokesman for Mr. Trump did not immediately respond to a request for comment.\nThe meeting offers a chance for Mr. Cook to seek Mr. Trump\u2019s support on several issues that could challenge Apple\u2019s business in the coming years, including pressure on the App Store from European regulators and the potential that new tariffs could put the company\u2019s iPhone business at risk.\nMr. Trump has been receptive to those appeals in the past. Duringa podcast interview in October,Mr. Trump said he listened sympathetically as Mr. Cook complained to him on a call last month about European regulators who havefined Apple $2 billionfor using the App Store to thwart competition.\n\u201cI\u2019m not going to let them take advantage of our companies,\u201d Mr. Trump recalled telling Mr. Cook. \u201cThat won\u2019t be happening.\u201d\nMr. Cook has become something of a model for corporate executives looking to stay on good terms with Mr. Trump. During Mr. Trump\u2019s first term, the president heaped praise on Mr. Cook, saying that he liked that Mr. Cook called him directlyto discuss business and economic issues. The approach helped Mr. Cook build a personal relationship with Mr. Trump and helpedApple avoid tariffson many of its products, even as the Trump administration cracked down on other companies manufacturing in China.\nIn contrast, other tech giants have spent the last month working to repair damage in their relationships with Mr. Trump. In addition to Mr. Zuckerberg and Mr. Pichai, Amazon founder Jeff Bezos is scheduled to meet with Mr. Trump next week.MetaandAmazonalso said that they would donate $1 million to Mr. Trump\u2019s inaugural fund.\nIn 2017, Mr. Cook started to build a relationship with the Trump administration by getting to know Mr. Trump\u2019s daughter, Ivanka, and her husband, Jared Kushner. He would often call them to talk about policy matters and the potential ramifications of issues like tariffs on Apple.\nSince neither Ms. Trump nor Mr. Kushner are expected to be involved in the upcoming administration, Mr. Cook may have to forge new allies in this next White House, especially on issues critical to Apple\u2019s business, like manufacturing and trade.\nMr. Cook was among the many chief executives in technology who sought to flatter Mr. Trump after his election. He posted congratulations on X andsaid, \u201cWe look forward to engaging with you and your administration to help make sure the United States continues to lead with and be fueled by ingenuity, innovation, and creativity.\u201d"
    },
    {
        "url": "https://www.nytimes.com/2024/12/08/technology/apple-child-sexual-abuse-material-lawsuit.html",
        "title": "Apple Sued for Failing to Curtail Child Sexual Abuse Material on iCloud",
        "fulltext": "The abuse began when she was still an infant. A relative molested her, took photographs and swapped the images with others online. He allowed another man to spend time with her, multiplying the abuse.\nNearly every day, the woman, now 27 and living in the Northeast, is reminded of that abuse with a law enforcement notice that someone has been charged with possessing those images. One of those notifications, which she received in late 2021, said the images had been found on a man\u2019s MacBook in Vermont. Her lawyer later confirmed with law enforcement that the images had also been stored in Apple\u2019s iCloud.\nThe notice arrived months after Apple had unveiled a tool that allowed it to scan for illegal images of sexual abuse. But it quickly abandoned that tool after facing criticism from cybersecurity experts, who said it could pave the way to other government surveillance requests.\nNow, the woman, using a pseudonym, is suing Apple because she says it broke its promise to protect victims like her. Instead of using the tools that it had created to identify, remove and report images of her abuse, the lawsuit says, Apple allowed that material to proliferate, forcing victims of child sexual abuse to relive the trauma that has shaped their lives.\nThe lawsuit was filed late Saturday in U.S. District Court in Northern California. It says Apple\u2019s failures mean it has been selling defective products that harmed a class of customers, namely child sexual abuse victims, because it briefly introduced \u201ca widely touted improved design aimed at protecting children\u201d but \u201cthen failed to implement those designs or take any measures to detect and limit\u201d child sexual abuse material.\nThe suit seeks to change Apple\u2019s practices and compensate a potential group of 2,680 victims who are eligible to be part of the case, said James Marsh, one of the attorneys involved. Under law, victims of child sexual abuse are entitled to a minimum of $150,000 in damages, which means the total award, with the typical tripling of damages being sought, could exceed $1.2 billion should a jury find Apple liable.\nThe lawsuit is the second of its kind against Apple, but its scope and potential financial impact could force the company into a yearslong litigation process over an issue it has sought to put behind it. And it points to increasing concern that the privacy of Apple\u2019s iCloud allows illegal material to be circulated without being as easily spotted as it would be on social media services like Facebook.\nFor years, Apple has reported less abusive material than its peers, capturing and reporting a small fraction of what is caught by Google and Facebook. It has defended its practice by saying it is protecting user privacy, but child safety groups have criticized it for not doing more to stop the spread of that material.\nThe case is the latest example of an emerging legal strategy against tech companies. For decades,Section 230 of the Communications Decency Acthas shielded companies from legal liability for what users post on their platforms. But recent rulings by the U.S. Court of Appeals for the Ninth Circuit have determined thatthose shields can be appliedonly to content moderation anddon\u2019t provide blanketliability protection.\nThe rulings have raised hope among plaintiffs\u2019 attorneys that tech companies could be challenged in court. In August, a 9-year-old girl sued the company in North Carolina after strangers sent her child sexual abuse videos through iCloud links and encouraged her to film and upload her own nude videos.\nApple filed a motion to dismiss the North Carolina case, saying Section 230 protects it from liability for material posted on iCloud by someone else. It also argued that iCloud couldn\u2019t be subject to a product liability claim because it wasn\u2019t a product, like a defective tire.\nIn a statement in response to the new suit, Fred Sainz, an Apple spokesman, said: \u201cChild sexual abuse material is abhorrent and we are committed to fighting the ways predators put children at risk. We are urgently and actively innovating to combat these crimes without compromising the security and privacy of all our users.\u201d\nMr. Sainz pointed to safety tools the company has introduced to curtail the spread of newly created illegal images, including features in its Messages app that warn children of nude content and allow people to report harmful material to Apple.\nRiana Pfefferkorn, a lawyer and policy fellow at the Stanford Institute for Human-Centered Artificial Intelligence, said there are significant hurdles to any lawsuit over Apple\u2019s policies on child sexual abuse material. She added that a victory for the plaintiffs could backfire because it could raise questions about whether the government is forcing Apple to scan for illegal material in violation of the Fourth Amendment.\nThe New York Times granted anonymity to the 27-year-old woman suing Apple so she could tell her story. She spoke anonymously because people have been known to seek out victims and search for their child sexual abuse material on the internet.\nHer abuse started not long after she was born. An adult male family member would engage in sexual acts with her and photograph them. He was arrested after logging into a chat room and offering to swap photos of the girl with other men. He was found guilty of several felonies and sent to prison.\nWhat she could remember of the abuse came to her in bits and pieces. One night as her mother watched an episode of \u201cLaw & Order: Special Victims Unit\u201d about child sexual abuse, the story seemed eerily familiar. She screamed and startled her mother, who realized that she thought that the episode was about her.\n\u201cIt\u2019s not just you,\u201d her mother told her. \u201cThere are thousands of other kids.\u201d\nAs her images were found online, the authorities would notify her mother. They have commonly received a dozen or so notifications daily for more than a decade. What bothered her the most was knowing that pedophiles shared some of her photos with children to normalize abuse, a process called grooming.\n\u201cIt was hard to believe there were so many out there,\u201d she said. \u201cThey were not stopping.\u201d\nThe internet turbocharged the spread of child sexual abuse material. Physical images that had once been hard to find and share became digital photos and videos that could be stored on computers and servers and shared easily.\nIn 2009,Microsoft worked with Hany Farid, now a professor at the University of California, Berkeley, to create a software system to recognize photos, even altered ones, and compare them against a database of known illegal images. The system, called PhotoDNA, was adopted by a number of tech companies, including Google and Facebook.\nApple declined to use PhotoDNA or do widespread scanning like its peers. The tech industryreported 36 million reportsof photos and videos to the National Center for Missing & Exploited Children, the federal clearinghouse for suspected sexual abuse material. Google and Facebook each filed more than one million reports, but Apple made just 267.\nIn 2019,an investigation by The Timesrevealed that tech companies had failed to rein in abusive material.A bar graph the paper publisheddetailing public companies\u2019 reporting practices led Eric Friedman, an Apple executive responsible for fraud protection, to message a senior colleague and say he thoughtthe company may be underreporting child sexual abuse material.\n\u201cWe are the greatest platform for distributing child porn,\u201d said Mr. Friedman in the 2020 exchange. He said that was because Apple gave priority to privacy over trust and safety.\nA year later, Apple unveiled a system to scan for child sexual abuse. It said its iPhones would store a database of distinct digital signatures, which are known as hashes, that are associated with known child sexual abuse material identified by groups like the National Center for Missing & Exploited Children. It said it would compare those digital signatures against photos in a user\u2019s iCloud storage service. The technique, which it calledNeuralHash, would flag matches and forward them to the federal clearinghouse of suspected sexual abuse material.\nBut after cybersecurity experts warned that it would create a back door to iPhones that could give governments access,the company dropped its plan. It said it was almost impossible to scan iCloud photos without \u201cimperiling the securityand privacy of our users.\u201d\nEarly this year, Sarah Gardner, the founder of a child advocacy group called the Heat Initiative, began searching for law firms with experience representing victims of child sexual abuse.\nIn March, the Heat team asked Marsh Law, a 17-year-old firm that focuses on representing victims of child sexual abuse, if it could bring a suit against Apple. Heat offered to provide $75,000 to support what could be a costly litigation process. It was a strategy borrowed from other advocacy campaigns against companies.\nMargaret E. Mabie, a partner at Marsh Law, took on the case. The firm has represented thousands of victims of child sexual abuse. Ms. Mabie dug through law enforcement reports and other documents to find cases related to her clients\u2019 images and Apple\u2019s products, eventually building a list of more than 80 examples, including one of a Bay Area man whom law enforcement found with more than 2,000 illegal images and videos in iCloud.\nThe 27-year-old woman from the Northeast, who is represented by Marsh, agreed to sue Apple because, she said, she believes that Apple gave victims of child sexual abuse false hope by introducing and abandoning its NeuralHash system. An iPhone user herself, she said the company chose privacy and profit over people.\nJoining the suit was a difficult decision, she said. Because her images have been downloaded by so many people, she lives in constant fear that someone might track her down and recognize her. And being publicly associated with a high-profile case could cause an uptick in trafficking of her images.\nBut she said she had joined because she thought it was time for Apple to change. She said the company\u2019s inaction was heart-wrenching."
    },
    {
        "url": "https://www.nytimes.com/2024/12/16/opinion/trump-tech-leaders-support.html",
        "title": "The Great Capitulation",
        "fulltext": "At a press conference at Mar-a-Lago on Monday, Donald Trump described recent visits from Tim Cook, C.E.O. of Apple, Sergey Brin, a co-founder of Google, and other tech barons. \u201cIn the first term, everyone was fighting me,\u201d hesaid. \u201cIn this term, everyone wants to be my friend.\u201d For once, he wasn\u2019t exaggerating.\nSince Trump won re-election \u2014 this time with the popular vote \u2014 many of the most influential people in America seem to have lost any will to stand up to him as he goes about transforming America into the sort of authoritarian oligarchy he admires. Call it the Great Capitulation.\nFollowing Jan. 6, Mark Zuckerberg, the Facebook co-founder, suspended Trump\u2019s account. But last month at Mar-a-Lago, The Wall Street Journalreported, Zuckerberg stood, hand on heart, as \u201cthe club played a rendition of the national anthem sung by imprisoned\u201d Jan. 6 defendants. (It\u2019s not clear if Zuckerberg knew what he was listening to.) He\u2019s pledged a million-dollar donation to Trump\u2019s inauguration, as did the OpenAI C.E.O. Sam Altman and Jeff Bezos\u2019 company Amazon, which will also stream the inauguration on its video platform.\nAfter Time magazine declared Trump \u201cPerson of the Year,\u201d the publication\u2019s owner, the Salesforce C.E.O. Marc Benioff,wroteon X, \u201cThis marks a time of great promise for our nation.\u201d The owner of The L.A. Times, the billionaire pharmaceutical and biomedical entrepreneur Patrick Soon-Shiong,killedan editorial criticizing Trump\u2019s cabinet picks and urging the Senate not to allow recess appointments.\nMost shocking of all, last week ABC News, which is owned by the Walt Disney Company, made the craven decision to settle a flimsy defamation case brought by Trump.\nAs you may remember, a jury last year found Trump civilly liable for sexually abusing the writer E. Jean Carroll. In amemorandum, the judge in the case explained that while a jury didn\u2019t find that Trump had raped Carroll, it was operating under New York criminal law, which defines rape solely as \u201cvaginal penetration by a penis.\u201d It did find that he\u2019d forcibly penetrated her with his fingers.\n\u201cThe finding that Ms. Carroll failed to prove that she was \u2018raped\u2019 within the meaning of the New York Penal Law does not mean that she failed to prove that Mr. Trump \u2018raped\u2019 her as many people commonly understand the word \u2018rape,\u2019\u201d wrote the judge. \u201cIndeed, as the evidence at trial recounted below makes clear, the jury found that Mr. Trump in fact did exactly that.\u201d\nThe ABC News anchor George Stephanopoulos appeared to be using this broader definition when, in March, he said on-air that a jury had found Trump \u201cliable for rape.\u201d Trump, who regularly threatens, and sometimes files,defamation casesagainst his perceived enemies in the press, sued. And though his case seemed absurdly weak, ABC News decided to settle in exchange for a $15 million donation to Trump\u2019s future presidential library or museum, $1 million in legal fees and a public statement of regret from Stephanopoulos and the network.\nDisplays of submission aren\u2019t limited to tech and media. Christopher Wray, the head of the F.B.I., agreed to step aside before the end of his 10-year term rather than make Trump fire him. Several Democrats havesignaledtheir willingness to work with Elon Musk and Vivek Ramaswamy, whose so-called Department of Government Efficiency, or DOGE, seems poised to hack away at our already threadbare safety net.\nIn TheNew Yorker, Jonathan Blitzer wrote of the current administration\u2019s refusal, at least so far, to renew the humanitarian parole of immigrants from countries such as Venezuela and Haiti to possibly shield them from deportation under Trump. \u201cFor a president who considers Trump a fascist and has warned about the horrors of mass deportation, the atmosphere of Biden\u2019s White House has struck several people I spoke with as curiously sedate,\u201d Blitzer wrote.\nDifferent people have different reasons for falling in line. Some may simply lack the stomach for a fight or feel, not unreasonably, that it\u2019s futile. Our tech overlords, however liberal they once appeared, seem to welcome the new order. Many hated wokeness, resented the demands of newly uppity employees and chafed at attempts by Joe Biden\u2019s administration to regulate crypto and A.I., two industries with the potential to cause deep and lasting social harm. There are C.E.O.s who got where they are by riding the zeitgeist; they can pivot easily from mouthing platitudes about racial equity to slapping on a red MAGA hat.\nSome Democrats appear to think that they might steer DOGE in a productive direction and that, regardless, they\u2019ll get credit for bipartisanship. The electorate, after all, has rendered its verdict on #Resistance.\nOne of Kamala Harris\u2019s pollsters, Politicoreported, recently warned the Democratic National Committee leadership against pearl-clutching over Trump\u2019s transgressions, including the wildly unfit characters he\u2019s announced for his administration. The voters, she said, \u201cdon\u2019t care about who he\u2019s putting in cabinet positions.\u201d\nCollectively, all these elite decisions to bow to Trump make it feel like the air is going out of the old liberal order. In its place will be something more ruthless and Nietzschean.\n\u201cThe individual has the intrinsic moral right to live his life in a special and fulfilling way without subordinating to the universal collective,\u201d Marc Andreessen, the software engineer and venture capitalist at the forefront of Silicon Valley\u2019s rightward lurch,wroteon X last week. \u201cPurveyors of abstract guilt must not steal that from you.\u201d Even powerful people who didn\u2019t vote in favor of this harsh new world can find their consolations in it.\nThe Times is committed to publishinga diversity of lettersto the editor. We\u2019d like to hear what you think about this or any of our articles. Here are sometips. And here\u2019s our email:letters@nytimes.com.\nFollow the New York Times Opinion section onFacebook,Instagram,TikTok,WhatsApp,XandThreads."
    },
    {
        "url": "https://www.nytimes.com/2024/12/13/arts/music/larry-jackson-popcast-interview-drake.html",
        "title": "The Messy Modern Music Business, According to Larry Jackson",
        "fulltext": "The music executive Larry Jackson, a founder of the entertainment companyGamma, has seen several sea changes in the recording business from different vantages over different eras of disruption.\nAs head of A&R at Arista Records/RCA Music Group under Clive Davis, he oversaw albums by Whitney Houston and Jennifer Hudson while CDs were giving way to the iTunes Store. At Interscope, alongside Jimmy Iovine, he helped sign Chief Keef and Lana Del Rey as YouTube made new stars. As theglobal creative director at Apple Music, Jackson partnered with artists like Drake, Frank Ocean and Taylor Swift to bring streaming to the masses, while competing with Spotify \u2014 and the major labels.\nOn this week\u2019s episode of Popcast, Jackson spoke with the hosts Jon Caramanica and Joe Coscarelli about a topsy-turvy year in music \u2014 headlined by the battle between Kendrick Lamar and Drake \u2014 and how Jackson is applying lessons from his label days to whatever the industry has become.\nConnect With Popcast.Become a part of the Popcast community: Join the show\u2019sFacebook groupandDiscord channel. We want to hear from you! Tune in, and tell us what you think atpopcast@nytimes.com. Follow our host, Jon Caramanica, on Twitter:@joncaramanica.\nUnlock full access to New York Times podcasts and explore everything from politics to pop culture. Subscribe today atnytimes.com/podcastsor on Apple Podcasts and Spotify."
    },
    {
        "url": "https://www.nytimes.com/2024/12/18/technology/personaltech/apple-google-photo-apps-updates-changes.html",
        "title": "How to Find Your Way Around That Updated Photos App",
        "fulltext": "Apple\u2019s fall overhaul of its Photos app \u2014 publicized by the company as its\u201cbiggest redesign ever\u201d\u2014 gave the software a fresh look and new methods for managing your portable picture library on the iPhone and iPad. However,not everyone was a fan, as the new design retired familiar navigational icons in favor of a \u201cunified\u201d view that put almost everything on one screen.\nBut thanks to inconspicuous menus and settings, you can arrange things more to your liking. Here\u2019s how to find your stuff in the latest version of Photos, along with a quick look at some recent changes to the Google Photos app.\nApple\u2019siOS 18.2 updatelast week fixed a few issues that users had been complaining about since the new Photos app landed in September (like videos automatically looping). But the app\u2019s overall design is the same: You start off on one big screen for your picture library, albums, videos, selfies and everything else.\nThe exact items you see depend on your device, asmany late-model iPhones and iPadshave the newApple Intelligencesoftware for making things like\u201cmemory movies\u201don command.\nHow you find things depends on which way you scroll:\nLooking for your photo library? Swipe down to roll through the grid of image thumbnails, which goes farther back in time the more you scroll.\nLooking for albums, videos, favorites,the duplicates menuand other tools? Swipe in an upward motion to scroll toward the bottom of the app and through the automatically generated groupings (likeRecent DaysorPeople & Pets) and your handcrafted photo albums. The menus forMedia TypesandUtilitiesare here, too.\nLooking for a certain image? Tap the blueSearch buttonat the top of the screen to start hunting specific photos or videos.\nBoth the photo library and the collections-and-menus areas are packed, but you can streamline what you see.\nFor example, as you scroll through the library, a small menu offering Years, Months or All appears. Tap one of those options to jump to the photos taken in those time periods.\nWhen you select the All option, a pair of arrows appear in the bottom-left corner. This opens a menu where you can view the images when they were added to the library or by the date they were captured. This menu also includes Filter controls for sifting photos in the collection so that, for example, you see only pictures marked as favorites.\nAt the bottom of the menu, View Options allows you to zoom in or out on the thumbnails for a closer look. You can change the picture shapes, or aspect ratio, in the image grid if you would prefer to see the whole thumbnail in its original orientation instead of as a standardized square. You can also hide screenshots and shared albums from view.\nThe collections-and-menus end of the app can be modified, too. If you want to see fewer picture groupings or put them in a different order, go to the bottom of the screen, tap theCustomize & Reorderbutton and make your changes. Tap the \u201cx\u201d button in the top-right corner when you\u2019re finished.\nBut wait, there\u2019s yet another menu to sample: Tap your profile icon in the top-right corner of the Photos app for access to options for displaying or hiding certain albums in the main view, looping videos and other controls.\nApple\u2019sofficial guide to Photoson its site has more information on using the app for editing, sharing and storing your pictures.\nTheGoogle Photosapp for Android and iOS has been rolling out its own changes in recent months. TheGoogle Photos blogandhelp guideare good places to check if something suddenly looks different on your device, as what you may see depends on your hardware, software and other factors.\nAmong the updates, Google Photos now notates anyartificial intelligence-enhanced editing(like erasing background objects from an image) on a picture\u2019s details page. Google is also testing anAsk Photostool forsearching your pictureswith itsGeminiA.I. assistant, but interested users mustsign up and join a wait listto try it out.\nOther recent changes includea Collections viewthat replaces the Library icon at the bottom of the screen; the Collections section now groups albums and media menus together in one place. And you can see all your photo-sharing activity on the newUpdates pagewhen you tap the bell icon at the top of the screen.\nPhoto libraries are deeply personal, and it\u2019s natural to feel concerned when the software storing them suddenly changes. But no matter how far things evolve,keeping your photos backed upis a timeless idea."
    },
    {
        "url": "https://www.nytimes.com/2024/12/07/us/child-abuse-apple-google-apps.html",
        "title": "On These Apps, the Dark Promise of Mothers Sexually Abusing Children",
        "fulltext": "The promotional photo showed a mother affectionately hugging and kissing her daughter. The girl, around 8 years old, smiled into the camera.\nWith a few swipes on their phones, men entered a livestream where they paid $150 to watch the mother sexually abuse the girl for 10 minutes.\nThe horrendous activity wasn\u2019t hidden on some dark corner of the internet. It was available for anyone with an iPhone or Android to download from the Apple or Google app store.\nThe woman, who lives in Southeast Asia, promoted her livestream on Bigo Live, a video chat app where The New York Times viewed a screenshot of her profile early this year. When she was later contacted online by an undercover agent for the U.S. Department of Homeland Security \u2014 posing as a man interested in young girls \u2014 she directed him to another livestreaming app, where her pay-per-view sexual abuse had moved.\nSince last year, The Times has been investigating the world of parents who run accounts on Instagram and elsewhere for their underage daughters and who post or sell racy photos of the girls, in some casesearning large sums of money. The Timesreported in Februarythat many of the so-called mom-run social media accounts with the biggest reach were overwhelmingly followed by adult men, including pedophiles.\nThe livestream apps downloaded from Apple and Google illustrate an even darker aspect of the social media technology boom, particularly for children living in poverty in developing countries. There, with the ease of a smartphone, parents and other adults can connect with pedophiles in the United States and elsewhere who pay to watch \u2014 and direct \u2014 criminal behavior.\nAfter confirming the authenticity of the Bigo livestreamer with the authorities, The Times searched the Apple and Google app stores for other video chat apps. Reporters identified a sample of more than 80 apps that advertised children before stopping the search. They later contacted Homeland Security Investigations, the government\u2019s main law enforcement group for international exploitation, for comment.\nThe agency made the undercover agent available to answer questions, so long as he was not identified.\nThe apps had not been a focus of the agency\u2019s work, the agent said, but the criminal activity mirrored that on dating websites he had investigated. There, men search for women, typically in Southeast Asia, who charge to sexually abuse children on camera.\nWhile mothers or other family members are the most common culprits, he said, other adults \u2014 including members of criminal organizations \u2014 sometimes arrange the abuse.\n\u201cThe number one customer base paying for this abuse is in the United States,\u201d the agent said. \u201cIt\u2019s not like they are abused once a day. It\u2019s 50 men getting 50 separate shows. They\u2019ll wake up these kids in the middle of the night to be abused.\u201d\nThe livestream apps follow different models. Some, like Bigo, are designed for a mainstream audience to watch dancers, gamers or other content creators. Viewers can reward streamers with in-app currency.\nOthers are geared toward men looking for sexual encounters, and users can pay by the minute for private video chats. Although Apple and Google ban pornography from their stores, The Times found apps that showed nude adults in sexual poses. Some apps had names like \u201c18+ Live & Video Chat,\u201d \u201cAdult Live Chat\u201d and \u201cAdult Calls, Love Chat.\u201d\nStreamers of all kinds collect money from their broadcasts, and the owners of the apps also take a cut, as do Apple and Google. The two big tech companies typically collect between 15 and 30 percent as a fee for in-app purchases.\nIn statements to The Times, neither Apple nor Google addressed the issue of in-app purchases for illegal streaming. Both companies said they had zero tolerance for child sexual abuse material and had removed or suspended the flagged apps. Both companies said they required app developers to police user-generated content on their platforms.\n\u201cWe\u2019re constantly on guard for these kinds of violations which carry severe penalties including removal from the store and termination from our developer program,\u201d Fred Sainz, an Apple spokesman, said. \u201cOur App Review team works 24/7 to review every new app and app update to ensure it meets our quality and safety standards, including stringent requirements for apps with person-to-person interactions.\u201d\nAsked about The Times\u2019s sample of offending apps, Mr. Sainz said a majority had been detected during the company\u2019s standard review process, with an additional 20 taken down after an internal investigation in response to The Times\u2019s findings.\nKarl Ryan, a Google spokesman, said the company \u201cdid not immediately uncover\u201d child sexual abuse material in the apps The Times had flagged, but it suspended them \u201cout of an abundance of caution\u201d while the apps\u2019 developers were contacted. \u201cWe take this issue extremely seriously,\u201d he said.\nMany of the apps on both platforms advertised sex shows or bestiality. The Apple App Store\u2019s search recommendations also helped The Times surface some of the apps advertising children by suggesting sexual terms such as \u201cx.x.x live.\u201d\nIn response, the company changed its search recommendations to no longer suggest adult content, Mr. Sainz said.\nOne profile identified by The Times showed a woman in Vietnam offering \u201cHOT VIDEO\u201d and listed possible participants as two young sisters, a little girl, three little boys and a dog.\nAnother woman in Vietnam described sex acts she could perform along with an invitation to \u201csee mother and daughter, son.\u201d A woman in the Philippines advertised \u201clil&Mom\u201d and showed a preview video of a young girl. The profiles did not include abuse, which required payment to be viewed.\nThe livestreaming of child sexual abuse is thought to be most common in the Philippines, though the data is limited.International Justice Mission, a global human rights organization with a program to protect minors in that country, commissioned a study last year that estimatednearly 500,000 Filipino childrenwere being abused in the creation of illegal imagery.\nThe country\u2019s top law enforcement official for such crimes, Brig. Gen. Portia B. Manalad of the Philippine National Police, said that she was aware of the apps, and that the agency had rescued more than 500 children and arrested more than 200 perpetrators \u2014 mostly relatives, \u201cusually the mother\u201d \u2014 over the last five years.\n\u201cWe are trying our best to find the victims,\u201d she said.\nIn the United States, The Times found nearly 100 federal criminal cases over the past decade involving men paying to watch the livestreaming of child sexual abuse.\nIn October, a woman in South Dakota, Krystal Kay Bulin, wassentenced to eight yearsin prison after she moderated a chat room during sexually explicit livestreams involving a 16-year-old girl. Ms. Bulin, the girl\u2019s temporary guardian, facilitated the livestreams on an app called BuzzCast to help pay for a speeding ticket, according to court records.\nA Florida man, Christopher John Streeter, has beenserving life in prisonsince 2021 after sending roughly $130,000 over a decade to people in the Philippines to direct the rape of children as young as 12.\nHe paid a premium if the video depicted girls losing their virginity or suffering injuries because of the sexual violence. Court records show Mr. Streeter\u2019s victims were particularly vulnerable \u201cdue to poverty and illness.\u201d\nAs a result of that case, six abused girls were rescued by local authorities in conjunction with officers from Homeland Security Investigations. The undercover agent who spoke to The Times said such outcomes were especially gratifying because once a livestream session ends, the evidence often disappears.\n\u201cIt\u2019s a very difficult crime to investigate,\u201d he said. \u201cNo one knows that it happened, except the poor kid that was raped, the mother that did it and the guy who paid for it.\u201d\nBy some measures, online child sexual abuse has increased in recent years. The distribution of such material surged during the pandemic, according toa study by Europol, the European law enforcement agency. An investigator for the organization said rates had been elevated ever since.\n\u201cNow, with these new livestreaming platforms and use of webcams, people can, from a relatively safe environment, abuse and direct the abuse of children from a distance in a very, very easy way,\u201d said the investigator, Danny van Althuis.\nSarah Gardner, who leads a child safety advocacy group,the Heat Initiative, said The Times\u2019s findings were particularly shocking given that Apple and Google both claim to hold apps on their marketplaces to the highest safety and content standards.\nShe faulted the two companies for allowing the livestreaming, and for facilitating and profiting from the payments.\n\u201cThe most powerful companies in the world are enabling the sexual abuse of a child to be livestreamed on the internet,\u201d she said. On Thursday, Ms. Gardner and others protested at Apple\u2019s store in New York\u2019s Grand Central Terminal, calling on the company to improve child safety.\nThe Times learned of the streaming on Bigo Live from a 39-year-old man in Utah who had visited the woman\u2019s profile page on his iPhone in what he described as a period of suicidal depression. The man, who spoke on the condition of anonymity, paid $550 for the mother and another woman to sexually abuse their daughters, including the 8-year-old girl and another believed to be 3 or 4. Some of the payments were made through in-app tokens, but most of the money was transferred through PayPal, the man said.\nThe man saved recordings of the sessions and reported them to the Canadian Center for Child Protection, which verified the abuse to The Times. He also reported the women to Bigo Live\u2019s support staff, emails show.\nA PayPal spokeswoman said the company worked with law enforcement around the world to help stop child exploitation.\nBigo Live said that when it received the report from the Utah man, \u201cwe took appropriate action against the creators involved, including account suspension and content removal.\u201d In its statement, the company said it was \u201cdeeply committed to protecting user safety\u201d and was \u201ccontinuously improving our technology and procedures.\u201d\nWhen The Times searched for other smartphone apps with similar content, many were hiding in plain sight. In reviews posted to Apple\u2019s and Google\u2019s app stores, users warned of child exploitation on some apps.\nReviews for the apps Bigo Live, Gaze, Superlive and Tango mentioned parents sexually exploiting their children, according to an analysis by The Times and Brian Levine, a professor at the University of Massachusetts, Amherst, who has createda database of app reviewswith Hany Farid, a professor at the University of California, Berkeley. (Some apps were also identified with help from Primal Wijesekera, a research scientist at theInternational Computer Science Institute, where he maintains searchable records of the app stores.)\n\u201cWomen use kids in their streams to promote child X and BIGO just let\u2019s it happen. Do not, repeat, do not download this disgusting app,\u201d one user wrote on the Apple App Store, using an abbreviation for \u201cchild exploitation.\u201d\n\u201cI have found people willing to serve there children on here,\u201d one user wrote about Gaze.\nBuzzCast and Superlive did not respond to requests for comment. Representatives for Gaze and Tango said their companies had no tolerance for child sexual abuse material and pointed to multiple moderation systems they used to enforce their standards. They said that they took user reviews seriously, and also that the negative reviews were unrepresentative and may have been written by competitors.\n\u201cWe are deeply committed to ensuring the safety of our platform,\u201d said Dor Isseroff, chief operating officer of Tango, adding that he was confident the app was not used to stream abuse, though some users were advertising the activity on other platforms. He said the company used information from the accounts The Times discovered to upgrade its moderation systems, and on Friday \u201cidentified and suspended dozens of profiles that violated our guidelines.\u201d\nQuantifying the illegal activity is difficult, but it has become prevalent enough that Homeland Security last yearadded\u201ccrimes of exploitation,\u201d which includes child sexual abuse, to its list of priorities, putting it on par with terrorism and border security.\nSecretary of Homeland Security Alejandro N. Mayorkas said in an interview that he had been aware of the issue since serving in the Obama administration. The problem has only grown, he said.\n\u201cI decided to lift its profile up and to devote the resources and attention accordingly,\u201d Mr. Mayorkas said.\nGovernment officials in the European Union, too, have been working to make it easier to combat the livestreaming of child sexual abuse, which has been made difficult by differing laws.A proposalwould update the bloc\u2019s criminal code to facilitate cross-border investigations.\nIn June, Homeland Security organized aninvestigative \u201csprint\u201dwith Europol, in which officials from 10 countries shared data from various investigations. It generated leads on nearly 200 \u201ccriminal buyers,\u201d a Europol spokeswoman said.\nWhile the livestreaming apps may be relatively new to many authorities, they have been around for years. Many of the apps launched during the pandemic, when interest in live video surged. On the dark web, they have also been a topic of interest, according to the Canadian Center for Child Protection, which monitors such activity.\nIn one post mentioning Tango in January, a user shared a screenshot of a young girl and inquired: \u201cCan anyone share the videos of this cutie who shows and masturbates along with her sister and mother in other videos?\u201d\nDuring 13 years working undercover, the Homeland Security agent said, he had helped rescue 286 children. He said the woman in the Southeast Asia case had been identified and the agency was now working with local authorities to rescue the 8-year-old.\nNext year, he will take part inonline safety education sessions for teenagersand train more agents.\nStill, he said, \u201cwe\u2019ve probably infiltrated .0001 percent of the actual abuse that\u2019s occurring.\u201d\nJennifer Valentino-DeVriescontributed reporting. Produced byGray BeltranandRumsey Taylor."
    }
]