[
    {
        "url": "https://www.nytimes.com/2018/05/10/technology/alexa-siri-hidden-command-audio-attacks.html",
        "title": "Alexa and Siri Can Hear This Hidden Command. You Can\u2019t.",
        "fulltext": "BERKELEY, Calif. \u2014 Many people have grown accustomed to talking to their smart devices, asking them to read a text, play a song or set an alarm. But someone else might be secretly talking to them, too.\nOver the last two years, researchers in China and the United States have begun demonstrating that they can send hidden commands that are undetectable to the human ear to Apple\u2019s Siri, Amazon\u2019s Alexa and Google\u2019s Assistant. Inside university labs, the researchers have been able to secretly activate the artificial intelligence systems on smartphones and smart speakers, making them dial phone numbers or open websites. In the wrong hands, the technology could be used tounlock doors,wire moneyor buy stuff online \u2014 simply with music playing over the radio.\nA group of students from University of California, Berkeley, and Georgetown University showed in 2016 that they could hide commands in white noise played over loudspeakers and through YouTube videos to get smart devices to turn on airplane mode or open a website.\nThis month, some of those Berkeley researchers published a research paper that went further, saying they could embed commands directly into recordings of music or spoken text. So while a human listener hears someone talking or an orchestra playing, Amazon\u2019s Echo speaker might hear an instruction to add something to your shopping list.\n\u201cWe wanted to see if we could make it even more stealthy,\u201d said Nicholas Carlini, a fifth-year Ph.D. student in computer security at U.C. Berkeley and one of the paper\u2019s authors.\n[Read more on whatAlexa can hearwhen brought into your home]\nMr. Carlini added that while there was no evidence that these techniques have left the lab, it may only be a matter of time before someone starts exploiting them. \u201cMy assumption is that the malicious people already employ people to do what I do,\u201d he said.\nThese deceptions illustrate how artificial intelligence \u2014 even as it is making great strides \u2014 can still be tricked and manipulated. Computers can be fooled into identifying an airplane as a cat just by changing a few pixels of a digital image, while researchers can make a self-driving car swerve or speed up simply by pasting small stickers on road signs and confusing the vehicle\u2019s computer vision system.\nWith audio attacks, the researchers are exploiting the gap between human and machine speech recognition. Speech recognition systems typically translate each sound to a letter, eventually compiling those into words and phrases. By making slight changes to audio files, researchers were able to cancel out the sound that the speech recognition system was supposed to hear and replace it with a sound that would be transcribed differently by machines while being nearly undetectable to the human ear.\nThe proliferation of voice-activated gadgets amplifies the implications of such tricks. Smartphones and smart speakers that use digital assistants like Amazon\u2019s Alexa or Apple\u2019s Siri are set to outnumber people by 2021,according to the research firm Ovum. And more than half of all American households will haveat least one smart speakerby then, according to Juniper Research.\nAmazon said that it doesn\u2019t disclose specific security measures, but it has taken steps to ensure its Echo smart speaker is secure. Google said security is an ongoing focus and that its Assistant has features to mitigate undetectable audio commands. Both companies\u2019 assistants employ voice recognition technology to prevent devices from acting on certain commands unless they recognize the user\u2019s voice.\nApple said its smart speaker, HomePod, is designed to prevent commands from doing things like unlocking doors, and it noted that iPhones and iPads must be unlocked before Siri will act on commands that access sensitive data or open apps and websites, among other measures.\nYet many people leave their smartphones unlocked, and, at least for now, voice recognition systems are notoriouslyeasy to fool.\nThere is already a history of smart devices being exploited for commercial gains through spoken commands.\nLast year, Burger Kingcaused a stirwith an online ad that purposely asked \u2018O.K., Google, what is the Whopper burger?\u201d Android devices with voice-enabled search would respond by reading from the Whopper\u2019s Wikipedia page. The ad was canceled after viewers started editing the Wikipedia page to comic effect.\n[Read more on how we may soon be living inAlexa\u2019s world]\nA few months later, the animated series South Park followed up with anentire episodebuilt around voice commands that caused viewers\u2019 voice-recognition assistants to parrot adolescent obscenities.\nThere is no American law against broadcasting subliminal messages to humans, let alone machines. The Federal Communications Commission discourages the practice as \u201ccounter to the public interest,\u201d and the Television Code of the National Association of Broadcasters bans \u201ctransmitting messages below the threshold of normal awareness.\u201d Neither say anything about subliminal stimuli for smart devices.\nCourts have ruled that subliminal messages may constitute an invasion of privacy, but the law has not extended the concept of privacy to machines.\nNow the technology is racing even further ahead of the law. Last year, researchers at Princeton University and China\u2019s Zhejiang University demonstrated that voice-recognition systems could be activated by using frequencies inaudible to the human ear. The attack first muted the phone so the owner wouldn\u2019t hear the system\u2019s responses, either.\nThe technique, which the Chinese researchers called DolphinAttack, can instruct smart devices to visit malicious websites, initiate phone calls, take a picture or send text messages. While DolphinAttack has its limitations \u2014 the transmitter must be close to the receiving device \u2014 experts warned that more powerful ultrasonic systems were possible.\nThat warning was borne out in April, when researchers at the University of Illinois at Urbana-Champaign demonstrated ultrasound attacks from 25 feet away. While the commands couldn\u2019t penetrate walls, they could control smart devices through open windows from outside a building.\nThis year, another group of Chinese and American researchers from China\u2019s Academy of Sciences and other institutions, demonstrated they could control voice-activated devices with commandsembedded in songsthat can be broadcast over the radio or played on services like YouTube.\nMore recently, Mr. Carlini and his colleagues at Berkeley haveincorporated commandsinto audio recognized by Mozilla\u2019s DeepSpeech voice-to-text translation software, an open-source platform. They were able to hide the command, \u201cO.K. Google, browse toevil.com\u201d in a recording of the spoken phrase, \u201cWithout the data set, the article is useless.\u201d Humans cannot discern the command.\nThe Berkeley group also embedded the command in music files, including a four-second clip from Verdi\u2019s \u201cRequiem.\u201d\nHow device makers respond will differ, especially as they balance security with ease of use.\n\u201cCompanies have to ensure user-friendliness of their devices, because that\u2019s their major selling point,\u201d said Tavish Vaidya, a researcher at Georgetown. He wrote one of the first papers on audio attacks, which he titled\u201cCocaine Noodles\u201dbecause devices interpreted the phrase \u201ccocaine noodles\u201d as \u201cO.K., Google.\u201d\nMr. Carlini said he was confident that in time he and his colleagues could mount successful adversarial attacks against any smart device system on the market.\n\u201cWe want to demonstrate that it\u2019s possible,\u201d he said, \u201cand then hope that other people will say, \u2018O.K. this is possible, now let\u2019s try and fix it.\u2019 \u201d"
    },
    {
        "url": "https://www.nytimes.com/2018/05/19/technology/phone-apps-stalking.html",
        "title": "Hundreds of Apps Can Empower Stalkers to Track Their Victims",
        "fulltext": "KidGuard is a phone app that markets itself as a tool for keeping tabs on children. But it has also promoted its surveillance for other purposes and run blog posts with headlines like \u201cHow to Read Deleted Texts on Your Lover\u2019s Phone.\u201d\nA similar app, mSpy, offered advice to a woman on secretly monitoring her husband. Still another, Spyzie, ran ads on Google alongside results for search terms like \u201ccatch cheating girlfriend iPhone.\u201d\nAs digital tools that gather cellphone data for tracking children, friends or lost phones have multiplied in recent years, so have the options for people who abuse the technology to track others without consent.\nMore than 200 apps and services offer would-be stalkers a variety of capabilities, from basic location tracking to harvesting texts and even secretly recording video, according toa new academic study. More than two dozen services were promoted as surveillance tools for spying on romantic partners, according to the researchers and reporting by The New York Times. Most of the spying services required access to victims\u2019 phones or knowledge of their passwords \u2014 both common in domestic relationships.\nDigital monitoring of a spouse or partner can constitute illegal stalking, wiretapping or hacking. But laws and law enforcement have struggled to keep up with technological changes, even though stalking is a top warning sign for attempted homicide in domestic violence cases.\n\u201cWe misunderstand and minimize this abuse,\u201d said Erica Olsen, director of theSafety Net Projectat the National Network to End Domestic Violence. \u201cPeople think that if there\u2019s not an immediate physical proximity to the victim, there might not be as much danger.\u201d\nStatistics on electronic stalking are hard to find because victims may not know they are being watched, or they may not report it. Even if they believe they are being tracked, hidden software can make confirmation difficult.\nBut data breaches at two surveillance companies last year \u2014 revealing accounts of more than 100,000 users, according to the technology siteMotherboard\u2014 gave some sense of the scale. The tracking app company mSpy told The New York Times that it sold subscriptions to more than 27,000 users in the United States in the first quarter of this year.\nAccording to data published last year by the Centers for Disease Control and Prevention, 27 percent of women and 11 percent of men in the United States at some point endure stalking or sexual or physical violence by an intimate partner that has significant effects. While comprehensive numbers aren\u2019t available on domestic abuse cases involving digital stalking in the United States, a small survey published in Australia in 2016 found that 17 percent of victims were tracked via GPS, including through such apps.\nIn a Florida case involving abusive surveillance, a man named Luis Toledo installed an app called SMS Tracker on his wife\u2019s phone in 2013 because he suspected she was having an affair. \u201cHe said he was able to see text messages and photos his wife was sending and receiving from others,\u201d Sgt. A. J. Pagliari of the Volusia County Sheriff\u2019s Office recalled.\nThis January, Mr. Toledowas sentencedto three consecutive life terms after being convicted of killing his wife, Yessenia Suarez, and her two children. Sergeant Pagliari said Mr. Toledo told him he installed the app several days before her death. \u201cWith the use of the app, Toledo was able to confirm his suspicion,\u201d the sergeant said.\nRepresentatives for SMS Tracker, made by the Dallas-based Gizmoquip, did not respond to requests for comment about the app\u2019s role in the case. A recent review on the Google Play store for SMS Tracker tells potential users: \u201cI would recommend if you think your partner is cheating.\u201d\nThere is no federal law against location tracking, but such monitoring can violate state laws on stalking. Spying on communications can break statutes on wiretapping or computer crime. And knowingly selling illegal wiretapping tools is a federal crime.\nBut it\u2019s not illegal to sell or use an app for tracking your children or your own phone. And it can be difficult to tell whether the person being surveilled has given consent, because abusers frequently coerce victims into using such apps.\nIn Everson, Wash., for example, Brooks Owen Laughlin is accused of beating his wife and using an app typically used for benign purposes, Find My iPhone, to control her movements.\n\u201cIf she would turn it off, he would instantly call her or text her and say, \u2018Why did you turn that off? What are you doing?\u2019 That was pretty much 24-7,\u201d Chief Daniel MacPhee of the Everson Police Department, said in an interview. Mr. Laughlin pleaded not guilty in April to charges of assault, harassment and stalking.\nSuch technical and legal ambiguity has created an environment in which tools are marketed for both legal and illegal uses, without apparent repercussion.\n\u201cThere are definitely app makers that are complicit, seeking out these customers and advertising this use,\u201d said Periwinkle Doerfler, a doctoral student at New York University and an author of the study on apps, which will be presented in the coming days. \u201cThey\u2019re a little bit under the radar about it, but they\u2019re still doing it.\u201d\nThe researchers, from N.Y.U., Cornell University and Cornell Tech, contacted customer support for nine companies with tracking services. The researchers claimed to be women who wanted to secretly track their husbands, and only one company, TeenSafe, refused to assist.\nKidGuard, the app largely aimed at parents, also bought ads alongside Google results for searches like \u201ccatch cheating spouse app.\u201d A spokesman for the business, based in Los Angeles, said in an email that the company worked with third-party marketers and customer service reps who had been \u201ctesting new strategies.\u201d It deleted blog posts about tracking romantic partners and said it did not support that activity.\nSpyzie, another app that ran such ads, did not respond to requests for comment.\nOn YouTube, dozens of videos provide tutorials on using several of the apps to catch cheating lovers. The videos frequently link back to the app makers\u2019 sites using a special code that ensures the promoter will get a cut of the sale \u2014 a type of deal known as affiliate marketing.\nAffiliate marketing also appeared on multiple websites that discussed using surveillance apps to track romantic partners. One site, spyblog.ml, had posts about spying on \u201cloved ones\u201d and linked to mSpy. The app company said that its terms of service prohibited illegal activity and that it would block the site from its affiliate program.\nReviews and online discussions about the apps suggest the market for spying on spouses has been important to the businesses. FlexiSPY, an app company, posted survey results on its site showing that 52 percent of potential customers were interested because they thought their partners might be cheating. Asked about the results, the company said the data was five years old and \u201cno longer relevant.\u201d\nThe proliferation of such tracking apps raises questions about the role of businesses like Google and Apple in policing their services.\nThe two companies, which run nearly all smartphones in the United States, have long taken different approaches to regulating apps.\nApple makes it difficult for iPhone users to download apps from outside the company\u2019s App Store, and has many restrictions on what apps in its store can do. After testing several programs available in the stores on both platforms, the researchers found that Apple\u2019s strict rules resulted in more limited surveillance capabilities on those apps than those running Google\u2019s software.\nMany App Store apps offered location tracking for phones. But for more intrusive surveillance, spying companies had to work around Apple\u2019s restrictions by using the victim\u2019s name and password to get data. To combat misuse by predators, an Apple spokesman said, the company urges people to use a tool called two-factor authentication to help protect their accounts even if their passwords are stolen.\nGoogle prides itself on being more open. Its smartphone software, Android, allows people to install apps from anywhere, and the most invasive ones were found outside the company\u2019s app store, Play.\nThe researchers found two apps in the Google Play store that allowed the app icon to be hidden from victims and the camera to run without notifications, as well as a handful of others that tracked users\u2019 locations without telling them, all apparent violations of Google\u2019s rules.\n\u201cThey\u2019re not enforcing their own policies,\u201d Ms. Doerfler, the N.Y.U. researcher, said. \u201cIf someone reports it then they\u2019ll take it down, but it\u2019s not something they are checking within their operating system.\u201d\nIn response to the researchers\u2019 findings, Google tightened several policies \u201cto further restrict the promotion and distribution\u201d of surveillance apps, a company spokesman said. The company provides funding to the N.Y.U. team that helped conduct the study.\nGoogle removed many spying and tracking apps and blocked advertising on search results about spying on spouses and romantic partners. YouTube, owned by Google, took down some videos about spying services, although the company determined that others didn\u2019t violate its policies because the services could be used with consent.\nMany law enforcement agencies don\u2019t have the computer skills to quickly help survivors, or they don\u2019t devote forensic resources to domestic abuse and stalking cases, which in many states are misdemeanors.\nOne sheriff\u2019s department, in Dakota County, Minn., is trying to tackle the problem of abusive digital surveillance, and has used Justice Department grants to hire a forensic specialist for the task.\nThe sheriff, Tim Leslie, said that from 2015 to 2017, the department went to court in 198 cases involving technology and stalking or domestic abuse, on par with earlier years. Its conviction rate rose to 94 percent from 50 percent, with many more suspects pleading guilty instead of contesting the charges, he said.\nIn one case, the specialist analyzed a woman\u2019s phone and found it had a program on it called Mobile Spy, bought using her then-husband\u2019s email address. The specialist could see that it had been launched 122 times. The effect of the stalking was \u201cprofound,\u201d the woman said.\nEven though it had been more than a year since the app was last used, the man was charged with misdemeanor stalking and pleaded guilty in 2015.\n\u201cWe go after the misdemeanor stuff pretty hard, in the theory that if you stop that, it doesn\u2019t escalate,\u201d Sheriff Leslie said.\nFederal cases involving such spying are rare. The Justice Department in 2014 charged the maker of a spying program called StealthGenie under a wiretap law that prohibits advertising and selling a device for \u201csurreptitious interception.\u201d The developer paid a $500,000 fine, shut down StealthGenie and was sentenced to time served.\nVictims\u2019 advocates said they noticed after the case that makers of surveillance tools changed their tactics, sometimes moving computer servers overseas or scrubbing explicit language about spousal spying from their websites. \u201cAs soon as these companies caught wind that they shouldn\u2019t be doing it, they just changed their marketing,\u201d Ms. Olsen said.\nOne app maker told The Times that he hired a legal team after the StealthGenie case to help him avoid running afoul of the law. \u201cThere were a few modifications we had to make,\u201d said Patrick Hinchy, the founder of New York-based ILF Mobile Apps, which makes Highster Mobile and other services. Several apps, he said, removed call recording and delayed the availability of the data by 10 to 15 minutes. Mr. Hinchy said the company only provided assistance to customers that it believed was legal.\nWhen a researcher recently contacted the company and asked, \u201cIf I use this app to track my husband, will he know that I am tracking him?\u201d the representative responded: \u201cOur software is undetectable from the home screen.\u201d"
    }
]