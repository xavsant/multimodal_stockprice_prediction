{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compiled models for sentiment analysis\n",
    "- First portion for headlines, second for abstract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import dependencies\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load LLM JSON data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pub_date</th>\n",
       "      <th>abstract</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-01-05</td>\n",
       "      <td>You can adjust your settings so that only cert...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-01-05</td>\n",
       "      <td>It’s time to take note of what lies at the top...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015-01-06</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015-01-07</td>\n",
       "      <td>With apps able to act as cameras, media player...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015-01-08</td>\n",
       "      <td>Google’s app store is the largest in the world...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     pub_date                                           abstract\n",
       "0  2015-01-05  You can adjust your settings so that only cert...\n",
       "0  2015-01-05  It’s time to take note of what lies at the top...\n",
       "1  2015-01-06                                                NaN\n",
       "2  2015-01-07  With apps able to act as cameras, media player...\n",
       "3  2015-01-08  Google’s app store is the largest in the world..."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load json \n",
    "path = '../../../data/clean/multimodal_inputs/llm_text_data_processed_abstract_AAPL.json'\n",
    "with open(path,\"r\") as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "df = pd.DataFrame(list(data.items()), columns=['pub_date','abstract'])\n",
    "df = df.explode('abstract')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 3402 entries, 0 to 2513\n",
      "Data columns (total 2 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   pub_date  3402 non-null   object\n",
      " 1   abstract  2143 non-null   object\n",
      "dtypes: object(2)\n",
      "memory usage: 79.7+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pub_date</th>\n",
       "      <th>abstract</th>\n",
       "      <th>ticker</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-01-05</td>\n",
       "      <td>You can adjust your settings so that only cert...</td>\n",
       "      <td>AAPL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015-01-05</td>\n",
       "      <td>It’s time to take note of what lies at the top...</td>\n",
       "      <td>AAPL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015-01-06</td>\n",
       "      <td></td>\n",
       "      <td>AAPL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015-01-07</td>\n",
       "      <td>With apps able to act as cameras, media player...</td>\n",
       "      <td>AAPL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015-01-08</td>\n",
       "      <td>Google’s app store is the largest in the world...</td>\n",
       "      <td>AAPL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3397</th>\n",
       "      <td>2024-12-23</td>\n",
       "      <td></td>\n",
       "      <td>AAPL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3398</th>\n",
       "      <td>2024-12-24</td>\n",
       "      <td></td>\n",
       "      <td>AAPL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3399</th>\n",
       "      <td>2024-12-26</td>\n",
       "      <td></td>\n",
       "      <td>AAPL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3400</th>\n",
       "      <td>2024-12-27</td>\n",
       "      <td></td>\n",
       "      <td>AAPL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3401</th>\n",
       "      <td>2024-12-30</td>\n",
       "      <td></td>\n",
       "      <td>AAPL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3402 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        pub_date                                           abstract ticker\n",
       "0     2015-01-05  You can adjust your settings so that only cert...   AAPL\n",
       "1     2015-01-05  It’s time to take note of what lies at the top...   AAPL\n",
       "2     2015-01-06                                                      AAPL\n",
       "3     2015-01-07  With apps able to act as cameras, media player...   AAPL\n",
       "4     2015-01-08  Google’s app store is the largest in the world...   AAPL\n",
       "...          ...                                                ...    ...\n",
       "3397  2024-12-23                                                      AAPL\n",
       "3398  2024-12-24                                                      AAPL\n",
       "3399  2024-12-26                                                      AAPL\n",
       "3400  2024-12-27                                                      AAPL\n",
       "3401  2024-12-30                                                      AAPL\n",
       "\n",
       "[3402 rows x 3 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add columns\n",
    "df['ticker'] = 'AAPL'\n",
    "\n",
    "# Replace NaN with empty string for models to process\n",
    "df['abstract'] = df['abstract'].fillna(\"\")\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### [Unused] Load company data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2143 entries, 0 to 2142\n",
      "Data columns (total 10 columns):\n",
      " #   Column            Non-Null Count  Dtype \n",
      "---  ------            --------------  ----- \n",
      " 0   ticker            2143 non-null   object\n",
      " 1   pub_date          2143 non-null   object\n",
      " 2   abstract          2143 non-null   object\n",
      " 3   lead_para         2124 non-null   object\n",
      " 4   headline          2143 non-null   object\n",
      " 5   doc_type          2143 non-null   object\n",
      " 6   section_name      2143 non-null   object\n",
      " 7   type_of_material  2142 non-null   object\n",
      " 8   rank              2143 non-null   int64 \n",
      " 9   web_url           2143 non-null   object\n",
      "dtypes: int64(1), object(9)\n",
      "memory usage: 167.6+ KB\n"
     ]
    }
   ],
   "source": [
    "#edit this part for new company\n",
    "df = pd.read_csv('Apple_Inc_text_data.csv')\n",
    "# format datetime again\n",
    "df['pub_date'] = pd.to_datetime(df['pub_date']) \n",
    "df['pub_date'] = df['pub_date'].dt.date\n",
    "#adding ticker in case we want to merge any DFs\n",
    "df['ticker'] = 'AAPL'\n",
    "df = df[['ticker'] + [col for col in df.columns if col != 'ticker']]\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#narrowing down to headlines and abstract\n",
    "# Select the desired columns\n",
    "sentiment_df = df[['ticker', 'pub_date', 'headline']]\n",
    "sentiment_df = sentiment_df.copy()  # Make a copy to avoid modifications on a slice\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Unused] Run headlines through all 5 models\n",
    "\n",
    "- This section compiles all sentiment features for all 5 models for 1 company\n",
    "- The final dataframe should consist of positive, neagtive and neutral probabilities for all models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Vader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     C:\\Users\\Tammy\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "nltk.download('vader_lexicon')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ticker</th>\n",
       "      <th>pub_date</th>\n",
       "      <th>headline</th>\n",
       "      <th>vader_pos</th>\n",
       "      <th>vader_neu</th>\n",
       "      <th>vader_neg</th>\n",
       "      <th>vader_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>2015-04-07</td>\n",
       "      <td>M.B.A. Programs That Get You Where You Want to Go</td>\n",
       "      <td>0.126</td>\n",
       "      <td>0.874</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>2015-04-14</td>\n",
       "      <td>What We’re Reading</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>2015-04-13</td>\n",
       "      <td>IBM Creates Watson Health to Analyze Medical Data</td>\n",
       "      <td>0.231</td>\n",
       "      <td>0.769</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>2015-04-22</td>\n",
       "      <td>What’s That on Beyoncé’s Wrist? Let Me Guess ....</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>2015-04-01</td>\n",
       "      <td>Daily Report: Tech Leaders Come Together to Op...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  ticker    pub_date                                           headline  \\\n",
       "0   AAPL  2015-04-07  M.B.A. Programs That Get You Where You Want to Go   \n",
       "1   AAPL  2015-04-14                                 What We’re Reading   \n",
       "2   AAPL  2015-04-13  IBM Creates Watson Health to Analyze Medical Data   \n",
       "3   AAPL  2015-04-22  What’s That on Beyoncé’s Wrist? Let Me Guess ....   \n",
       "4   AAPL  2015-04-01  Daily Report: Tech Leaders Come Together to Op...   \n",
       "\n",
       "   vader_pos  vader_neu  vader_neg vader_label  \n",
       "0      0.126      0.874        0.0    Positive  \n",
       "1      0.000      1.000        0.0     Neutral  \n",
       "2      0.231      0.769        0.0    Positive  \n",
       "3      0.000      1.000        0.0     Neutral  \n",
       "4      0.000      1.000        0.0     Neutral  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run model\n",
    "sia = SentimentIntensityAnalyzer()\n",
    "\n",
    "# Function to get full sentiment scores (including probabilities)\n",
    "def get_sentiment(text):\n",
    "    # Get the sentiment scores dictionary (positive, neutral, negative, and compound scores)\n",
    "    sentiment_scores = sia.polarity_scores(text)\n",
    "    return sentiment_scores\n",
    "\n",
    "# Apply the sentiment analysis to the 'headline' column\n",
    "sentiment_df['sentiment_scores'] = sentiment_df['headline'].apply(get_sentiment)\n",
    "\n",
    "# Separate out the individual sentiment probabilities into new columns\n",
    "sentiment_df['vader_pos'] = sentiment_df['sentiment_scores'].apply(lambda x: x['pos'])\n",
    "sentiment_df['vader_neu'] = sentiment_df['sentiment_scores'].apply(lambda x: x['neu'])\n",
    "sentiment_df['vader_neg'] = sentiment_df['sentiment_scores'].apply(lambda x: x['neg'])\n",
    "\n",
    "# Function to classify sentiment into Positive, Negative, or Neutral based on the compound score\n",
    "def classify_sentiment(score):\n",
    "    if score > 0.05:\n",
    "        return 'Positive'\n",
    "    elif score < -0.05:\n",
    "        return 'Negative'\n",
    "    else:\n",
    "        return 'Neutral'\n",
    "\n",
    "# Apply the compound score to classify sentiment\n",
    "sentiment_df['vader_label'] = sentiment_df['sentiment_scores'].apply(lambda x: classify_sentiment(x['compound']))\n",
    "\n",
    "# Display the result\n",
    "# Drop the 'sentiment_scores' column from the DataFrame\n",
    "sentiment_df = sentiment_df.drop(columns=['sentiment_scores'])\n",
    "\n",
    "# Display the result\n",
    "sentiment_df.head(5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Transformer (distilRoBERTa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"frostedtrees/Fin_distilroberta\")\n",
    "drob_model = AutoModelForSequenceClassification.from_pretrained(\"frostedtrees/Fin_distilroberta\", num_labels=3)  # Assuming 3 sentiments: positive, neutral, negative\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ticker</th>\n",
       "      <th>pub_date</th>\n",
       "      <th>headline</th>\n",
       "      <th>vader_pos</th>\n",
       "      <th>vader_neu</th>\n",
       "      <th>vader_neg</th>\n",
       "      <th>vader_label</th>\n",
       "      <th>drob_neg</th>\n",
       "      <th>drob_neu</th>\n",
       "      <th>drob_pos</th>\n",
       "      <th>drob_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>2015-04-07</td>\n",
       "      <td>M.B.A. Programs That Get You Where You Want to Go</td>\n",
       "      <td>0.126</td>\n",
       "      <td>0.874</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Positive</td>\n",
       "      <td>0.021400</td>\n",
       "      <td>0.790080</td>\n",
       "      <td>0.188520</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>2015-04-14</td>\n",
       "      <td>What We’re Reading</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>0.055277</td>\n",
       "      <td>0.798512</td>\n",
       "      <td>0.146211</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>2015-04-13</td>\n",
       "      <td>IBM Creates Watson Health to Analyze Medical Data</td>\n",
       "      <td>0.231</td>\n",
       "      <td>0.769</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Positive</td>\n",
       "      <td>0.015715</td>\n",
       "      <td>0.696537</td>\n",
       "      <td>0.287748</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>2015-04-22</td>\n",
       "      <td>What’s That on Beyoncé’s Wrist? Let Me Guess ....</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>0.042261</td>\n",
       "      <td>0.861066</td>\n",
       "      <td>0.096673</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>2015-04-01</td>\n",
       "      <td>Daily Report: Tech Leaders Come Together to Op...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>0.506060</td>\n",
       "      <td>0.291502</td>\n",
       "      <td>0.202438</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  ticker    pub_date                                           headline  \\\n",
       "0   AAPL  2015-04-07  M.B.A. Programs That Get You Where You Want to Go   \n",
       "1   AAPL  2015-04-14                                 What We’re Reading   \n",
       "2   AAPL  2015-04-13  IBM Creates Watson Health to Analyze Medical Data   \n",
       "3   AAPL  2015-04-22  What’s That on Beyoncé’s Wrist? Let Me Guess ....   \n",
       "4   AAPL  2015-04-01  Daily Report: Tech Leaders Come Together to Op...   \n",
       "\n",
       "   vader_pos  vader_neu  vader_neg vader_label  drob_neg  drob_neu  drob_pos  \\\n",
       "0      0.126      0.874        0.0    Positive  0.021400  0.790080  0.188520   \n",
       "1      0.000      1.000        0.0     Neutral  0.055277  0.798512  0.146211   \n",
       "2      0.231      0.769        0.0    Positive  0.015715  0.696537  0.287748   \n",
       "3      0.000      1.000        0.0     Neutral  0.042261  0.861066  0.096673   \n",
       "4      0.000      1.000        0.0     Neutral  0.506060  0.291502  0.202438   \n",
       "\n",
       "  drob_label  \n",
       "0    Neutral  \n",
       "1    Neutral  \n",
       "2    Neutral  \n",
       "3    Neutral  \n",
       "4   Negative  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "def predict_sentiment(headline):\n",
    "    inputs = tokenizer(headline, return_tensors=\"pt\", truncation=True, padding=True)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = drob_model(**inputs)\n",
    "    \n",
    "    logits = outputs.logits\n",
    "    probs = torch.softmax(logits, dim=-1)  # Convert logits to probabilities\n",
    "    \n",
    "    return probs[0].cpu().numpy()  # Returns an array of probabilities\n",
    "\n",
    "# Apply prediction to DataFrame\n",
    "sentiment_probs = sentiment_df['headline'].apply(predict_sentiment)\n",
    "\n",
    "# Create separate columns for sentiment probabilities\n",
    "sentiment_df[['drob_neg', 'drob_neu', 'drob_pos']] = pd.DataFrame(sentiment_probs.tolist(), index=sentiment_probs.index)\n",
    "\n",
    "# Determine final sentiment label based on highest probability and simplify label mapping\n",
    "sentiment_df['drob_label'] = sentiment_df[['drob_neg', 'drob_neu', 'drob_pos']].idxmax(axis=1)\n",
    "sentiment_df['drob_label'] = sentiment_df['drob_label'].replace({\n",
    "    'drob_pos': 'Positive',\n",
    "    'drob_neu': 'Neutral',\n",
    "    'drob_neg': 'Negative'\n",
    "})\n",
    "\n",
    "sentiment_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import tensorflow as tf\n",
    "\n",
    "# def drob_polarity_scores(sentence):\n",
    "#     encoded_text = tokenizer(sentence, return_tensors='tf')\n",
    "    \n",
    "#     output = drob_model(encoded_text)\n",
    "#     scores = output.logits[0].numpy()\n",
    "#     scores = tf.nn.softmax(scores).numpy()\n",
    "    \n",
    "#     scores_dict = {\n",
    "#         'drob_neg': scores[0],\n",
    "#         'drob_neu': scores[1],\n",
    "#         'drob_pos': scores[2]\n",
    "#     }\n",
    "#     return scores[0], scores[1], scores[2]\n",
    "\n",
    "# sentiment_df[['drob_pos','drob_neg','drob_neu']] = sentiment_df['headline'].apply(drob_polarity_scores).apply(pd.Series)\n",
    "\n",
    "# # Add label based on largest (neg/neu/pos)\n",
    "# sentiment_df['drob_label'] = sentiment_df.apply(lambda x:'Negative' if x['drob_neg'] >\n",
    "#                      x['drob_neu'] and x['drob_neu'] > x['drob_pos'] else ('Neutral' if x['drob_neu']>x['drob_pos'] else 'Positive'),axis=1)\n",
    "\n",
    "# sentiment_df.head() \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the DataFrame to a CSV file just in case \n",
    "sentiment_df.to_csv('apple_sentiment_analysis_results.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Transformer (DeBerta)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02c4793d097e47d490d8b57f49552c13",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/1.34k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Tammy\\anaconda3\\Lib\\site-packages\\huggingface_hub\\file_download.py:142: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\Tammy\\.cache\\huggingface\\hub\\models--tammiloveshf--Fin_DeBerta. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6306f466058d4e24a8973fbd2171f518",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "spm.model:   0%|          | 0.00/2.46M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "611785fb9f1d4e939df3a90b98def804",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/8.66M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e4fb7cd3cec24332bbdb0feaf0acf958",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "added_tokens.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b170d50ee1a0451b80bd4fbbe21671b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/301 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c9992f86ef947b8ac9f4876ed70a58a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.11k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "abd3d62cbb8147d2bc66ed36d39006e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/738M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"tammiloveshf/Fin_DeBerta\")\n",
    "deb_model = AutoModelForSequenceClassification.from_pretrained(\"tammiloveshf/Fin_DeBerta\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 21\u001b[0m\n\u001b[0;32m     18\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m deb_neg, deb_neu, deb_pos, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNegative\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m deb_neg \u001b[38;5;241m>\u001b[39m deb_neu \u001b[38;5;129;01mand\u001b[39;00m deb_neg \u001b[38;5;241m>\u001b[39m deb_pos \u001b[38;5;28;01melse\u001b[39;00m (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNeutral\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m deb_neu \u001b[38;5;241m>\u001b[39m deb_pos \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPositive\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     20\u001b[0m \u001b[38;5;66;03m# Apply the function to the 'headline' column and unpack the values into separate columns\u001b[39;00m\n\u001b[1;32m---> 21\u001b[0m sentiment_df[[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdeb_pos\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdeb_neg\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdeb_neu\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdeb_label\u001b[39m\u001b[38;5;124m'\u001b[39m]] \u001b[38;5;241m=\u001b[39m sentiment_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mheadline\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(get_sentiment)\u001b[38;5;241m.\u001b[39mapply(pd\u001b[38;5;241m.\u001b[39mSeries)\n\u001b[0;32m     23\u001b[0m \u001b[38;5;66;03m# Display the first few rows of the DataFrame to verify the results\u001b[39;00m\n\u001b[0;32m     24\u001b[0m sentiment_df\u001b[38;5;241m.\u001b[39mhead(\u001b[38;5;241m10\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Tammy\\anaconda3\\Lib\\site-packages\\pandas\\core\\series.py:4924\u001b[0m, in \u001b[0;36mSeries.apply\u001b[1;34m(self, func, convert_dtype, args, by_row, **kwargs)\u001b[0m\n\u001b[0;32m   4789\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply\u001b[39m(\n\u001b[0;32m   4790\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   4791\u001b[0m     func: AggFuncType,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4796\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   4797\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m Series:\n\u001b[0;32m   4798\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   4799\u001b[0m \u001b[38;5;124;03m    Invoke function on values of Series.\u001b[39;00m\n\u001b[0;32m   4800\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4915\u001b[0m \u001b[38;5;124;03m    dtype: float64\u001b[39;00m\n\u001b[0;32m   4916\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m   4917\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m SeriesApply(\n\u001b[0;32m   4918\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   4919\u001b[0m         func,\n\u001b[0;32m   4920\u001b[0m         convert_dtype\u001b[38;5;241m=\u001b[39mconvert_dtype,\n\u001b[0;32m   4921\u001b[0m         by_row\u001b[38;5;241m=\u001b[39mby_row,\n\u001b[0;32m   4922\u001b[0m         args\u001b[38;5;241m=\u001b[39margs,\n\u001b[0;32m   4923\u001b[0m         kwargs\u001b[38;5;241m=\u001b[39mkwargs,\n\u001b[1;32m-> 4924\u001b[0m     )\u001b[38;5;241m.\u001b[39mapply()\n",
      "File \u001b[1;32mc:\\Users\\Tammy\\anaconda3\\Lib\\site-packages\\pandas\\core\\apply.py:1427\u001b[0m, in \u001b[0;36mSeriesApply.apply\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1424\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_compat()\n\u001b[0;32m   1426\u001b[0m \u001b[38;5;66;03m# self.func is Callable\u001b[39;00m\n\u001b[1;32m-> 1427\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_standard()\n",
      "File \u001b[1;32mc:\\Users\\Tammy\\anaconda3\\Lib\\site-packages\\pandas\\core\\apply.py:1507\u001b[0m, in \u001b[0;36mSeriesApply.apply_standard\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1501\u001b[0m \u001b[38;5;66;03m# row-wise access\u001b[39;00m\n\u001b[0;32m   1502\u001b[0m \u001b[38;5;66;03m# apply doesn't have a `na_action` keyword and for backward compat reasons\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m \u001b[38;5;66;03m# we need to give `na_action=\"ignore\"` for categorical data.\u001b[39;00m\n\u001b[0;32m   1504\u001b[0m \u001b[38;5;66;03m# TODO: remove the `na_action=\"ignore\"` when that default has been changed in\u001b[39;00m\n\u001b[0;32m   1505\u001b[0m \u001b[38;5;66;03m#  Categorical (GH51645).\u001b[39;00m\n\u001b[0;32m   1506\u001b[0m action \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj\u001b[38;5;241m.\u001b[39mdtype, CategoricalDtype) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1507\u001b[0m mapped \u001b[38;5;241m=\u001b[39m obj\u001b[38;5;241m.\u001b[39m_map_values(\n\u001b[0;32m   1508\u001b[0m     mapper\u001b[38;5;241m=\u001b[39mcurried, na_action\u001b[38;5;241m=\u001b[39maction, convert\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconvert_dtype\n\u001b[0;32m   1509\u001b[0m )\n\u001b[0;32m   1511\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(mapped) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(mapped[\u001b[38;5;241m0\u001b[39m], ABCSeries):\n\u001b[0;32m   1512\u001b[0m     \u001b[38;5;66;03m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001b[39;00m\n\u001b[0;32m   1513\u001b[0m     \u001b[38;5;66;03m#  See also GH#25959 regarding EA support\u001b[39;00m\n\u001b[0;32m   1514\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m obj\u001b[38;5;241m.\u001b[39m_constructor_expanddim(\u001b[38;5;28mlist\u001b[39m(mapped), index\u001b[38;5;241m=\u001b[39mobj\u001b[38;5;241m.\u001b[39mindex)\n",
      "File \u001b[1;32mc:\\Users\\Tammy\\anaconda3\\Lib\\site-packages\\pandas\\core\\base.py:921\u001b[0m, in \u001b[0;36mIndexOpsMixin._map_values\u001b[1;34m(self, mapper, na_action, convert)\u001b[0m\n\u001b[0;32m    918\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(arr, ExtensionArray):\n\u001b[0;32m    919\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m arr\u001b[38;5;241m.\u001b[39mmap(mapper, na_action\u001b[38;5;241m=\u001b[39mna_action)\n\u001b[1;32m--> 921\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m algorithms\u001b[38;5;241m.\u001b[39mmap_array(arr, mapper, na_action\u001b[38;5;241m=\u001b[39mna_action, convert\u001b[38;5;241m=\u001b[39mconvert)\n",
      "File \u001b[1;32mc:\\Users\\Tammy\\anaconda3\\Lib\\site-packages\\pandas\\core\\algorithms.py:1743\u001b[0m, in \u001b[0;36mmap_array\u001b[1;34m(arr, mapper, na_action, convert)\u001b[0m\n\u001b[0;32m   1741\u001b[0m values \u001b[38;5;241m=\u001b[39m arr\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mobject\u001b[39m, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m na_action \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1743\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mmap_infer(values, mapper, convert\u001b[38;5;241m=\u001b[39mconvert)\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1745\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mmap_infer_mask(\n\u001b[0;32m   1746\u001b[0m         values, mapper, mask\u001b[38;5;241m=\u001b[39misna(values)\u001b[38;5;241m.\u001b[39mview(np\u001b[38;5;241m.\u001b[39muint8), convert\u001b[38;5;241m=\u001b[39mconvert\n\u001b[0;32m   1747\u001b[0m     )\n",
      "File \u001b[1;32mlib.pyx:2972\u001b[0m, in \u001b[0;36mpandas._libs.lib.map_infer\u001b[1;34m()\u001b[0m\n",
      "Cell \u001b[1;32mIn[11], line 9\u001b[0m, in \u001b[0;36mget_sentiment\u001b[1;34m(headline)\u001b[0m\n\u001b[0;32m      6\u001b[0m encoded_text \u001b[38;5;241m=\u001b[39m tokenizer(headline, return_tensors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m'\u001b[39m, padding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, truncation\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# Get the model's output (logits)\u001b[39;00m\n\u001b[1;32m----> 9\u001b[0m output \u001b[38;5;241m=\u001b[39m deb_model(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mencoded_text)\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# Apply softmax to get probabilities for each class (negative, neutral, positive)\u001b[39;00m\n\u001b[0;32m     12\u001b[0m probs \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mfunctional\u001b[38;5;241m.\u001b[39msoftmax(output\u001b[38;5;241m.\u001b[39mlogits, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Tammy\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Tammy\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\Tammy\\anaconda3\\Lib\\site-packages\\transformers\\models\\deberta_v2\\modeling_deberta_v2.py:1297\u001b[0m, in \u001b[0;36mDebertaV2ForSequenceClassification.forward\u001b[1;34m(self, input_ids, attention_mask, token_type_ids, position_ids, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m   1289\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1290\u001b[0m \u001b[38;5;124;03mlabels (`torch.LongTensor` of shape `(batch_size,)`, *optional*):\u001b[39;00m\n\u001b[0;32m   1291\u001b[0m \u001b[38;5;124;03m    Labels for computing the sequence classification/regression loss. Indices should be in `[0, ...,\u001b[39;00m\n\u001b[0;32m   1292\u001b[0m \u001b[38;5;124;03m    config.num_labels - 1]`. If `config.num_labels == 1` a regression loss is computed (Mean-Square loss), If\u001b[39;00m\n\u001b[0;32m   1293\u001b[0m \u001b[38;5;124;03m    `config.num_labels > 1` a classification loss is computed (Cross-Entropy).\u001b[39;00m\n\u001b[0;32m   1294\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1295\u001b[0m return_dict \u001b[38;5;241m=\u001b[39m return_dict \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39muse_return_dict\n\u001b[1;32m-> 1297\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdeberta(\n\u001b[0;32m   1298\u001b[0m     input_ids,\n\u001b[0;32m   1299\u001b[0m     token_type_ids\u001b[38;5;241m=\u001b[39mtoken_type_ids,\n\u001b[0;32m   1300\u001b[0m     attention_mask\u001b[38;5;241m=\u001b[39mattention_mask,\n\u001b[0;32m   1301\u001b[0m     position_ids\u001b[38;5;241m=\u001b[39mposition_ids,\n\u001b[0;32m   1302\u001b[0m     inputs_embeds\u001b[38;5;241m=\u001b[39minputs_embeds,\n\u001b[0;32m   1303\u001b[0m     output_attentions\u001b[38;5;241m=\u001b[39moutput_attentions,\n\u001b[0;32m   1304\u001b[0m     output_hidden_states\u001b[38;5;241m=\u001b[39moutput_hidden_states,\n\u001b[0;32m   1305\u001b[0m     return_dict\u001b[38;5;241m=\u001b[39mreturn_dict,\n\u001b[0;32m   1306\u001b[0m )\n\u001b[0;32m   1308\u001b[0m encoder_layer \u001b[38;5;241m=\u001b[39m outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m   1309\u001b[0m pooled_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpooler(encoder_layer)\n",
      "File \u001b[1;32mc:\\Users\\Tammy\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Tammy\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\Tammy\\anaconda3\\Lib\\site-packages\\transformers\\models\\deberta_v2\\modeling_deberta_v2.py:1063\u001b[0m, in \u001b[0;36mDebertaV2Model.forward\u001b[1;34m(self, input_ids, attention_mask, token_type_ids, position_ids, inputs_embeds, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m   1053\u001b[0m     token_type_ids \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mzeros(input_shape, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mlong, device\u001b[38;5;241m=\u001b[39mdevice)\n\u001b[0;32m   1055\u001b[0m embedding_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membeddings(\n\u001b[0;32m   1056\u001b[0m     input_ids\u001b[38;5;241m=\u001b[39minput_ids,\n\u001b[0;32m   1057\u001b[0m     token_type_ids\u001b[38;5;241m=\u001b[39mtoken_type_ids,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1060\u001b[0m     inputs_embeds\u001b[38;5;241m=\u001b[39minputs_embeds,\n\u001b[0;32m   1061\u001b[0m )\n\u001b[1;32m-> 1063\u001b[0m encoder_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencoder(\n\u001b[0;32m   1064\u001b[0m     embedding_output,\n\u001b[0;32m   1065\u001b[0m     attention_mask,\n\u001b[0;32m   1066\u001b[0m     output_hidden_states\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m   1067\u001b[0m     output_attentions\u001b[38;5;241m=\u001b[39moutput_attentions,\n\u001b[0;32m   1068\u001b[0m     return_dict\u001b[38;5;241m=\u001b[39mreturn_dict,\n\u001b[0;32m   1069\u001b[0m )\n\u001b[0;32m   1070\u001b[0m encoded_layers \u001b[38;5;241m=\u001b[39m encoder_outputs[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m   1072\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mz_steps \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\Tammy\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Tammy\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\Tammy\\anaconda3\\Lib\\site-packages\\transformers\\models\\deberta_v2\\modeling_deberta_v2.py:507\u001b[0m, in \u001b[0;36mDebertaV2Encoder.forward\u001b[1;34m(self, hidden_states, attention_mask, output_hidden_states, output_attentions, query_states, relative_pos, return_dict)\u001b[0m\n\u001b[0;32m    497\u001b[0m     output_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gradient_checkpointing_func(\n\u001b[0;32m    498\u001b[0m         layer_module\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m,\n\u001b[0;32m    499\u001b[0m         next_kv,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    504\u001b[0m         output_attentions,\n\u001b[0;32m    505\u001b[0m     )\n\u001b[0;32m    506\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 507\u001b[0m     output_states \u001b[38;5;241m=\u001b[39m layer_module(\n\u001b[0;32m    508\u001b[0m         next_kv,\n\u001b[0;32m    509\u001b[0m         attention_mask,\n\u001b[0;32m    510\u001b[0m         query_states\u001b[38;5;241m=\u001b[39mquery_states,\n\u001b[0;32m    511\u001b[0m         relative_pos\u001b[38;5;241m=\u001b[39mrelative_pos,\n\u001b[0;32m    512\u001b[0m         rel_embeddings\u001b[38;5;241m=\u001b[39mrel_embeddings,\n\u001b[0;32m    513\u001b[0m         output_attentions\u001b[38;5;241m=\u001b[39moutput_attentions,\n\u001b[0;32m    514\u001b[0m     )\n\u001b[0;32m    516\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m output_attentions:\n\u001b[0;32m    517\u001b[0m     output_states, att_m \u001b[38;5;241m=\u001b[39m output_states\n",
      "File \u001b[1;32mc:\\Users\\Tammy\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Tammy\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\Tammy\\anaconda3\\Lib\\site-packages\\transformers\\models\\deberta_v2\\modeling_deberta_v2.py:355\u001b[0m, in \u001b[0;36mDebertaV2Layer.forward\u001b[1;34m(self, hidden_states, attention_mask, query_states, relative_pos, rel_embeddings, output_attentions)\u001b[0m\n\u001b[0;32m    346\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\n\u001b[0;32m    347\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    348\u001b[0m     hidden_states,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    353\u001b[0m     output_attentions\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    354\u001b[0m ):\n\u001b[1;32m--> 355\u001b[0m     attention_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mattention(\n\u001b[0;32m    356\u001b[0m         hidden_states,\n\u001b[0;32m    357\u001b[0m         attention_mask,\n\u001b[0;32m    358\u001b[0m         output_attentions\u001b[38;5;241m=\u001b[39moutput_attentions,\n\u001b[0;32m    359\u001b[0m         query_states\u001b[38;5;241m=\u001b[39mquery_states,\n\u001b[0;32m    360\u001b[0m         relative_pos\u001b[38;5;241m=\u001b[39mrelative_pos,\n\u001b[0;32m    361\u001b[0m         rel_embeddings\u001b[38;5;241m=\u001b[39mrel_embeddings,\n\u001b[0;32m    362\u001b[0m     )\n\u001b[0;32m    363\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m output_attentions:\n\u001b[0;32m    364\u001b[0m         attention_output, att_matrix \u001b[38;5;241m=\u001b[39m attention_output\n",
      "File \u001b[1;32mc:\\Users\\Tammy\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Tammy\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\Tammy\\anaconda3\\Lib\\site-packages\\transformers\\models\\deberta_v2\\modeling_deberta_v2.py:286\u001b[0m, in \u001b[0;36mDebertaV2Attention.forward\u001b[1;34m(self, hidden_states, attention_mask, output_attentions, query_states, relative_pos, rel_embeddings)\u001b[0m\n\u001b[0;32m    277\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\n\u001b[0;32m    278\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    279\u001b[0m     hidden_states,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    284\u001b[0m     rel_embeddings\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    285\u001b[0m ):\n\u001b[1;32m--> 286\u001b[0m     self_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mself(\n\u001b[0;32m    287\u001b[0m         hidden_states,\n\u001b[0;32m    288\u001b[0m         attention_mask,\n\u001b[0;32m    289\u001b[0m         output_attentions,\n\u001b[0;32m    290\u001b[0m         query_states\u001b[38;5;241m=\u001b[39mquery_states,\n\u001b[0;32m    291\u001b[0m         relative_pos\u001b[38;5;241m=\u001b[39mrelative_pos,\n\u001b[0;32m    292\u001b[0m         rel_embeddings\u001b[38;5;241m=\u001b[39mrel_embeddings,\n\u001b[0;32m    293\u001b[0m     )\n\u001b[0;32m    294\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m output_attentions:\n\u001b[0;32m    295\u001b[0m         self_output, att_matrix \u001b[38;5;241m=\u001b[39m self_output\n",
      "File \u001b[1;32mc:\\Users\\Tammy\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Tammy\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\Tammy\\anaconda3\\Lib\\site-packages\\transformers\\models\\deberta_v2\\modeling_deberta_v2.py:700\u001b[0m, in \u001b[0;36mDisentangledSelfAttention.forward\u001b[1;34m(self, hidden_states, attention_mask, output_attentions, query_states, relative_pos, rel_embeddings)\u001b[0m\n\u001b[0;32m    698\u001b[0m     query_states \u001b[38;5;241m=\u001b[39m hidden_states\n\u001b[0;32m    699\u001b[0m query_layer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtranspose_for_scores(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mquery_proj(query_states), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_attention_heads)\n\u001b[1;32m--> 700\u001b[0m key_layer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtranspose_for_scores(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkey_proj(hidden_states), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_attention_heads)\n\u001b[0;32m    701\u001b[0m value_layer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtranspose_for_scores(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalue_proj(hidden_states), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_attention_heads)\n\u001b[0;32m    703\u001b[0m rel_att \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Tammy\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Tammy\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\Tammy\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\linear.py:125\u001b[0m, in \u001b[0;36mLinear.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    124\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 125\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mlinear(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweight, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Function to get sentiment and probabilities for negative, neutral, and positive\n",
    "def get_sentiment(headline):\n",
    "    # Tokenize the input headline\n",
    "    encoded_text = tokenizer(headline, return_tensors='pt', padding=True, truncation=True)\n",
    "    \n",
    "    # Get the model's output (logits)\n",
    "    output = deb_model(**encoded_text)\n",
    "    \n",
    "    # Apply softmax to get probabilities for each class (negative, neutral, positive)\n",
    "    probs = torch.nn.functional.softmax(output.logits, dim=-1)\n",
    "    \n",
    "    # Extract sentiment scores (negative, neutral, positive)\n",
    "    deb_neg, deb_neu, deb_pos = probs[0].detach().numpy()\n",
    "    \n",
    "    # Return sentiment scores as well as the label\n",
    "    return deb_neg, deb_neu, deb_pos, 'Negative' if deb_neg > deb_neu and deb_neg > deb_pos else ('Neutral' if deb_neu > deb_pos else 'Positive')\n",
    "\n",
    "# Apply the function to the 'headline' column and unpack the values into separate columns\n",
    "sentiment_df[['deb_pos', 'deb_neg', 'deb_neu', 'deb_label']] = sentiment_df['headline'].apply(get_sentiment).apply(pd.Series)\n",
    "\n",
    "# Display the first few rows of the DataFrame to verify the results\n",
    "sentiment_df.head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ticker</th>\n",
       "      <th>pub_date</th>\n",
       "      <th>headline</th>\n",
       "      <th>vader_pos</th>\n",
       "      <th>vader_neu</th>\n",
       "      <th>vader_neg</th>\n",
       "      <th>vader_label</th>\n",
       "      <th>drob_neg</th>\n",
       "      <th>drob_neu</th>\n",
       "      <th>drob_pos</th>\n",
       "      <th>drob_label</th>\n",
       "      <th>deb_pos</th>\n",
       "      <th>deb_neg</th>\n",
       "      <th>deb_neu</th>\n",
       "      <th>deb_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>2015-04-07</td>\n",
       "      <td>M.B.A. Programs That Get You Where You Want to Go</td>\n",
       "      <td>0.126</td>\n",
       "      <td>0.874</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Positive</td>\n",
       "      <td>0.021400</td>\n",
       "      <td>0.790080</td>\n",
       "      <td>0.188520</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>0.001556</td>\n",
       "      <td>0.910922</td>\n",
       "      <td>0.087523</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>2015-04-14</td>\n",
       "      <td>What We’re Reading</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>0.055277</td>\n",
       "      <td>0.798512</td>\n",
       "      <td>0.146211</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>0.012333</td>\n",
       "      <td>0.986333</td>\n",
       "      <td>0.001334</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>2015-04-13</td>\n",
       "      <td>IBM Creates Watson Health to Analyze Medical Data</td>\n",
       "      <td>0.231</td>\n",
       "      <td>0.769</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Positive</td>\n",
       "      <td>0.015715</td>\n",
       "      <td>0.696537</td>\n",
       "      <td>0.287748</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>0.001769</td>\n",
       "      <td>0.969001</td>\n",
       "      <td>0.029229</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>2015-04-22</td>\n",
       "      <td>What’s That on Beyoncé’s Wrist? Let Me Guess ....</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>0.042261</td>\n",
       "      <td>0.861066</td>\n",
       "      <td>0.096673</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>0.059633</td>\n",
       "      <td>0.933838</td>\n",
       "      <td>0.006529</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>2015-04-01</td>\n",
       "      <td>Daily Report: Tech Leaders Come Together to Op...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>0.506060</td>\n",
       "      <td>0.291502</td>\n",
       "      <td>0.202438</td>\n",
       "      <td>Negative</td>\n",
       "      <td>0.910898</td>\n",
       "      <td>0.066995</td>\n",
       "      <td>0.022107</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  ticker    pub_date                                           headline  \\\n",
       "0   AAPL  2015-04-07  M.B.A. Programs That Get You Where You Want to Go   \n",
       "1   AAPL  2015-04-14                                 What We’re Reading   \n",
       "2   AAPL  2015-04-13  IBM Creates Watson Health to Analyze Medical Data   \n",
       "3   AAPL  2015-04-22  What’s That on Beyoncé’s Wrist? Let Me Guess ....   \n",
       "4   AAPL  2015-04-01  Daily Report: Tech Leaders Come Together to Op...   \n",
       "\n",
       "   vader_pos  vader_neu  vader_neg vader_label  drob_neg  drob_neu  drob_pos  \\\n",
       "0      0.126      0.874        0.0    Positive  0.021400  0.790080  0.188520   \n",
       "1      0.000      1.000        0.0     Neutral  0.055277  0.798512  0.146211   \n",
       "2      0.231      0.769        0.0    Positive  0.015715  0.696537  0.287748   \n",
       "3      0.000      1.000        0.0     Neutral  0.042261  0.861066  0.096673   \n",
       "4      0.000      1.000        0.0     Neutral  0.506060  0.291502  0.202438   \n",
       "\n",
       "  drob_label   deb_pos   deb_neg   deb_neu deb_label  \n",
       "0    Neutral  0.001556  0.910922  0.087523   Neutral  \n",
       "1    Neutral  0.012333  0.986333  0.001334   Neutral  \n",
       "2    Neutral  0.001769  0.969001  0.029229   Neutral  \n",
       "3    Neutral  0.059633  0.933838  0.006529   Neutral  \n",
       "4   Negative  0.910898  0.066995  0.022107  Negative  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the DataFrame to a CSV file just in case \n",
    "sentiment_df.to_csv('finetuned_sentiment_model.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run abstract through all 5 models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ticker</th>\n",
       "      <th>pub_date</th>\n",
       "      <th>abstract</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>2015-01-05</td>\n",
       "      <td>You can adjust your settings so that only cert...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>2015-01-05</td>\n",
       "      <td>It’s time to take note of what lies at the top...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>2015-01-06</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>2015-01-07</td>\n",
       "      <td>With apps able to act as cameras, media player...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>2015-01-08</td>\n",
       "      <td>Google’s app store is the largest in the world...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  ticker    pub_date                                           abstract\n",
       "0   AAPL  2015-01-05  You can adjust your settings so that only cert...\n",
       "1   AAPL  2015-01-05  It’s time to take note of what lies at the top...\n",
       "2   AAPL  2015-01-06                                                   \n",
       "3   AAPL  2015-01-07  With apps able to act as cameras, media player...\n",
       "4   AAPL  2015-01-08  Google’s app store is the largest in the world..."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#narrowing down to headlines and abstract\n",
    "# Select the desired columns\n",
    "sentiment_df = df[['ticker', 'pub_date', 'abstract']]\n",
    "sentiment_df = sentiment_df.copy()  # Make a copy to avoid modifications on a slice\n",
    "sentiment_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Vader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     /Users/trinatan/nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "nltk.download('vader_lexicon')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ticker</th>\n",
       "      <th>pub_date</th>\n",
       "      <th>abstract</th>\n",
       "      <th>vader_pos</th>\n",
       "      <th>vader_neu</th>\n",
       "      <th>vader_neg</th>\n",
       "      <th>vader_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>2015-01-05</td>\n",
       "      <td>You can adjust your settings so that only cert...</td>\n",
       "      <td>0.106</td>\n",
       "      <td>0.894</td>\n",
       "      <td>0.000</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>2015-01-05</td>\n",
       "      <td>It’s time to take note of what lies at the top...</td>\n",
       "      <td>0.092</td>\n",
       "      <td>0.765</td>\n",
       "      <td>0.143</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>2015-01-06</td>\n",
       "      <td></td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>2015-01-07</td>\n",
       "      <td>With apps able to act as cameras, media player...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.912</td>\n",
       "      <td>0.088</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>2015-01-08</td>\n",
       "      <td>Google’s app store is the largest in the world...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  ticker    pub_date                                           abstract  \\\n",
       "0   AAPL  2015-01-05  You can adjust your settings so that only cert...   \n",
       "1   AAPL  2015-01-05  It’s time to take note of what lies at the top...   \n",
       "2   AAPL  2015-01-06                                                      \n",
       "3   AAPL  2015-01-07  With apps able to act as cameras, media player...   \n",
       "4   AAPL  2015-01-08  Google’s app store is the largest in the world...   \n",
       "\n",
       "   vader_pos  vader_neu  vader_neg vader_label  \n",
       "0      0.106      0.894      0.000    Positive  \n",
       "1      0.092      0.765      0.143    Negative  \n",
       "2      0.000      0.000      0.000     Neutral  \n",
       "3      0.000      0.912      0.088    Negative  \n",
       "4      0.000      1.000      0.000     Neutral  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run model\n",
    "sia = SentimentIntensityAnalyzer()\n",
    "\n",
    "# Function to get full sentiment scores (including probabilities)\n",
    "def get_sentiment(text):\n",
    "    # Get the sentiment scores dictionary (positive, neutral, negative, and compound scores)\n",
    "    sentiment_scores = sia.polarity_scores(text)\n",
    "    return sentiment_scores\n",
    "\n",
    "# Apply the sentiment analysis to the 'headline' column\n",
    "sentiment_df['sentiment_scores'] = sentiment_df['abstract'].apply(get_sentiment)\n",
    "\n",
    "# Separate out the individual sentiment probabilities into new columns\n",
    "sentiment_df['vader_pos'] = sentiment_df['sentiment_scores'].apply(lambda x: x['pos'])\n",
    "sentiment_df['vader_neu'] = sentiment_df['sentiment_scores'].apply(lambda x: x['neu'])\n",
    "sentiment_df['vader_neg'] = sentiment_df['sentiment_scores'].apply(lambda x: x['neg'])\n",
    "\n",
    "# Function to classify sentiment into Positive, Negative, or Neutral based on the compound score\n",
    "def classify_sentiment(score):\n",
    "    if score > 0.05:\n",
    "        return 'Positive'\n",
    "    elif score < -0.05:\n",
    "        return 'Negative'\n",
    "    else:\n",
    "        return 'Neutral'\n",
    "\n",
    "# Apply the compound score to classify sentiment\n",
    "sentiment_df['vader_label'] = sentiment_df['sentiment_scores'].apply(lambda x: classify_sentiment(x['compound']))\n",
    "\n",
    "# Display the result\n",
    "# Drop the 'sentiment_scores' column from the DataFrame\n",
    "sentiment_df = sentiment_df.drop(columns=['sentiment_scores'])\n",
    "\n",
    "# Display the result\n",
    "sentiment_df.head(5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Transformer (distilRoBERTa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/MLApps/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"frostedtrees/Fin_distilroberta\")\n",
    "drob_model = AutoModelForSequenceClassification.from_pretrained(\"frostedtrees/Fin_distilroberta\", num_labels=3)  # Assuming 3 sentiments: positive, neutral, negative\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ticker</th>\n",
       "      <th>pub_date</th>\n",
       "      <th>abstract</th>\n",
       "      <th>vader_pos</th>\n",
       "      <th>vader_neu</th>\n",
       "      <th>vader_neg</th>\n",
       "      <th>vader_label</th>\n",
       "      <th>drob_neg</th>\n",
       "      <th>drob_neu</th>\n",
       "      <th>drob_pos</th>\n",
       "      <th>drob_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>2015-01-05</td>\n",
       "      <td>You can adjust your settings so that only cert...</td>\n",
       "      <td>0.106</td>\n",
       "      <td>0.894</td>\n",
       "      <td>0.000</td>\n",
       "      <td>Positive</td>\n",
       "      <td>0.075523</td>\n",
       "      <td>0.807759</td>\n",
       "      <td>0.116718</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>2015-01-05</td>\n",
       "      <td>It’s time to take note of what lies at the top...</td>\n",
       "      <td>0.092</td>\n",
       "      <td>0.765</td>\n",
       "      <td>0.143</td>\n",
       "      <td>Negative</td>\n",
       "      <td>0.066431</td>\n",
       "      <td>0.663510</td>\n",
       "      <td>0.270059</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>2015-01-06</td>\n",
       "      <td></td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>0.026959</td>\n",
       "      <td>0.898535</td>\n",
       "      <td>0.074505</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>2015-01-07</td>\n",
       "      <td>With apps able to act as cameras, media player...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.912</td>\n",
       "      <td>0.088</td>\n",
       "      <td>Negative</td>\n",
       "      <td>0.787576</td>\n",
       "      <td>0.128845</td>\n",
       "      <td>0.083579</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>2015-01-08</td>\n",
       "      <td>Google’s app store is the largest in the world...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>0.593591</td>\n",
       "      <td>0.319998</td>\n",
       "      <td>0.086411</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  ticker    pub_date                                           abstract  \\\n",
       "0   AAPL  2015-01-05  You can adjust your settings so that only cert...   \n",
       "1   AAPL  2015-01-05  It’s time to take note of what lies at the top...   \n",
       "2   AAPL  2015-01-06                                                      \n",
       "3   AAPL  2015-01-07  With apps able to act as cameras, media player...   \n",
       "4   AAPL  2015-01-08  Google’s app store is the largest in the world...   \n",
       "\n",
       "   vader_pos  vader_neu  vader_neg vader_label  drob_neg  drob_neu  drob_pos  \\\n",
       "0      0.106      0.894      0.000    Positive  0.075523  0.807759  0.116718   \n",
       "1      0.092      0.765      0.143    Negative  0.066431  0.663510  0.270059   \n",
       "2      0.000      0.000      0.000     Neutral  0.026959  0.898535  0.074505   \n",
       "3      0.000      0.912      0.088    Negative  0.787576  0.128845  0.083579   \n",
       "4      0.000      1.000      0.000     Neutral  0.593591  0.319998  0.086411   \n",
       "\n",
       "  drob_label  \n",
       "0    Neutral  \n",
       "1    Neutral  \n",
       "2    Neutral  \n",
       "3   Negative  \n",
       "4   Negative  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "def predict_sentiment(headline):\n",
    "    inputs = tokenizer(headline, return_tensors=\"pt\", truncation=True, padding=True)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = drob_model(**inputs)\n",
    "    \n",
    "    logits = outputs.logits\n",
    "    probs = torch.softmax(logits, dim=-1)  # Convert logits to probabilities\n",
    "    \n",
    "    return probs[0].cpu().numpy()  # Returns an array of probabilities\n",
    "\n",
    "# Apply prediction to DataFrame\n",
    "sentiment_probs = sentiment_df['abstract'].apply(predict_sentiment)\n",
    "\n",
    "# Create separate columns for sentiment probabilities\n",
    "sentiment_df[['drob_neg', 'drob_neu', 'drob_pos']] = pd.DataFrame(sentiment_probs.tolist(), index=sentiment_probs.index)\n",
    "\n",
    "# Determine final sentiment label based on highest probability and simplify label mapping\n",
    "sentiment_df['drob_label'] = sentiment_df[['drob_neg', 'drob_neu', 'drob_pos']].idxmax(axis=1)\n",
    "sentiment_df['drob_label'] = sentiment_df['drob_label'].replace({\n",
    "    'drob_pos': 'Positive',\n",
    "    'drob_neu': 'Neutral',\n",
    "    'drob_neg': 'Negative'\n",
    "})\n",
    "\n",
    "sentiment_df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Transformer (DeBerta)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"tammiloveshf/Fin_DeBerta\")\n",
    "deb_model = AutoModelForSequenceClassification.from_pretrained(\"tammiloveshf/Fin_DeBerta\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ticker</th>\n",
       "      <th>pub_date</th>\n",
       "      <th>abstract</th>\n",
       "      <th>vader_pos</th>\n",
       "      <th>vader_neu</th>\n",
       "      <th>vader_neg</th>\n",
       "      <th>vader_label</th>\n",
       "      <th>drob_neg</th>\n",
       "      <th>drob_neu</th>\n",
       "      <th>drob_pos</th>\n",
       "      <th>drob_label</th>\n",
       "      <th>deb_pos</th>\n",
       "      <th>deb_neg</th>\n",
       "      <th>deb_neu</th>\n",
       "      <th>deb_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>2015-01-05</td>\n",
       "      <td>You can adjust your settings so that only cert...</td>\n",
       "      <td>0.106</td>\n",
       "      <td>0.894</td>\n",
       "      <td>0.000</td>\n",
       "      <td>Positive</td>\n",
       "      <td>0.075523</td>\n",
       "      <td>0.807759</td>\n",
       "      <td>0.116718</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>0.000852</td>\n",
       "      <td>0.988287</td>\n",
       "      <td>0.010861</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>2015-01-05</td>\n",
       "      <td>It’s time to take note of what lies at the top...</td>\n",
       "      <td>0.092</td>\n",
       "      <td>0.765</td>\n",
       "      <td>0.143</td>\n",
       "      <td>Negative</td>\n",
       "      <td>0.066431</td>\n",
       "      <td>0.663510</td>\n",
       "      <td>0.270059</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>0.001523</td>\n",
       "      <td>0.985242</td>\n",
       "      <td>0.013235</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>2015-01-06</td>\n",
       "      <td></td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>0.026959</td>\n",
       "      <td>0.898535</td>\n",
       "      <td>0.074505</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>0.072680</td>\n",
       "      <td>0.207977</td>\n",
       "      <td>0.719343</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>2015-01-07</td>\n",
       "      <td>With apps able to act as cameras, media player...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.912</td>\n",
       "      <td>0.088</td>\n",
       "      <td>Negative</td>\n",
       "      <td>0.787576</td>\n",
       "      <td>0.128845</td>\n",
       "      <td>0.083579</td>\n",
       "      <td>Negative</td>\n",
       "      <td>0.025295</td>\n",
       "      <td>0.898772</td>\n",
       "      <td>0.075933</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>2015-01-08</td>\n",
       "      <td>Google’s app store is the largest in the world...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>0.593591</td>\n",
       "      <td>0.319998</td>\n",
       "      <td>0.086411</td>\n",
       "      <td>Negative</td>\n",
       "      <td>0.110893</td>\n",
       "      <td>0.643165</td>\n",
       "      <td>0.245942</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>2015-01-09</td>\n",
       "      <td>Facebook eventually reverts to the “Top Storie...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>0.094106</td>\n",
       "      <td>0.804785</td>\n",
       "      <td>0.101109</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>0.080449</td>\n",
       "      <td>0.860113</td>\n",
       "      <td>0.059438</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>2015-01-12</td>\n",
       "      <td></td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>0.026959</td>\n",
       "      <td>0.898535</td>\n",
       "      <td>0.074505</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>0.072680</td>\n",
       "      <td>0.207977</td>\n",
       "      <td>0.719343</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>2015-01-13</td>\n",
       "      <td></td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>0.026959</td>\n",
       "      <td>0.898535</td>\n",
       "      <td>0.074505</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>0.072680</td>\n",
       "      <td>0.207977</td>\n",
       "      <td>0.719343</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>2015-01-14</td>\n",
       "      <td>Apple, Google, Intel and Adobe say a new deal ...</td>\n",
       "      <td>0.070</td>\n",
       "      <td>0.800</td>\n",
       "      <td>0.130</td>\n",
       "      <td>Negative</td>\n",
       "      <td>0.258490</td>\n",
       "      <td>0.338560</td>\n",
       "      <td>0.402950</td>\n",
       "      <td>Positive</td>\n",
       "      <td>0.004473</td>\n",
       "      <td>0.043939</td>\n",
       "      <td>0.951588</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>2015-01-14</td>\n",
       "      <td>Apple, Google, Intel and Adobe are said to be ...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.901</td>\n",
       "      <td>0.099</td>\n",
       "      <td>Negative</td>\n",
       "      <td>0.049437</td>\n",
       "      <td>0.630534</td>\n",
       "      <td>0.320029</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>0.043262</td>\n",
       "      <td>0.134464</td>\n",
       "      <td>0.822274</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  ticker    pub_date                                           abstract  \\\n",
       "0   AAPL  2015-01-05  You can adjust your settings so that only cert...   \n",
       "1   AAPL  2015-01-05  It’s time to take note of what lies at the top...   \n",
       "2   AAPL  2015-01-06                                                      \n",
       "3   AAPL  2015-01-07  With apps able to act as cameras, media player...   \n",
       "4   AAPL  2015-01-08  Google’s app store is the largest in the world...   \n",
       "5   AAPL  2015-01-09  Facebook eventually reverts to the “Top Storie...   \n",
       "6   AAPL  2015-01-12                                                      \n",
       "7   AAPL  2015-01-13                                                      \n",
       "8   AAPL  2015-01-14  Apple, Google, Intel and Adobe say a new deal ...   \n",
       "9   AAPL  2015-01-14  Apple, Google, Intel and Adobe are said to be ...   \n",
       "\n",
       "   vader_pos  vader_neu  vader_neg vader_label  drob_neg  drob_neu  drob_pos  \\\n",
       "0      0.106      0.894      0.000    Positive  0.075523  0.807759  0.116718   \n",
       "1      0.092      0.765      0.143    Negative  0.066431  0.663510  0.270059   \n",
       "2      0.000      0.000      0.000     Neutral  0.026959  0.898535  0.074505   \n",
       "3      0.000      0.912      0.088    Negative  0.787576  0.128845  0.083579   \n",
       "4      0.000      1.000      0.000     Neutral  0.593591  0.319998  0.086411   \n",
       "5      0.000      1.000      0.000     Neutral  0.094106  0.804785  0.101109   \n",
       "6      0.000      0.000      0.000     Neutral  0.026959  0.898535  0.074505   \n",
       "7      0.000      0.000      0.000     Neutral  0.026959  0.898535  0.074505   \n",
       "8      0.070      0.800      0.130    Negative  0.258490  0.338560  0.402950   \n",
       "9      0.000      0.901      0.099    Negative  0.049437  0.630534  0.320029   \n",
       "\n",
       "  drob_label   deb_pos   deb_neg   deb_neu deb_label  \n",
       "0    Neutral  0.000852  0.988287  0.010861   Neutral  \n",
       "1    Neutral  0.001523  0.985242  0.013235   Neutral  \n",
       "2    Neutral  0.072680  0.207977  0.719343  Positive  \n",
       "3   Negative  0.025295  0.898772  0.075933   Neutral  \n",
       "4   Negative  0.110893  0.643165  0.245942   Neutral  \n",
       "5    Neutral  0.080449  0.860113  0.059438   Neutral  \n",
       "6    Neutral  0.072680  0.207977  0.719343  Positive  \n",
       "7    Neutral  0.072680  0.207977  0.719343  Positive  \n",
       "8   Positive  0.004473  0.043939  0.951588  Positive  \n",
       "9    Neutral  0.043262  0.134464  0.822274  Positive  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Function to get sentiment and probabilities for negative, neutral, and positive\n",
    "def get_sentiment(abstract):\n",
    "    # Tokenize the input abstract\n",
    "    encoded_text = tokenizer(abstract, return_tensors='pt', padding=True, truncation=True)\n",
    "    \n",
    "    # Get the model's output (logits)\n",
    "    output = deb_model(**encoded_text)\n",
    "    \n",
    "    # Apply softmax to get probabilities for each class (negative, neutral, positive)\n",
    "    probs = torch.nn.functional.softmax(output.logits, dim=-1)\n",
    "    \n",
    "    # Extract sentiment scores (negative, neutral, positive)\n",
    "    deb_neg, deb_neu, deb_pos = probs[0].detach().numpy()\n",
    "    \n",
    "    # Return sentiment scores as well as the label\n",
    "    return deb_neg, deb_neu, deb_pos, 'Negative' if deb_neg > deb_neu and deb_neg > deb_pos else ('Neutral' if deb_neu > deb_pos else 'Positive')\n",
    "\n",
    "# Apply the function to the 'abstract' column and unpack the values into separate columns\n",
    "sentiment_df[['deb_pos', 'deb_neg', 'deb_neu', 'deb_label']] = sentiment_df['abstract'].apply(get_sentiment).apply(pd.Series)\n",
    "\n",
    "# Display the first few rows of the DataFrame to verify the results\n",
    "sentiment_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export to csv\n",
    "'../../../data/clean/multimodal_inputs/llm_text_data_processed_abstract_AAPL.json'\n",
    "sentiment_df.to_csv('../../../data/clean/sentiment_analysis_results/finetuned_sentiment_analysis_abstract_AAPL.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MLApps",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
