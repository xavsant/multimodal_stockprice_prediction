{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NYTimes News Data\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "\n",
    "# Utility\n",
    "from pathlib import Path\n",
    "from os import path\n",
    "import json\n",
    "import time\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_filepaths(directory_path: str):\n",
    "    # Get all .json files (including subdirectories) that do not start with 'fulltext'\n",
    "    json_filepaths = [str(file) for file in Path(directory_path).rglob(\"*.json\") if not file.name.startswith(\"fulltext\")]\n",
    "\n",
    "    return json_filepaths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_scraped_files(directory_path: str):\n",
    "    # Get all .json files without 'fulltext' prefix\n",
    "    json_filepaths = [str(file) for file in Path(directory_path).rglob(\"*.json\") if not file.name.startswith(\"fulltext\")]\n",
    "    \n",
    "    # Create a set of filenames of fulltext files\n",
    "    fulltext_files = {str(file).replace(\"fulltext_\", \"\") for file in Path(directory_path).rglob(\"fulltext_*.json\")}\n",
    "    \n",
    "    # Filter out files that have a corresponding fulltext version\n",
    "    remaining_files = [file for file in json_filepaths if file not in fulltext_files]\n",
    "    \n",
    "    return remaining_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_json(filepath: str, export_file: list[dict], verbose: bool):\n",
    "    # Modify filepath for export\n",
    "    directory, filename = path.split(filepath)\n",
    "    export_filename = f\"fulltext_{filename}\"\n",
    "    export_filepath = path.join(directory, export_filename)\n",
    "\n",
    "    # Export as .json\n",
    "    with open(export_filepath, 'w') as json_file:\n",
    "        json.dump(export_file, json_file, indent=4)\n",
    "\n",
    "    if verbose:\n",
    "        print(f\"Processed '{export_filepath}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fall_back_scrape_full_text(url: str):\n",
    "    # Fall-back\n",
    "    # Load HTML content\n",
    "    response_fallback = requests.get(url)\n",
    "\n",
    "    # Create a BeautifulSoup object\n",
    "    soup_fallback = BeautifulSoup(response_fallback.text, 'html.parser')\n",
    "\n",
    "    # Extract text from HTML\n",
    "    article_container = soup_fallback.find('article')\n",
    "\n",
    "    # Extract text from found element\n",
    "    if article_container:\n",
    "        full_text = \"\\n\".join([p.get_text(strip=True) for p in article_container.find_all('p')])  # Extract paragraphs\n",
    "    else:\n",
    "        full_text = \"Article content not found\"\n",
    "\n",
    "    return full_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_nyt_url(json_filepaths: list[str]):\n",
    "    for file in json_filepaths:\n",
    "        # Open .json\n",
    "        with open(file, \"r\") as f:\n",
    "            response = json.load(f)  # Load JSON data into a dictionary\n",
    "\n",
    "        # ---\n",
    "\n",
    "        # Get all web urls\n",
    "        web_url_list = [article['web_url'] for article in response['response']['docs']]\n",
    "\n",
    "        # List to store article data for export\n",
    "        list_of_dict = []\n",
    "\n",
    "        # ---\n",
    "        \n",
    "        # Iterate through web urls\n",
    "        for url in web_url_list:\n",
    "            # Define cookies\n",
    "            cookies = {\n",
    "                'NYT-S': '0^CBoSMgjA89K9BhCXytW9BhoSMS3vHQ4I8sRMXKS37rBEiuLmIJyp_IIBKgIeVTjogcO9BkIAGkBmO6AJFtSiXUdFrL50D0JoH5sHkKVbO19xpSjKgTTkpxBPM9e7MHrS1G-EytgLWjjyD9ZkaBAJXgUfltOY8TEN',\n",
    "                'nyt-a': 'jp4fDxi0FZZqELYzNbf4yQ'\n",
    "            }\n",
    "\n",
    "            headers = {\n",
    "                \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/110.0.0.0 Safari/537.36\"\n",
    "            }\n",
    "\n",
    "            # Use session with cookies\n",
    "            session = requests.Session()\n",
    "            response = session.get(url, headers=headers, cookies=cookies)\n",
    "\n",
    "            # Parse the content\n",
    "            soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "            # Extract title (either <h1> or <title>)\n",
    "            title = soup.find('h1')\n",
    "            if not title:\n",
    "                title = soup.find('title')\n",
    "\n",
    "            # Extract full article text (either from <section> or <article>)\n",
    "            article_container = soup.find('section', {'name': 'articleBody'} or soup.find('article'))\n",
    "            if article_container:\n",
    "                full_text = \"\\n\".join([p.get_text(strip=True) for p in article_container.find_all('p')])  # Extract paragraphs\n",
    "            else:\n",
    "                # Fall-back\n",
    "                full_text = fall_back_scrape_full_text(url)\n",
    "\n",
    "            # Prepare result as a dictionary\n",
    "            result = {\n",
    "                'url': url,\n",
    "                'title': title.get_text(strip=True) if title else 'Title not found',\n",
    "                'fulltext': full_text\n",
    "            }\n",
    "\n",
    "            list_of_dict.append(result)\n",
    "\n",
    "            # Introduce a random delay between 1 and 3 seconds\n",
    "            time.sleep(random.uniform(1, 3))\n",
    "\n",
    "        to_json(filepath=file, export_file=list_of_dict, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "102\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['../../data/raw/2021/organizations_Apple_Inc_mth08_pg1.json',\n",
       " '../../data/raw/2021/organizations_Apple_Inc_mth09_pg2.json',\n",
       " '../../data/raw/2021/organizations_Apple_Inc_mth07_pg0.json']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get filepaths\n",
    "# json_filepaths = get_filepaths(directory_path = \"../../data/raw/\")\n",
    "# print(len(json_filepaths))\n",
    "# json_filepaths[0:3]\n",
    "\n",
    "# Get remaining filepaths\n",
    "json_filepaths = filter_scraped_files(directory_path = \"../../data/raw/\")\n",
    "print(len(json_filepaths))\n",
    "json_filepaths[0:3]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 'fulltext_organizations_Apple_Inc_mth08_pg1.json'\n",
      "Processed 'fulltext_organizations_Apple_Inc_mth09_pg2.json'\n",
      "Processed 'fulltext_organizations_Apple_Inc_mth07_pg0.json'\n",
      "Processed 'fulltext_organizations_Apple_Inc_mth06_pg0.json'\n",
      "Processed 'fulltext_organizations_Apple_Inc_mth10_pg1.json'\n",
      "Processed 'fulltext_organizations_Apple_Inc_mth10_pg0.json'\n",
      "Processed 'fulltext_organizations_Apple_Inc_mth11_pg0.json'\n",
      "Processed 'fulltext_organizations_Apple_Inc_mth07_pg1.json'\n",
      "Processed 'fulltext_organizations_Apple_Inc_mth06_pg1.json'\n",
      "Processed 'fulltext_organizations_Apple_Inc_mth09_pg3.json'\n",
      "Processed 'fulltext_organizations_Apple_Inc_mth01_pg0.json'\n",
      "Processed 'fulltext_organizations_Apple_Inc_mth04_pg1.json'\n",
      "Processed 'fulltext_organizations_Apple_Inc_mth12_pg0.json'\n",
      "Processed 'fulltext_organizations_Apple_Inc_mth12_pg1.json'\n",
      "Processed 'fulltext_organizations_Apple_Inc_mth01_pg2.json'\n",
      "Processed 'fulltext_organizations_Apple_Inc_mth04_pg0.json'\n",
      "Processed 'fulltext_organizations_Apple_Inc_mth05_pg0.json'\n",
      "Processed 'fulltext_organizations_Apple_Inc_mth07_pg2.json'\n",
      "Processed 'fulltext_organizations_Apple_Inc_mth09_pg0.json'\n",
      "Processed 'fulltext_organizations_Apple_Inc_mth08_pg0.json'\n",
      "Processed 'fulltext_organizations_Apple_Inc_mth03_pg0.json'\n",
      "Processed 'fulltext_organizations_Apple_Inc_mth02_pg0.json'\n",
      "Processed 'fulltext_organizations_Apple_Inc_mth10_pg2.json'\n",
      "Processed 'fulltext_organizations_Apple_Inc_mth02_pg1.json'\n",
      "Processed 'fulltext_organizations_Apple_Inc_mth09_pg1.json'\n",
      "Processed 'fulltext_organizations_Apple_Inc_mth08_pg1.json'\n",
      "Processed 'fulltext_organizations_Apple_Inc_mth07_pg3.json'\n",
      "Processed 'fulltext_organizations_Apple_Inc_mth07_pg0.json'\n",
      "Processed 'fulltext_organizations_Apple_Inc_mth06_pg0.json'\n",
      "Processed 'fulltext_organizations_Apple_Inc_mth10_pg1.json'\n",
      "Processed 'fulltext_organizations_Apple_Inc_mth10_pg0.json'\n",
      "Processed 'fulltext_organizations_Apple_Inc_mth11_pg0.json'\n",
      "Processed 'fulltext_organizations_Apple_Inc_mth07_pg1.json'\n",
      "Processed 'fulltext_organizations_Apple_Inc_mth06_pg1.json'\n",
      "Processed 'fulltext_organizations_Apple_Inc_mth01_pg1.json'\n",
      "Processed 'fulltext_organizations_Apple_Inc_mth01_pg0.json'\n",
      "Processed 'fulltext_organizations_Apple_Inc_mth05_pg1.json'\n",
      "Processed 'fulltext_organizations_Apple_Inc_mth12_pg0.json'\n",
      "Processed 'fulltext_organizations_Apple_Inc_mth12_pg1.json'\n",
      "Processed 'fulltext_organizations_Apple_Inc_mth01_pg2.json'\n",
      "Processed 'fulltext_organizations_Apple_Inc_mth04_pg0.json'\n",
      "Processed 'fulltext_organizations_Apple_Inc_mth05_pg0.json'\n",
      "Processed 'fulltext_organizations_Apple_Inc_mth09_pg0.json'\n",
      "Processed 'fulltext_organizations_Apple_Inc_mth08_pg0.json'\n",
      "Processed 'fulltext_organizations_Apple_Inc_mth03_pg0.json'\n",
      "Processed 'fulltext_organizations_Apple_Inc_mth02_pg0.json'\n",
      "Processed 'fulltext_organizations_Apple_Inc_mth03_pg1.json'\n",
      "Processed 'fulltext_organizations_Apple_Inc_mth09_pg1.json'\n",
      "Processed 'fulltext_organizations_Apple_Inc_mth08_pg1.json'\n",
      "Processed 'fulltext_organizations_Apple_Inc_mth07_pg0.json'\n",
      "Processed 'fulltext_organizations_Apple_Inc_mth06_pg0.json'\n",
      "Processed 'fulltext_organizations_Apple_Inc_mth11_pg1.json'\n",
      "Processed 'fulltext_organizations_Apple_Inc_mth10_pg0.json'\n",
      "Processed 'fulltext_organizations_Apple_Inc_mth11_pg0.json'\n",
      "Processed 'fulltext_organizations_Apple_Inc_mth06_pg1.json'\n",
      "Processed 'fulltext_organizations_Apple_Inc_mth01_pg1.json'\n",
      "Processed 'fulltext_organizations_Apple_Inc_mth01_pg0.json'\n",
      "Processed 'fulltext_organizations_Apple_Inc_mth04_pg1.json'\n",
      "Processed 'fulltext_organizations_Apple_Inc_mth05_pg1.json'\n",
      "Processed 'fulltext_organizations_Apple_Inc_mth02_pg6.json'\n",
      "Processed 'fulltext_organizations_Apple_Inc_mth03_pg6.json'\n",
      "Processed 'fulltext_organizations_Apple_Inc_mth12_pg0.json'\n",
      "Processed 'fulltext_organizations_Apple_Inc_mth12_pg1.json'\n",
      "Processed 'fulltext_organizations_Apple_Inc_mth01_pg2.json'\n",
      "Processed 'fulltext_organizations_Apple_Inc_mth02_pg7.json'\n",
      "Processed 'fulltext_organizations_Apple_Inc_mth03_pg7.json'\n",
      "Processed 'fulltext_organizations_Apple_Inc_mth04_pg0.json'\n",
      "Processed 'fulltext_organizations_Apple_Inc_mth05_pg0.json'\n",
      "Processed 'fulltext_organizations_Apple_Inc_mth06_pg2.json'\n",
      "Processed 'fulltext_organizations_Apple_Inc_mth09_pg0.json'\n",
      "Processed 'fulltext_organizations_Apple_Inc_mth08_pg0.json'\n",
      "Processed 'fulltext_organizations_Apple_Inc_mth03_pg0.json'\n",
      "Processed 'fulltext_organizations_Apple_Inc_mth02_pg0.json'\n",
      "Processed 'fulltext_organizations_Apple_Inc_mth03_pg1.json'\n",
      "Processed 'fulltext_organizations_Apple_Inc_mth02_pg1.json'\n",
      "Processed 'fulltext_organizations_Apple_Inc_mth09_pg1.json'\n",
      "Processed 'fulltext_organizations_Apple_Inc_mth08_pg1.json'\n",
      "Processed 'fulltext_organizations_Apple_Inc_mth08_pg2.json'\n",
      "Processed 'fulltext_organizations_Apple_Inc_mth09_pg2.json'\n",
      "Processed 'fulltext_organizations_Apple_Inc_mth07_pg0.json'\n",
      "Processed 'fulltext_organizations_Apple_Inc_mth06_pg0.json'\n",
      "Processed 'fulltext_organizations_Apple_Inc_mth10_pg1.json'\n",
      "Processed 'fulltext_organizations_Apple_Inc_mth11_pg1.json'\n",
      "Processed 'fulltext_organizations_Apple_Inc_mth02_pg2.json'\n",
      "Processed 'fulltext_organizations_Apple_Inc_mth03_pg2.json'\n",
      "Processed 'fulltext_organizations_Apple_Inc_mth02_pg3.json'\n",
      "Processed 'fulltext_organizations_Apple_Inc_mth03_pg3.json'\n",
      "Processed 'fulltext_organizations_Apple_Inc_mth10_pg0.json'\n",
      "Processed 'fulltext_organizations_Apple_Inc_mth11_pg0.json'\n",
      "Processed 'fulltext_organizations_Apple_Inc_mth07_pg1.json'\n",
      "Processed 'fulltext_organizations_Apple_Inc_mth06_pg1.json'\n",
      "Processed 'fulltext_organizations_Apple_Inc_mth09_pg3.json'\n",
      "Processed 'fulltext_organizations_Apple_Inc_mth03_pg4.json'\n",
      "Processed 'fulltext_organizations_Apple_Inc_mth02_pg4.json'\n",
      "Processed 'fulltext_organizations_Apple_Inc_mth04_pg3.json'\n",
      "Processed 'fulltext_organizations_Apple_Inc_mth09_pg4.json'\n",
      "Processed 'fulltext_organizations_Apple_Inc_mth01_pg1.json'\n",
      "Processed 'fulltext_organizations_Apple_Inc_mth01_pg0.json'\n",
      "Processed 'fulltext_organizations_Apple_Inc_mth05_pg2.json'\n",
      "Processed 'fulltext_organizations_Apple_Inc_mth04_pg2.json'\n",
      "Processed 'fulltext_organizations_Apple_Inc_mth03_pg5.json'\n",
      "Processed 'fulltext_organizations_Apple_Inc_mth02_pg5.json'\n"
     ]
    }
   ],
   "source": [
    "scrape_nyt_url(json_filepaths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed '../../data/raw/2022/organizations_Apple_Inc_mth04_pg1.json'\n",
      "Processed '../../data/raw/2022/organizations_Apple_Inc_mth05_pg1.json'\n",
      "Processed '../../data/raw/2022/organizations_Apple_Inc_mth12_pg0.json'\n",
      "Processed '../../data/raw/2022/organizations_Apple_Inc_mth12_pg1.json'\n",
      "Processed '../../data/raw/2022/organizations_Apple_Inc_mth04_pg0.json'\n",
      "Processed '../../data/raw/2022/organizations_Apple_Inc_mth05_pg0.json'\n",
      "Processed '../../data/raw/2022/organizations_Apple_Inc_mth09_pg0.json'\n",
      "Processed '../../data/raw/2022/organizations_Apple_Inc_mth08_pg0.json'\n",
      "Processed '../../data/raw/2022/organizations_Apple_Inc_mth03_pg0.json'\n",
      "Processed '../../data/raw/2022/organizations_Apple_Inc_mth02_pg0.json'\n",
      "Processed '../../data/raw/2022/organizations_Apple_Inc_mth03_pg1.json'\n",
      "Processed '../../data/raw/2022/organizations_Apple_Inc_mth02_pg1.json'\n",
      "Processed '../../data/raw/2022/organizations_Apple_Inc_mth09_pg1.json'\n",
      "Processed '../../data/raw/2022/organizations_Apple_Inc_mth07_pg0.json'\n",
      "Processed '../../data/raw/2022/organizations_Apple_Inc_mth06_pg0.json'\n",
      "Processed '../../data/raw/2022/organizations_Apple_Inc_mth10_pg1.json'\n",
      "Processed '../../data/raw/2022/organizations_Apple_Inc_mth11_pg1.json'\n",
      "Processed '../../data/raw/2022/organizations_Apple_Inc_mth10_pg0.json'\n",
      "Processed '../../data/raw/2022/organizations_Apple_Inc_mth11_pg0.json'\n",
      "Processed '../../data/raw/2022/organizations_Apple_Inc_mth07_pg1.json'\n",
      "Processed '../../data/raw/2022/organizations_Apple_Inc_mth01_pg0.json'\n",
      "Processed '../../data/raw/2024/organizations_Apple_Inc_mth12_pg0.json'\n",
      "Processed '../../data/raw/2024/organizations_Apple_Inc_mth04_pg0.json'\n",
      "Processed '../../data/raw/2024/organizations_Apple_Inc_mth05_pg0.json'\n",
      "Processed '../../data/raw/2024/organizations_Apple_Inc_mth09_pg0.json'\n",
      "Processed '../../data/raw/2024/organizations_Apple_Inc_mth08_pg0.json'\n",
      "Processed '../../data/raw/2024/organizations_Apple_Inc_mth03_pg0.json'\n",
      "Processed '../../data/raw/2024/organizations_Apple_Inc_mth02_pg0.json'\n",
      "Processed '../../data/raw/2024/organizations_Apple_Inc_mth03_pg1.json'\n",
      "Processed '../../data/raw/2024/organizations_Apple_Inc_mth02_pg1.json'\n",
      "Processed '../../data/raw/2024/organizations_Apple_Inc_mth09_pg1.json'\n",
      "Processed '../../data/raw/2024/organizations_Apple_Inc_mth08_pg1.json'\n",
      "Processed '../../data/raw/2024/organizations_Apple_Inc_mth07_pg0.json'\n",
      "Processed '../../data/raw/2024/organizations_Apple_Inc_mth06_pg0.json'\n",
      "Processed '../../data/raw/2024/organizations_Apple_Inc_mth03_pg2.json'\n",
      "Processed '../../data/raw/2024/organizations_Apple_Inc_mth10_pg0.json'\n",
      "Processed '../../data/raw/2024/organizations_Apple_Inc_mth11_pg0.json'\n",
      "Processed '../../data/raw/2024/organizations_Apple_Inc_mth06_pg1.json'\n",
      "Processed '../../data/raw/2024/organizations_Apple_Inc_mth01_pg1.json'\n",
      "Processed '../../data/raw/2024/organizations_Apple_Inc_mth01_pg0.json'\n",
      "Processed '../../data/raw/2023/organizations_Apple_Inc_mth12_pg0.json'\n",
      "Processed '../../data/raw/2023/organizations_Apple_Inc_mth04_pg0.json'\n",
      "Processed '../../data/raw/2023/organizations_Apple_Inc_mth05_pg0.json'\n",
      "Processed '../../data/raw/2023/organizations_Apple_Inc_mth09_pg0.json'\n",
      "Processed '../../data/raw/2023/organizations_Apple_Inc_mth08_pg0.json'\n",
      "Processed '../../data/raw/2023/organizations_Apple_Inc_mth03_pg0.json'\n",
      "Processed '../../data/raw/2023/organizations_Apple_Inc_mth02_pg0.json'\n",
      "Processed '../../data/raw/2023/organizations_Apple_Inc_mth09_pg1.json'\n",
      "Processed '../../data/raw/2023/organizations_Apple_Inc_mth07_pg0.json'\n",
      "Processed '../../data/raw/2023/organizations_Apple_Inc_mth06_pg0.json'\n",
      "Processed '../../data/raw/2023/organizations_Apple_Inc_mth11_pg1.json'\n",
      "Processed '../../data/raw/2023/organizations_Apple_Inc_mth10_pg0.json'\n",
      "Processed '../../data/raw/2023/organizations_Apple_Inc_mth11_pg0.json'\n",
      "Processed '../../data/raw/2023/organizations_Apple_Inc_mth06_pg1.json'\n",
      "Processed '../../data/raw/2023/organizations_Apple_Inc_mth01_pg0.json'\n",
      "Processed '../../data/raw/2015/organizations_Apple_Inc_mth04_pg1.json'\n",
      "Processed '../../data/raw/2015/organizations_Apple_Inc_mth05_pg1.json'\n",
      "Processed '../../data/raw/2015/organizations_Apple_Inc_mth12_pg0.json'\n",
      "Processed '../../data/raw/2015/organizations_Apple_Inc_mth12_pg1.json'\n",
      "Processed '../../data/raw/2015/organizations_Apple_Inc_mth01_pg2.json'\n",
      "Processed '../../data/raw/2015/organizations_Apple_Inc_mth04_pg0.json'\n",
      "Processed '../../data/raw/2015/organizations_Apple_Inc_mth05_pg0.json'\n",
      "Processed '../../data/raw/2015/organizations_Apple_Inc_mth06_pg2.json'\n",
      "Processed '../../data/raw/2015/organizations_Apple_Inc_mth09_pg0.json'\n",
      "Processed '../../data/raw/2015/organizations_Apple_Inc_mth08_pg0.json'\n",
      "Processed '../../data/raw/2015/organizations_Apple_Inc_mth03_pg0.json'\n",
      "Processed '../../data/raw/2015/organizations_Apple_Inc_mth02_pg0.json'\n",
      "Processed '../../data/raw/2015/organizations_Apple_Inc_mth10_pg3.json'\n",
      "Processed '../../data/raw/2015/organizations_Apple_Inc_mth10_pg2.json'\n",
      "Processed '../../data/raw/2015/organizations_Apple_Inc_mth03_pg1.json'\n",
      "Processed '../../data/raw/2015/organizations_Apple_Inc_mth02_pg1.json'\n",
      "Processed '../../data/raw/2015/organizations_Apple_Inc_mth09_pg1.json'\n",
      "Processed '../../data/raw/2015/organizations_Apple_Inc_mth08_pg1.json'\n",
      "Processed '../../data/raw/2015/organizations_Apple_Inc_mth06_pg3.json'\n",
      "Processed '../../data/raw/2015/organizations_Apple_Inc_mth09_pg2.json'\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 20\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m# ---\u001b[39;00m\n\u001b[1;32m     17\u001b[0m \n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m# Extract full text using BeautifulSoup\u001b[39;00m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m url \u001b[38;5;129;01min\u001b[39;00m web_url_list:\n\u001b[0;32m---> 20\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mrequests\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     21\u001b[0m     html_content \u001b[38;5;241m=\u001b[39m response\u001b[38;5;241m.\u001b[39mtext\n\u001b[1;32m     23\u001b[0m     \u001b[38;5;66;03m# Create a BeautifulSoup object\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.9/envs/multimodal_stockprice_predictor/lib/python3.11/site-packages/requests/api.py:73\u001b[0m, in \u001b[0;36mget\u001b[0;34m(url, params, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mget\u001b[39m(url, params\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     63\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Sends a GET request.\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \n\u001b[1;32m     65\u001b[0m \u001b[38;5;124;03m    :param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[38;5;124;03m    :rtype: requests.Response\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 73\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mget\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.9/envs/multimodal_stockprice_predictor/lib/python3.11/site-packages/requests/api.py:59\u001b[0m, in \u001b[0;36mrequest\u001b[0;34m(method, url, **kwargs)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;66;03m# By using the 'with' statement we are sure the session is closed, thus we\u001b[39;00m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;66;03m# avoid leaving sockets open which can trigger a ResourceWarning in some\u001b[39;00m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;66;03m# cases, and look like a memory leak in others.\u001b[39;00m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m sessions\u001b[38;5;241m.\u001b[39mSession() \u001b[38;5;28;01mas\u001b[39;00m session:\n\u001b[0;32m---> 59\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msession\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.9/envs/multimodal_stockprice_predictor/lib/python3.11/site-packages/requests/sessions.py:589\u001b[0m, in \u001b[0;36mSession.request\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    584\u001b[0m send_kwargs \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    585\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimeout\u001b[39m\u001b[38;5;124m\"\u001b[39m: timeout,\n\u001b[1;32m    586\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow_redirects\u001b[39m\u001b[38;5;124m\"\u001b[39m: allow_redirects,\n\u001b[1;32m    587\u001b[0m }\n\u001b[1;32m    588\u001b[0m send_kwargs\u001b[38;5;241m.\u001b[39mupdate(settings)\n\u001b[0;32m--> 589\u001b[0m resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43msend_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    591\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.9/envs/multimodal_stockprice_predictor/lib/python3.11/site-packages/requests/sessions.py:703\u001b[0m, in \u001b[0;36mSession.send\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    700\u001b[0m start \u001b[38;5;241m=\u001b[39m preferred_clock()\n\u001b[1;32m    702\u001b[0m \u001b[38;5;66;03m# Send the request\u001b[39;00m\n\u001b[0;32m--> 703\u001b[0m r \u001b[38;5;241m=\u001b[39m \u001b[43madapter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    705\u001b[0m \u001b[38;5;66;03m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[1;32m    706\u001b[0m elapsed \u001b[38;5;241m=\u001b[39m preferred_clock() \u001b[38;5;241m-\u001b[39m start\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.9/envs/multimodal_stockprice_predictor/lib/python3.11/site-packages/requests/adapters.py:667\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    664\u001b[0m     timeout \u001b[38;5;241m=\u001b[39m TimeoutSauce(connect\u001b[38;5;241m=\u001b[39mtimeout, read\u001b[38;5;241m=\u001b[39mtimeout)\n\u001b[1;32m    666\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 667\u001b[0m     resp \u001b[38;5;241m=\u001b[39m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    668\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    669\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    670\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    671\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    672\u001b[0m \u001b[43m        \u001b[49m\u001b[43mredirect\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    673\u001b[0m \u001b[43m        \u001b[49m\u001b[43massert_same_host\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    674\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    675\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    676\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    677\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    678\u001b[0m \u001b[43m        \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    679\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    681\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (ProtocolError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m    682\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m(err, request\u001b[38;5;241m=\u001b[39mrequest)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.9/envs/multimodal_stockprice_predictor/lib/python3.11/site-packages/urllib3/connectionpool.py:787\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[1;32m    784\u001b[0m response_conn \u001b[38;5;241m=\u001b[39m conn \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m release_conn \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    786\u001b[0m \u001b[38;5;66;03m# Make the request on the HTTPConnection object\u001b[39;00m\n\u001b[0;32m--> 787\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    788\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    789\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    790\u001b[0m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    791\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout_obj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    792\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    793\u001b[0m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    794\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    795\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    796\u001b[0m \u001b[43m    \u001b[49m\u001b[43mresponse_conn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresponse_conn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    797\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpreload_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    798\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecode_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    799\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mresponse_kw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    800\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    802\u001b[0m \u001b[38;5;66;03m# Everything went great!\u001b[39;00m\n\u001b[1;32m    803\u001b[0m clean_exit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.9/envs/multimodal_stockprice_predictor/lib/python3.11/site-packages/urllib3/connectionpool.py:534\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[0;34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[0m\n\u001b[1;32m    532\u001b[0m \u001b[38;5;66;03m# Receive the response from the server\u001b[39;00m\n\u001b[1;32m    533\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 534\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    535\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (BaseSSLError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    536\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_raise_timeout(err\u001b[38;5;241m=\u001b[39me, url\u001b[38;5;241m=\u001b[39murl, timeout_value\u001b[38;5;241m=\u001b[39mread_timeout)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.9/envs/multimodal_stockprice_predictor/lib/python3.11/site-packages/urllib3/connection.py:516\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    513\u001b[0m _shutdown \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msock, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshutdown\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    515\u001b[0m \u001b[38;5;66;03m# Get the response from http.client.HTTPConnection\u001b[39;00m\n\u001b[0;32m--> 516\u001b[0m httplib_response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    518\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    519\u001b[0m     assert_header_parsing(httplib_response\u001b[38;5;241m.\u001b[39mmsg)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.9/lib/python3.11/http/client.py:1395\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1393\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1394\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1395\u001b[0m         \u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbegin\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1396\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m:\n\u001b[1;32m   1397\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.9/lib/python3.11/http/client.py:325\u001b[0m, in \u001b[0;36mHTTPResponse.begin\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    323\u001b[0m \u001b[38;5;66;03m# read until we get a non-100 response\u001b[39;00m\n\u001b[1;32m    324\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 325\u001b[0m     version, status, reason \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_read_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    326\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m status \u001b[38;5;241m!=\u001b[39m CONTINUE:\n\u001b[1;32m    327\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.9/lib/python3.11/http/client.py:286\u001b[0m, in \u001b[0;36mHTTPResponse._read_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    285\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_read_status\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 286\u001b[0m     line \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfp\u001b[38;5;241m.\u001b[39mreadline(_MAXLINE \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124miso-8859-1\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    287\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(line) \u001b[38;5;241m>\u001b[39m _MAXLINE:\n\u001b[1;32m    288\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m LineTooLong(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstatus line\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.9/lib/python3.11/socket.py:706\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    704\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m    705\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 706\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    707\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[1;32m    708\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout_occurred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.9/lib/python3.11/ssl.py:1314\u001b[0m, in \u001b[0;36mSSLSocket.recv_into\u001b[0;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[1;32m   1310\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m flags \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   1311\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1312\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[1;32m   1313\u001b[0m           \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m)\n\u001b[0;32m-> 1314\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnbytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1315\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1316\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mrecv_into(buffer, nbytes, flags)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.9/lib/python3.11/ssl.py:1166\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m   1164\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1165\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m buffer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1166\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sslobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1167\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1168\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sslobj\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;28mlen\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for file in json_files:\n",
    "    # Open .json\n",
    "    with open(file, \"r\") as f:\n",
    "        response = json.load(f)  # Load JSON data into a dictionary\n",
    "\n",
    "    # ---\n",
    "\n",
    "    # Get all web urls for given .json\n",
    "    web_url_list = []\n",
    "    list_of_dict = [] # for export\n",
    "    articles = response['response']['docs']\n",
    "\n",
    "    for article in articles:\n",
    "        web_url_list.append(article['web_url'])\n",
    "\n",
    "    # ---\n",
    "\n",
    "    # Extract full text using BeautifulSoup\n",
    "    for url in web_url_list:\n",
    "        response = requests.get(url)\n",
    "        html_content = response.text\n",
    "\n",
    "        # Create a BeautifulSoup object\n",
    "        soup = bs(html_content, 'html.parser')\n",
    "\n",
    "        # Extract text from HTML\n",
    "        title_container = soup.find('title')\n",
    "        article_container = soup.find('article')\n",
    "\n",
    "        # Extract text from found element\n",
    "        if article_container:\n",
    "            text_content = \"\\n\".join([p.get_text(strip=True) for p in article_container.find_all('p')])  # Extract paragraphs\n",
    "        else:\n",
    "            text_content = \"No article content found.\"\n",
    "\n",
    "        title_content = title_container.get_text(strip=True)\n",
    "\n",
    "        # Text Export\n",
    "        export_dict = {\n",
    "            'headline': title_content,\n",
    "            'web_url': url,\n",
    "            'full_text': text_content\n",
    "        }\n",
    "\n",
    "        list_of_dict.append(export_dict)\n",
    "\n",
    "    # Modify filepath for export\n",
    "    directory, filename = path.split(file)\n",
    "    export_filename = f\"fulltext_{filename}\"\n",
    "    export_filepath = path.join(directory, export_filename)\n",
    "\n",
    "    # Export as .json\n",
    "    with open(export_filepath, 'w') as json_file:\n",
    "        json.dump(list_of_dict, json_file, indent=4)\n",
    "    \n",
    "    print(f\"Processed '{file}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_article_full_text(json_files):\n",
    "    for file in json_files:\n",
    "        # Open .json and load data\n",
    "        with open(file, \"r\") as f:\n",
    "            response = json.load(f)\n",
    "\n",
    "        # Get all web urls\n",
    "        web_url_list = [article['web_url'] for article in response['response']['docs']]\n",
    "\n",
    "        # List to store article data for export\n",
    "        list_of_dict = []\n",
    "\n",
    "        # Process each URL\n",
    "        for url in web_url_list:\n",
    "            response = requests.get(url)\n",
    "            html_content = response.text\n",
    "\n",
    "            # Create BeautifulSoup object\n",
    "            soup = bs(html_content, 'html.parser')\n",
    "\n",
    "            # Extract title and full article text\n",
    "            title_container = soup.find('title')\n",
    "            article_container = soup.find('article')\n",
    "\n",
    "            if article_container:\n",
    "                full_text = \"\\n\".join([p.get_text(strip=True) for p in article_container.find_all('p')])\n",
    "            else:\n",
    "                full_text = \"No article content found.\"\n",
    "\n",
    "            title_content = title_container.get_text(strip=True) if title_container else \"No title found\"\n",
    "\n",
    "            # Prepare article data\n",
    "            export_dict = {\n",
    "                'headline': title_content,\n",
    "                'web_url': url,\n",
    "                'full_text': full_text\n",
    "            }\n",
    "\n",
    "            list_of_dict.append(export_dict)\n",
    "\n",
    "        # Prepare filepath for export\n",
    "        directory, filename = path.split(file)\n",
    "        export_filename = f\"fulltext_{filename}\"\n",
    "        export_filepath = path.join(directory, export_filename)\n",
    "\n",
    "        # Export data to .json\n",
    "        with open(export_filepath, 'w') as json_file:\n",
    "            json.dump(list_of_dict, json_file, indent=4)\n",
    "\n",
    "        print(f\"Processed '{file}' and exported to '{export_filename}'\")\n",
    "\n",
    "# Example usage\n",
    "json_files = ['file1.json', 'file2.json']  # Replace with your actual file paths\n",
    "extract_article_full_text(json_files)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Multimodal Stock Price Prediction (Poetry)",
   "language": "python",
   "name": "multimodal_stockprice_prediction"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
