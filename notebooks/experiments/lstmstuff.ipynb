{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy import concatenate\n",
    "from pandas import read_csv, DataFrame, concat\n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn\n",
    "import sklearn\n",
    "import tensorflow\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "import statsmodels\n",
    "import yfinance as yf\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_absolute_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define global variables\n",
    "#TODO find out what is the target variable and what lag steps\n",
    "num_features = 53\n",
    "target_variable = 'POILBRE'\n",
    "lag_steps = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO check if data is clean already\n",
    "df = read_csv('data/dataset.csv', header = 0, index_col = 0, usecols = [i for i in range(0, num_features+1)])\n",
    "df.dropna(inplace=True) # NA values after June 2017\n",
    "print(df.shape)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transformation for LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform the time-series dataset specifically for LSTM\n",
    "def time_series_to_lstm(df, target_variable, lag_steps=1, dropna=True, fill='ffill'):\n",
    "    \"\"\"\n",
    "    Transforms time-series data into a supervised learning format compatible with LSTMs.\n",
    "    \n",
    "    Args:\n",
    "        df (pd.DataFrame): The input time-series dataset.\n",
    "        target_variable (str): The column to predict.\n",
    "        lag_steps (int): Number of past time steps to include.\n",
    "        dropna (bool): Whether to drop rows with NaN values.\n",
    "        fill (str): What to fill NaN values with ('ffill', 'bfill', 'mean', 'median', None)\n",
    "        \n",
    "    Returns:\n",
    "        df_transformed (pd.DataFrame): DataFrame to be used as input for LSTM model\n",
    "    \"\"\"\n",
    "    # Ensure dataframe format\n",
    "    if isinstance(df, list):\n",
    "        df = DataFrame(df)\n",
    "    \n",
    "    cols = []\n",
    "    feature_names = []\n",
    "    \n",
    "    # Create Lag Steps\n",
    "    for i in range(lag_steps, 0, -1):\n",
    "        cols.append(df.shift(i))\n",
    "        feature_names += [f\"{col}(t-{i})\" for col in df.columns]\n",
    "    \n",
    "    # Current time step (t) for target variable\n",
    "    cols.append(df[[target_variable]])\n",
    "    feature_names += [f\"{target_variable}(t)\"]\n",
    "    \n",
    "    # Combine and assign column names\n",
    "    df_transformed = concat(cols, axis=1)\n",
    "    df_transformed.columns = feature_names\n",
    "\n",
    "    # Drop NaN rows if required\n",
    "    if dropna:\n",
    "        df_transformed.dropna(inplace=True)\n",
    "    else:\n",
    "        if not None:\n",
    "            df_transformed.fillna(method=fill, inplace=True)\n",
    "    \n",
    "    return df_transformed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_transformed = time_series_to_lstm(df, target_variable, lag_steps)\n",
    "print(df_transformed.shape)\n",
    "df_transformed.head()\n",
    "# for company in companies: \n",
    "    # df_transformed.to_csv(f'data/{company}_transformed.csv')\n",
    "# Export transformed dataset\n",
    "df_transformed.to_csv('data/dataset_transformed.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train-Test Split\n",
    "split = int(df_transformed.shape[0]*0.8)\n",
    "train = df_transformed[:split]\n",
    "test = df_transformed[split:]\n",
    "\n",
    "print('Split Shape:', train.shape, test.shape)\n",
    "# Scale to avoid distance calculation bias\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "train_scaled = scaler.fit_transform(train)\n",
    "test_scaled = scaler.transform(test) # Avoid data leakage\n",
    "train.iloc[:, -1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate into features and target (last column)\n",
    "X_train, y_train = train_scaled[:, :-1], train_scaled[:, -1]\n",
    "X_test, y_test = test_scaled[:, :-1], test_scaled[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape features for LSTM\n",
    "X_train = X_train.reshape((X_train.shape[0], lag_steps, X_train.shape[1]))\n",
    "X_test = X_test.reshape((X_test.shape[0], lag_steps, X_test.shape[1]))\n",
    "\n",
    "print('Train Shape:', X_train.shape, y_train.shape)\n",
    "print('Test Shape:', X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initiate LSTM model\n",
    "model = Sequential()\n",
    "model.add(LSTM(125, input_shape=(X_train.shape[1], X_train.shape[2])))\n",
    "model.add(Dense(1))\n",
    "model.compile(loss='mae', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model fitting\n",
    "history = model.fit(X_train, y_train, epochs=70, batch_size=128, validation_data=(X_test, y_test), verbose=2, shuffle=False)\n",
    "\n",
    "# Plot training progression\n",
    "plt.plot(history.history['loss'], label='train')\n",
    "plt.plot(history.history['val_loss'], label='test')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get predicted values\n",
    "yhat = model.predict(X_test)\n",
    "\n",
    "# Reshaping back into 2D for inverse scaling\n",
    "X_test_inv = X_test.reshape((X_test.shape[0], X_test.shape[2])) \n",
    "\n",
    "# Concatenate and Inverse Scaling\n",
    "# Prediction\n",
    "inv_yhat = concatenate((X_test_inv, yhat), axis=1) # Required to get back original scale\n",
    "inv_yhat = scaler.inverse_transform(inv_yhat)\n",
    "inv_yhat = inv_yhat[:, num_features*lag_steps] # Extract target_variable\n",
    "\n",
    "# Validation\n",
    "y_test_inv = y_test.reshape((len(y_test), 1))\n",
    "inv_y = concatenate((X_test_inv, y_test_inv), axis=1) # Both arrays must have same dimensions\n",
    "inv_y = scaler.inverse_transform(inv_y)\n",
    "inv_y = inv_y[:, num_features*lag_steps]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get MAE\n",
    "mae = np.sqrt(mean_absolute_error(inv_y, inv_yhat))\n",
    "print('LSTM Test MAE: %.3f' % mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(inv_y, label = 'Actual')\n",
    "plt.plot(inv_yhat, label = 'Predicted')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
