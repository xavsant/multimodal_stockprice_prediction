{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#>=50% of annotators agreed on the financial sentiment \n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "file_path = r'C:/Users/Tammy/Documents/GitHub/multimodal_stockprice_prediction/data/clean/stock_text_data/Apple_Inc_text_data.csv'\n",
    "# Load the CSV file with the specified encoding and column names\n",
    "df = pd.read_csv(file_path,encoding='utf-8')\n",
    "\n",
    "# Cleaning function\n",
    "def clean_text(text):\n",
    "    # Remove non-ASCII characters\n",
    "    text = re.sub(r'[^\\x00-\\x7F]+', '', text)\n",
    "\n",
    "    # Convert to lowercase\n",
    "    text = text.lower()\n",
    "\n",
    "    # Remove punctuation and special characters (except spaces)\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "\n",
    "    # Remove extra whitespace\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "\n",
    "    return text\n",
    "# Check the first few rows of the data\n",
    "df.head()\n",
    "#reformat date\n",
    "# format datetime again\n",
    "df['pub_date'] = pd.to_datetime(df['pub_date']) \n",
    "df['pub_date'] = df['pub_date'].dt.date\n",
    "#cleaning\n",
    "# df['headline'] = df['headline'].apply(clean_text) # change this line for abstract\n",
    "df['headline'] = df['headline'].apply(clean_text)\n",
    "# Select only the 'pub_date' and 'headline' columns\n",
    "df_new = df[['pub_date', 'headline']] #change this line for abstract\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Polarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel\n",
    "\n",
    "class SentimentTrendPrediction(BaseModel):\n",
    "    SentimentScore: float   # Predicted price as a string (could be float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Setting up Gemini\n",
    "#set up gemini to process textual templates\n",
    "from google import genai\n",
    "from dotenv import load_dotenv\n",
    "from pydantic import BaseModel\n",
    "import os\n",
    "load_dotenv()\n",
    "# Load environment variables from the .env file\n",
    "API_KEY = os.getenv(\"API_KEY\")\n",
    "client = genai.Client(api_key=API_KEY)#insert api key\n",
    "## Function to call Gemini API\n",
    "from google.genai import types\n",
    "import json\n",
    "\n",
    "# Function to get sentiment based on model output\n",
    "def gemini_predict_sentiment_trend(prompt, return_json=False):\n",
    "    try:\n",
    "        # Generate content from the model\n",
    "        response = client.models.generate_content(\n",
    "            model='gemini-2.0-flash-lite', \n",
    "            contents=prompt,\n",
    "            config=types.GenerateContentConfig(\n",
    "            system_instruction= f\"\"\"\n",
    "            You are a financial analyst specializing in both quantitative market sentiment and trend analysis. Your task is to analyze each headline and provide:\n",
    "\n",
    "            **Sentiment Score (-1.0 to 1.0)**:\n",
    "            - -1.0: Extremely negative news (bankruptcy, massive fraud, severe regulatory action)\n",
    "            - 0.0: Neutral or balanced news (mixed results, status quo maintained)\n",
    "            - 1.0: Extremely positive news (breakthrough products, industry-changing acquisitions)\n",
    "            - Consider both **direct effects on Appleâ€™s stock price** and **general market or sector trends**.\n",
    "\n",
    "            CRITICAL INSTRUCTIONS:\n",
    "            - Evaluate Apple's stock movement within the broader tech industry context and the overall market sentiment.\n",
    "            - Consider broader market trends, including economic events, industry-wide shifts, or global developments that may indirectly impact Apple or the tech sector. \n",
    "            - If the headline does not pertain to Apple or tech but has potential ripple effects, assign a neutral sentiment (0.0) or assess if it has any relevant impact on market sentiment as a whole.\n",
    "            - For ambiguous headlines, default to low scores (-0.1 to +0.1 range).\n",
    "            - Return ONLY one value in JSON format like:\n",
    "            {{ \"SentimentScore\": 0.7 }}\n",
    "            \"\"\"\n",
    ",\n",
    "            max_output_tokens=75,  # Label only\n",
    "            temperature=0.5,      # More flexibility\n",
    "            top_k=5,              # Limit to top 5 choices\n",
    "            top_p=0.7,            # Consider tokens covering 70% probability mass\n",
    "            response_mime_type='application/json',\n",
    "            response_schema=SentimentTrendPrediction\n",
    "          # No stop sequence to avoid premature stops\n",
    "            )\n",
    "        )\n",
    "        \n",
    "        # Check if the response is valid\n",
    "        response_text = response.text.strip()\n",
    "        if not response_text:\n",
    "            print(\"Error: No response text found.\")\n",
    "            return 'Error' if not return_json else {}\n",
    "\n",
    "        # Try parsing the response as JSON\n",
    "        try:\n",
    "            response_json = json.loads(response_text)\n",
    "            if return_json:\n",
    "                return response_json\n",
    "\n",
    "            return response_json\n",
    "\n",
    "        except json.JSONDecodeError:\n",
    "            print(f\"Error parsing JSON. Response: {response_text}\")\n",
    "            return 'Error' if not return_json else {}\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"API Error: {e}\")\n",
    "        return 'Error' if not return_json else {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Experiment with few-shot prompting\n",
    "def analyze_sentiment_trend(text): #alter prompt for abstract\n",
    "    prompt = f\"\"\"\n",
    "    Analyze this financial headline and provide: \n",
    "    Sentiment Score: from -1.0 (extremely negative) to 1.0 (extremely positive)\n",
    "\n",
    "    Return results in JSON format like:\n",
    "    {{ \"SentimentScore\": X.X }}\n",
    "\n",
    "    Here are some examples:\n",
    "\n",
    "    Example 1: \n",
    "    Headline: \"Company Close to Finalizing Its 40 billion dollar funding.\" \n",
    "    {{ \"SentimentScore\": 0.9}}\n",
    "\n",
    "    Example 2: \n",
    "    Headline: \"Regulatory authorities block 10% of funds for key agency in US-China Tech Race.\"\n",
    "    {{ \"SentimentScore\": -0.8 }}\n",
    "\n",
    "    Example 3: \n",
    "    Headline: \"Why Company B could be a key to a Company C's Deal.\"\n",
    "    {{ \"SentimentScore\": 0.2 }}\n",
    "\n",
    "    Example 4: \n",
    "    Headline: \"Artificial intelligence boom might help mitigate some tariff pain.\"\n",
    "    {{ \"SentimentScore\": 0.3}}\n",
    "\n",
    "    Example 5: \n",
    "    Headline: \"Major banks face regulatory hurdles, impacting earnings outlook.\"\n",
    "    {{ \"SentimentScore\": -0.6 }}\n",
    "\n",
    "    Example 6: \n",
    "    Headline: \"Company's $32 billion deal may signal a turning point for slow IPO, M&A markets.\"\n",
    "    {{ \"SentimentScore\": 0.8 }}\n",
    "\n",
    "    Example 7: \n",
    "    Headline: \"Company X enters a strategic partnership with Company Y to expand its operations in Asia.\"\n",
    "    Sentiment Score: 0.7\n",
    "    {{ \"SentimentScore\": 0.7 }}\n",
    "\n",
    "    Now, analyze this headline:\n",
    "\n",
    "    Headline: \"{text}\"\n",
    "    Response (in JSON format):\n",
    "   {{ \"SentimentScore\": }}\"\"\"\n",
    "    \n",
    "    result = gemini_predict_sentiment_trend(prompt)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Impact Duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DurationPrediction(BaseModel):\n",
    "    PotentialImpactDays: int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for duration prediction\n",
    "def gemini_predict_duration(prompt, return_json=False):\n",
    "    try:\n",
    "        # Generate content from the model\n",
    "        response = client.models.generate_content(\n",
    "            model='gemini-2.0-flash-lite', \n",
    "            contents=prompt,\n",
    "            config=types.GenerateContentConfig(\n",
    "                system_instruction=\"\"\"\n",
    "                You are a financial market expert specializing in estimating the impact duration of financial news. Your task is to analyze each headline and estimate how long its impact will last on the stock market.\n",
    "\n",
    "                Consider:\n",
    "                - **1-3 days**: Short-lived news (minor developments, non-urgent reactions).\n",
    "                - **4-7 days**: Moderately impactful news (earnings reports, key regulatory actions).\n",
    "                - **8-14 days**: Significant developments (corporate mergers, product announcements).\n",
    "                - **15-30 days**: Major structural changes (industry shifts, global economic impacts).\n",
    "\n",
    "                For Apple-specific news, consider historical precedents for how similar news has impacted Apple's stock in the past. For market-wide or industry news, estimate how long the ripple effects might last, considering Apple's role in the tech sector.\n",
    "\n",
    "                Return only the result in JSON format like:\n",
    "                {{ \"PotentialImpactDays\": Z }}\n",
    "                \"\"\",\n",
    "                max_output_tokens=50,\n",
    "                temperature=0.5,\n",
    "                top_k=5,\n",
    "                top_p=0.7,\n",
    "                response_mime_type='application/json',\n",
    "                response_schema=DurationPrediction\n",
    "            )\n",
    "        )\n",
    "        \n",
    "        # Check if the response is valid\n",
    "        response_text = response.text.strip()\n",
    "        if not response_text:\n",
    "            print(\"Error: No response text found.\")\n",
    "            return 'Error' if not return_json else {}\n",
    "\n",
    "        # Try parsing the response as JSON\n",
    "        try:\n",
    "            response_json = json.loads(response_text)\n",
    "            if return_json:\n",
    "                return response_json\n",
    "\n",
    "            return response_json\n",
    "\n",
    "        except json.JSONDecodeError:\n",
    "            print(f\"Error parsing JSON. Response: {response_text}\")\n",
    "            return 'Error' if not return_json else {}\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"API Error: {e}\")\n",
    "        return 'Error' if not return_json else {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_duration(text):\n",
    "    prompt = f\"\"\"\n",
    "    Analyze this financial headline and estimate how many days (1-30) this news might impact the market.\n",
    "    Consider: \n",
    "    - 1-3 days for short-lived news\n",
    "    - 4-7 days for moderately impactful news \n",
    "    - 8-14 days for significant developments\n",
    "    - 15-30 days for major structural changes or significant corporate events\n",
    "    Additionally, for Apple-specific news (e.g., product launches, earnings results), consider the historical reaction of Apple's stock and the potential market sentiment based on previous similar events.\n",
    "\n",
    "    For market-wide news (e.g., interest rate changes, regulatory updates), estimate how it will ripple through the tech sector and its potential impact on Apple stock.\n",
    "\n",
    "    Return result in JSON format like:\n",
    "    {{ \"PotentialImpactDays\": Z }}\n",
    "\n",
    "    Examples:\n",
    "\n",
    "    Example 1: \n",
    "    Headline: \"Company close to finalizing its 40 billion dollar funding.\" \n",
    "    {{ \"PotentialImpactDays\": 14 }}\n",
    "\n",
    "    Example 2: \n",
    "    Headline: \"Regulatory authorities block 10% of funds for key agency in US-China Tech Race.\"\n",
    "    {{ \"PotentialImpactDays\": 7 }}\n",
    "\n",
    "    Example 3: \n",
    "    Headline: \"Why Company B could be a key to a Company C's Deal.\"\n",
    "    {{ \"PotentialImpactDays\": 3 }}\n",
    "\n",
    "    Example 4: \n",
    "    Headline: \"Artificial intelligence boom might help mitigate some tariff pain.\"\n",
    "    {{ \"PotentialImpactDays\": 5 }}\n",
    "\n",
    "    Example 5: \n",
    "    Headline: \"Major banks face regulatory hurdles, impacting earnings outlook.\"\n",
    "    {{ \"PotentialImpactDays\": 10 }}\n",
    "\n",
    "    Example 6: \n",
    "    Headline: \"Company's $32 billion deal may signal a turning point for slow IPO, M&A markets.\"\n",
    "    {{ \"PotentialImpactDays\": 10 }}\n",
    "\n",
    "    Now analyze this headline:\n",
    "    Headline: \"{text}\"\n",
    "    \"\"\"\n",
    "    \n",
    "    result = gemini_predict_duration(prompt)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Joining data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Sentiment: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2143/2143 [38:39<00:00,  1.08s/headline]\n",
      "C:\\Users\\Tammy\\AppData\\Local\\Temp\\ipykernel_47952\\242754928.py:48: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['sentiment_score'] = sentiment_score_list\n",
      "Processing Duration:   0%|          | 7/2143 [00:12<1:05:22,  1.84s/headline]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[31], line 69\u001b[0m\n\u001b[0;32m     66\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m df\n\u001b[0;32m     68\u001b[0m \u001b[38;5;66;03m# Apply the separate models\u001b[39;00m\n\u001b[1;32m---> 69\u001b[0m df_analyzed \u001b[38;5;241m=\u001b[39m process_headlines_with_separate_models(df_new, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mheadline\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     71\u001b[0m \u001b[38;5;66;03m# Display results\u001b[39;00m\n\u001b[0;32m     72\u001b[0m \u001b[38;5;28mprint\u001b[39m(df_analyzed[[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpub_date\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mheadline\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msentiment_score\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimpact_days\u001b[39m\u001b[38;5;124m'\u001b[39m]])\n",
      "Cell \u001b[1;32mIn[31], line 54\u001b[0m, in \u001b[0;36mprocess_headlines_with_separate_models\u001b[1;34m(df, sentiment_column)\u001b[0m\n\u001b[0;32m     49\u001b[0m \u001b[38;5;66;03m# df['trend_strength'] = trend_strength_list\u001b[39;00m\n\u001b[0;32m     50\u001b[0m \n\u001b[0;32m     51\u001b[0m \u001b[38;5;66;03m# Process with second model (duration)\u001b[39;00m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m idx, headline \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28menumerate\u001b[39m(df[sentiment_column]), total\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(df), desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mProcessing Duration\u001b[39m\u001b[38;5;124m\"\u001b[39m, unit\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mheadline\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m     53\u001b[0m     \u001b[38;5;66;03m# Get duration prediction\u001b[39;00m\n\u001b[1;32m---> 54\u001b[0m     result \u001b[38;5;241m=\u001b[39m analyze_duration(headline)\n\u001b[0;32m     56\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(result, \u001b[38;5;28mdict\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPotentialImpactDays\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m result:\n\u001b[0;32m     57\u001b[0m         impact_days \u001b[38;5;241m=\u001b[39m result[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPotentialImpactDays\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "Cell \u001b[1;32mIn[26], line 46\u001b[0m, in \u001b[0;36manalyze_duration\u001b[1;34m(text)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21manalyze_duration\u001b[39m(text):\n\u001b[0;32m      2\u001b[0m     prompt \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;124m    Analyze this financial headline and estimate how many days (1-30) this news might impact the market.\u001b[39m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;124m    Consider: \u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     43\u001b[0m \u001b[38;5;124m    Headline: \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtext\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     44\u001b[0m \u001b[38;5;124m    \u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[1;32m---> 46\u001b[0m     result \u001b[38;5;241m=\u001b[39m gemini_predict_duration(prompt)\n\u001b[0;32m     47\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "Cell \u001b[1;32mIn[25], line 5\u001b[0m, in \u001b[0;36mgemini_predict_duration\u001b[1;34m(prompt, return_json)\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgemini_predict_duration\u001b[39m(prompt, return_json\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m      3\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m      4\u001b[0m         \u001b[38;5;66;03m# Generate content from the model\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m         response \u001b[38;5;241m=\u001b[39m client\u001b[38;5;241m.\u001b[39mmodels\u001b[38;5;241m.\u001b[39mgenerate_content(\n\u001b[0;32m      6\u001b[0m             model\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgemini-2.0-flash-lite\u001b[39m\u001b[38;5;124m'\u001b[39m, \n\u001b[0;32m      7\u001b[0m             contents\u001b[38;5;241m=\u001b[39mprompt,\n\u001b[0;32m      8\u001b[0m             config\u001b[38;5;241m=\u001b[39mtypes\u001b[38;5;241m.\u001b[39mGenerateContentConfig(\n\u001b[0;32m      9\u001b[0m                 system_instruction\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;124m                You are a financial market expert specializing in estimating the impact duration of financial news. Your task is to analyze each headline and estimate how long its impact will last on the stock market.\u001b[39m\n\u001b[0;32m     11\u001b[0m \n\u001b[0;32m     12\u001b[0m \u001b[38;5;124m                Consider:\u001b[39m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;124m                - **1-3 days**: Short-lived news (minor developments, non-urgent reactions).\u001b[39m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;124m                - **4-7 days**: Moderately impactful news (earnings reports, key regulatory actions).\u001b[39m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;124m                - **8-14 days**: Significant developments (corporate mergers, product announcements).\u001b[39m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;124m                - **15-30 days**: Major structural changes (industry shifts, global economic impacts).\u001b[39m\n\u001b[0;32m     17\u001b[0m \n\u001b[0;32m     18\u001b[0m \u001b[38;5;124m                For Apple-specific news, consider historical precedents for how similar news has impacted Apple\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ms stock in the past. For market-wide or industry news, estimate how long the ripple effects might last, considering Apple\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ms role in the tech sector.\u001b[39m\n\u001b[0;32m     19\u001b[0m \n\u001b[0;32m     20\u001b[0m \u001b[38;5;124m                Return only the result in JSON format like:\u001b[39m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;124m                \u001b[39m\u001b[38;5;124m{{\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPotentialImpactDays\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m: Z }}\u001b[39m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;124m                \u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m,\n\u001b[0;32m     23\u001b[0m                 max_output_tokens\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m50\u001b[39m,\n\u001b[0;32m     24\u001b[0m                 temperature\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.5\u001b[39m,\n\u001b[0;32m     25\u001b[0m                 top_k\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m,\n\u001b[0;32m     26\u001b[0m                 top_p\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.7\u001b[39m,\n\u001b[0;32m     27\u001b[0m                 response_mime_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mapplication/json\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m     28\u001b[0m                 response_schema\u001b[38;5;241m=\u001b[39mDurationPrediction\n\u001b[0;32m     29\u001b[0m             )\n\u001b[0;32m     30\u001b[0m         )\n\u001b[0;32m     32\u001b[0m         \u001b[38;5;66;03m# Check if the response is valid\u001b[39;00m\n\u001b[0;32m     33\u001b[0m         response_text \u001b[38;5;241m=\u001b[39m response\u001b[38;5;241m.\u001b[39mtext\u001b[38;5;241m.\u001b[39mstrip()\n",
      "File \u001b[1;32mc:\\Users\\Tammy\\anaconda3\\Lib\\site-packages\\google\\genai\\models.py:5304\u001b[0m, in \u001b[0;36mModels.generate_content\u001b[1;34m(self, model, contents, config)\u001b[0m\n\u001b[0;32m   5302\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m remaining_remote_calls_afc \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m   5303\u001b[0m   i \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m-> 5304\u001b[0m   response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate_content(\n\u001b[0;32m   5305\u001b[0m       model\u001b[38;5;241m=\u001b[39mmodel, contents\u001b[38;5;241m=\u001b[39mcontents, config\u001b[38;5;241m=\u001b[39mconfig\n\u001b[0;32m   5306\u001b[0m   )\n\u001b[0;32m   5307\u001b[0m   logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAFC remote call \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m is done.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m   5308\u001b[0m   remaining_remote_calls_afc \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\Tammy\\anaconda3\\Lib\\site-packages\\google\\genai\\models.py:4272\u001b[0m, in \u001b[0;36mModels._generate_content\u001b[1;34m(self, model, contents, config)\u001b[0m\n\u001b[0;32m   4269\u001b[0m request_dict \u001b[38;5;241m=\u001b[39m _common\u001b[38;5;241m.\u001b[39mconvert_to_dict(request_dict)\n\u001b[0;32m   4270\u001b[0m request_dict \u001b[38;5;241m=\u001b[39m _common\u001b[38;5;241m.\u001b[39mencode_unserializable_types(request_dict)\n\u001b[1;32m-> 4272\u001b[0m response_dict \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_api_client\u001b[38;5;241m.\u001b[39mrequest(\n\u001b[0;32m   4273\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpost\u001b[39m\u001b[38;5;124m'\u001b[39m, path, request_dict, http_options\n\u001b[0;32m   4274\u001b[0m )\n\u001b[0;32m   4276\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_api_client\u001b[38;5;241m.\u001b[39mvertexai:\n\u001b[0;32m   4277\u001b[0m   response_dict \u001b[38;5;241m=\u001b[39m _GenerateContentResponse_from_vertex(\n\u001b[0;32m   4278\u001b[0m       \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_api_client, response_dict\n\u001b[0;32m   4279\u001b[0m   )\n",
      "File \u001b[1;32mc:\\Users\\Tammy\\anaconda3\\Lib\\site-packages\\google\\genai\\_api_client.py:575\u001b[0m, in \u001b[0;36mBaseApiClient.request\u001b[1;34m(self, http_method, path, request_dict, http_options)\u001b[0m\n\u001b[0;32m    565\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrequest\u001b[39m(\n\u001b[0;32m    566\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    567\u001b[0m     http_method: \u001b[38;5;28mstr\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    570\u001b[0m     http_options: Optional[HttpOptionsOrDict] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    571\u001b[0m ):\n\u001b[0;32m    572\u001b[0m   http_request \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_request(\n\u001b[0;32m    573\u001b[0m       http_method, path, request_dict, http_options\n\u001b[0;32m    574\u001b[0m   )\n\u001b[1;32m--> 575\u001b[0m   response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_request(http_request, stream\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m    576\u001b[0m   json_response \u001b[38;5;241m=\u001b[39m response\u001b[38;5;241m.\u001b[39mjson\n\u001b[0;32m    577\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m json_response:\n",
      "File \u001b[1;32mc:\\Users\\Tammy\\anaconda3\\Lib\\site-packages\\google\\genai\\_api_client.py:488\u001b[0m, in \u001b[0;36mBaseApiClient._request\u001b[1;34m(self, http_request, stream)\u001b[0m\n\u001b[0;32m    484\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m HttpResponse(\n\u001b[0;32m    485\u001b[0m       response\u001b[38;5;241m.\u001b[39mheaders, response \u001b[38;5;28;01mif\u001b[39;00m stream \u001b[38;5;28;01melse\u001b[39;00m [response\u001b[38;5;241m.\u001b[39mtext]\n\u001b[0;32m    486\u001b[0m   )\n\u001b[0;32m    487\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 488\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_request_unauthorized(http_request, stream)\n",
      "File \u001b[1;32mc:\\Users\\Tammy\\anaconda3\\Lib\\site-packages\\google\\genai\\_api_client.py:503\u001b[0m, in \u001b[0;36mBaseApiClient._request_unauthorized\u001b[1;34m(self, http_request, stream)\u001b[0m\n\u001b[0;32m    500\u001b[0m     data \u001b[38;5;241m=\u001b[39m http_request\u001b[38;5;241m.\u001b[39mdata\n\u001b[0;32m    502\u001b[0m http_session \u001b[38;5;241m=\u001b[39m requests\u001b[38;5;241m.\u001b[39mSession()\n\u001b[1;32m--> 503\u001b[0m response \u001b[38;5;241m=\u001b[39m http_session\u001b[38;5;241m.\u001b[39mrequest(\n\u001b[0;32m    504\u001b[0m     method\u001b[38;5;241m=\u001b[39mhttp_request\u001b[38;5;241m.\u001b[39mmethod,\n\u001b[0;32m    505\u001b[0m     url\u001b[38;5;241m=\u001b[39mhttp_request\u001b[38;5;241m.\u001b[39murl,\n\u001b[0;32m    506\u001b[0m     headers\u001b[38;5;241m=\u001b[39mhttp_request\u001b[38;5;241m.\u001b[39mheaders,\n\u001b[0;32m    507\u001b[0m     data\u001b[38;5;241m=\u001b[39mdata,\n\u001b[0;32m    508\u001b[0m     timeout\u001b[38;5;241m=\u001b[39mhttp_request\u001b[38;5;241m.\u001b[39mtimeout,\n\u001b[0;32m    509\u001b[0m     stream\u001b[38;5;241m=\u001b[39mstream,\n\u001b[0;32m    510\u001b[0m )\n\u001b[0;32m    511\u001b[0m errors\u001b[38;5;241m.\u001b[39mAPIError\u001b[38;5;241m.\u001b[39mraise_for_response(response)\n\u001b[0;32m    512\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m HttpResponse(\n\u001b[0;32m    513\u001b[0m     response\u001b[38;5;241m.\u001b[39mheaders, response \u001b[38;5;28;01mif\u001b[39;00m stream \u001b[38;5;28;01melse\u001b[39;00m [response\u001b[38;5;241m.\u001b[39mtext]\n\u001b[0;32m    514\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\Tammy\\anaconda3\\Lib\\site-packages\\requests\\sessions.py:589\u001b[0m, in \u001b[0;36mSession.request\u001b[1;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[0;32m    584\u001b[0m send_kwargs \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m    585\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimeout\u001b[39m\u001b[38;5;124m\"\u001b[39m: timeout,\n\u001b[0;32m    586\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow_redirects\u001b[39m\u001b[38;5;124m\"\u001b[39m: allow_redirects,\n\u001b[0;32m    587\u001b[0m }\n\u001b[0;32m    588\u001b[0m send_kwargs\u001b[38;5;241m.\u001b[39mupdate(settings)\n\u001b[1;32m--> 589\u001b[0m resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msend(prep, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39msend_kwargs)\n\u001b[0;32m    591\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "File \u001b[1;32mc:\\Users\\Tammy\\anaconda3\\Lib\\site-packages\\requests\\sessions.py:703\u001b[0m, in \u001b[0;36mSession.send\u001b[1;34m(self, request, **kwargs)\u001b[0m\n\u001b[0;32m    700\u001b[0m start \u001b[38;5;241m=\u001b[39m preferred_clock()\n\u001b[0;32m    702\u001b[0m \u001b[38;5;66;03m# Send the request\u001b[39;00m\n\u001b[1;32m--> 703\u001b[0m r \u001b[38;5;241m=\u001b[39m adapter\u001b[38;5;241m.\u001b[39msend(request, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    705\u001b[0m \u001b[38;5;66;03m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[0;32m    706\u001b[0m elapsed \u001b[38;5;241m=\u001b[39m preferred_clock() \u001b[38;5;241m-\u001b[39m start\n",
      "File \u001b[1;32mc:\\Users\\Tammy\\anaconda3\\Lib\\site-packages\\requests\\adapters.py:667\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[1;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[0;32m    664\u001b[0m     timeout \u001b[38;5;241m=\u001b[39m TimeoutSauce(connect\u001b[38;5;241m=\u001b[39mtimeout, read\u001b[38;5;241m=\u001b[39mtimeout)\n\u001b[0;32m    666\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 667\u001b[0m     resp \u001b[38;5;241m=\u001b[39m conn\u001b[38;5;241m.\u001b[39murlopen(\n\u001b[0;32m    668\u001b[0m         method\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mmethod,\n\u001b[0;32m    669\u001b[0m         url\u001b[38;5;241m=\u001b[39murl,\n\u001b[0;32m    670\u001b[0m         body\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mbody,\n\u001b[0;32m    671\u001b[0m         headers\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mheaders,\n\u001b[0;32m    672\u001b[0m         redirect\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    673\u001b[0m         assert_same_host\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    674\u001b[0m         preload_content\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    675\u001b[0m         decode_content\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    676\u001b[0m         retries\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_retries,\n\u001b[0;32m    677\u001b[0m         timeout\u001b[38;5;241m=\u001b[39mtimeout,\n\u001b[0;32m    678\u001b[0m         chunked\u001b[38;5;241m=\u001b[39mchunked,\n\u001b[0;32m    679\u001b[0m     )\n\u001b[0;32m    681\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (ProtocolError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m    682\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m(err, request\u001b[38;5;241m=\u001b[39mrequest)\n",
      "File \u001b[1;32mc:\\Users\\Tammy\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py:789\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[0;32m    786\u001b[0m response_conn \u001b[38;5;241m=\u001b[39m conn \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m release_conn \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    788\u001b[0m \u001b[38;5;66;03m# Make the request on the HTTPConnection object\u001b[39;00m\n\u001b[1;32m--> 789\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_request(\n\u001b[0;32m    790\u001b[0m     conn,\n\u001b[0;32m    791\u001b[0m     method,\n\u001b[0;32m    792\u001b[0m     url,\n\u001b[0;32m    793\u001b[0m     timeout\u001b[38;5;241m=\u001b[39mtimeout_obj,\n\u001b[0;32m    794\u001b[0m     body\u001b[38;5;241m=\u001b[39mbody,\n\u001b[0;32m    795\u001b[0m     headers\u001b[38;5;241m=\u001b[39mheaders,\n\u001b[0;32m    796\u001b[0m     chunked\u001b[38;5;241m=\u001b[39mchunked,\n\u001b[0;32m    797\u001b[0m     retries\u001b[38;5;241m=\u001b[39mretries,\n\u001b[0;32m    798\u001b[0m     response_conn\u001b[38;5;241m=\u001b[39mresponse_conn,\n\u001b[0;32m    799\u001b[0m     preload_content\u001b[38;5;241m=\u001b[39mpreload_content,\n\u001b[0;32m    800\u001b[0m     decode_content\u001b[38;5;241m=\u001b[39mdecode_content,\n\u001b[0;32m    801\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mresponse_kw,\n\u001b[0;32m    802\u001b[0m )\n\u001b[0;32m    804\u001b[0m \u001b[38;5;66;03m# Everything went great!\u001b[39;00m\n\u001b[0;32m    805\u001b[0m clean_exit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Tammy\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py:536\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[1;34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[0m\n\u001b[0;32m    534\u001b[0m \u001b[38;5;66;03m# Receive the response from the server\u001b[39;00m\n\u001b[0;32m    535\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 536\u001b[0m     response \u001b[38;5;241m=\u001b[39m conn\u001b[38;5;241m.\u001b[39mgetresponse()\n\u001b[0;32m    537\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (BaseSSLError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    538\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_raise_timeout(err\u001b[38;5;241m=\u001b[39me, url\u001b[38;5;241m=\u001b[39murl, timeout_value\u001b[38;5;241m=\u001b[39mread_timeout)\n",
      "File \u001b[1;32mc:\\Users\\Tammy\\anaconda3\\Lib\\site-packages\\urllib3\\connection.py:507\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    504\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mresponse\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m HTTPResponse\n\u001b[0;32m    506\u001b[0m \u001b[38;5;66;03m# Get the response from http.client.HTTPConnection\u001b[39;00m\n\u001b[1;32m--> 507\u001b[0m httplib_response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mgetresponse()\n\u001b[0;32m    509\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    510\u001b[0m     assert_header_parsing(httplib_response\u001b[38;5;241m.\u001b[39mmsg)\n",
      "File \u001b[1;32mc:\\Users\\Tammy\\anaconda3\\Lib\\http\\client.py:1428\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1426\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1427\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1428\u001b[0m         response\u001b[38;5;241m.\u001b[39mbegin()\n\u001b[0;32m   1429\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m:\n\u001b[0;32m   1430\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[1;32mc:\\Users\\Tammy\\anaconda3\\Lib\\http\\client.py:331\u001b[0m, in \u001b[0;36mHTTPResponse.begin\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    329\u001b[0m \u001b[38;5;66;03m# read until we get a non-100 response\u001b[39;00m\n\u001b[0;32m    330\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m--> 331\u001b[0m     version, status, reason \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_read_status()\n\u001b[0;32m    332\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m status \u001b[38;5;241m!=\u001b[39m CONTINUE:\n\u001b[0;32m    333\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Tammy\\anaconda3\\Lib\\http\\client.py:292\u001b[0m, in \u001b[0;36mHTTPResponse._read_status\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    291\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_read_status\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m--> 292\u001b[0m     line \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfp\u001b[38;5;241m.\u001b[39mreadline(_MAXLINE \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124miso-8859-1\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    293\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(line) \u001b[38;5;241m>\u001b[39m _MAXLINE:\n\u001b[0;32m    294\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m LineTooLong(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstatus line\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Tammy\\anaconda3\\Lib\\socket.py:720\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[1;34m(self, b)\u001b[0m\n\u001b[0;32m    718\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m    719\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 720\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sock\u001b[38;5;241m.\u001b[39mrecv_into(b)\n\u001b[0;32m    721\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[0;32m    722\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout_occurred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Tammy\\anaconda3\\Lib\\ssl.py:1251\u001b[0m, in \u001b[0;36mSSLSocket.recv_into\u001b[1;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[0;32m   1247\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m flags \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m   1248\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1249\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[0;32m   1250\u001b[0m           \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m)\n\u001b[1;32m-> 1251\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mread(nbytes, buffer)\n\u001b[0;32m   1252\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1253\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mrecv_into(buffer, nbytes, flags)\n",
      "File \u001b[1;32mc:\\Users\\Tammy\\anaconda3\\Lib\\ssl.py:1103\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[1;34m(self, len, buffer)\u001b[0m\n\u001b[0;32m   1101\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1102\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m buffer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1103\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sslobj\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;28mlen\u001b[39m, buffer)\n\u001b[0;32m   1104\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1105\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sslobj\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;28mlen\u001b[39m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "def process_headlines_with_separate_models(df, sentiment_column):\n",
    "    # sentiment_list = []\n",
    "    sentiment_score_list = []\n",
    "    # trend_strength_list = []\n",
    "    impact_days_list = []\n",
    "    \n",
    "    # Process with first model (sentiment and trend)\n",
    "    for idx, headline in tqdm(enumerate(df[sentiment_column]), total=len(df), desc=\"Processing Sentiment\", unit=\"headline\"):\n",
    "        # Get sentiment and trend predictions\n",
    "        result = analyze_sentiment_trend(headline)\n",
    "        \n",
    "        if isinstance(result, dict) and 'SentimentScore' in result:\n",
    "            sentiment_score = result['SentimentScore']\n",
    "            \n",
    "            # Store values\n",
    "            sentiment_score_list.append(sentiment_score)\n",
    "        #     # Determine categorical sentiment\n",
    "        #     if sentiment_score == 1.0:\n",
    "        #         sentiment = 'Extremely Positive'\n",
    "        #     elif sentiment_score >= 0.8:\n",
    "        #         sentiment = 'Very Positive'\n",
    "        #     elif sentiment_score >= 0.5:\n",
    "        #         sentiment = 'Moderately Positive'\n",
    "        #     elif sentiment_score >= 0.2:\n",
    "        #         sentiment = 'Slightly Positive'\n",
    "        #     elif sentiment_score == 0.0:\n",
    "        #         sentiment = 'Neutral'\n",
    "        #     elif sentiment_score >= -0.2:\n",
    "        #         sentiment = 'Slightly Negative'\n",
    "        #     elif sentiment_score >= -0.5:\n",
    "        #         sentiment = 'Moderately Negative'\n",
    "        #     elif sentiment_score >= -0.8:\n",
    "        #         sentiment = 'Very Negative'\n",
    "        #     else:\n",
    "        #         sentiment = 'Extremely Negative'\n",
    "            \n",
    "        #     sentiment_list.append(sentiment)\n",
    "        # else:\n",
    "        #     # Handle error case\n",
    "        #     sentiment_list.append('Error')\n",
    "        #     sentiment_score_list.append(None)\n",
    "        #     trend_strength_list.append(None)\n",
    "    \n",
    "    # Add sentiment and trend to DataFrame\n",
    "    # df['gemini_sentiment'] = sentiment_list\n",
    "    df['sentiment_score'] = sentiment_score_list\n",
    "    # df['trend_strength'] = trend_strength_list\n",
    "    \n",
    "    # Process with second model (duration)\n",
    "    for idx, headline in tqdm(enumerate(df[sentiment_column]), total=len(df), desc=\"Processing Duration\", unit=\"headline\"):\n",
    "        # Get duration prediction\n",
    "        result = analyze_duration(headline)\n",
    "        \n",
    "        if isinstance(result, dict) and 'PotentialImpactDays' in result:\n",
    "            impact_days = result['PotentialImpactDays']\n",
    "            impact_days_list.append(impact_days)\n",
    "        else:\n",
    "            # Handle error case\n",
    "            impact_days_list.append(None)\n",
    "    \n",
    "    # Add duration to DataFrame\n",
    "    df['impact_days'] = impact_days_list\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Apply the separate models\n",
    "df_analyzed = process_headlines_with_separate_models(df_new, 'headline')\n",
    "\n",
    "# Display results\n",
    "print(df_analyzed[['pub_date', 'headline', 'sentiment_score', 'impact_days']])\n",
    "\n",
    "# Save to CSV\n",
    "df_analyzed.to_csv('gemini_headline_features_predictions.csv', index= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pub_date</th>\n",
       "      <th>headline</th>\n",
       "      <th>sentiment_score</th>\n",
       "      <th>impact_days</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-04-07</td>\n",
       "      <td>mba programs that get you where you want to go</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015-04-14</td>\n",
       "      <td>what were reading</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015-04-13</td>\n",
       "      <td>ibm creates watson health to analyze medical data</td>\n",
       "      <td>0.4</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015-04-22</td>\n",
       "      <td>whats that on beyoncs wrist let me guess an ap...</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015-04-01</td>\n",
       "      <td>daily report tech leaders come together to opp...</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     pub_date                                           headline  \\\n",
       "0  2015-04-07     mba programs that get you where you want to go   \n",
       "1  2015-04-14                                  what were reading   \n",
       "2  2015-04-13  ibm creates watson health to analyze medical data   \n",
       "3  2015-04-22  whats that on beyoncs wrist let me guess an ap...   \n",
       "4  2015-04-01  daily report tech leaders come together to opp...   \n",
       "\n",
       "   sentiment_score  impact_days  \n",
       "0              0.0            3  \n",
       "1              0.0            1  \n",
       "2              0.4            8  \n",
       "3              0.1            1  \n",
       "4             -0.2            7  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_analyzed.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Archive to be ignored"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel\n",
    "\n",
    "class SentimentTrendPrediction(BaseModel):\n",
    "    SentimentScore: float\n",
    "    TrendStrength: float    # Predicted price as a string (could be float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Setting up Gemini\n",
    "#set up gemini to process textual templates\n",
    "from google import genai\n",
    "from dotenv import load_dotenv\n",
    "from pydantic import BaseModel\n",
    "import os\n",
    "load_dotenv()\n",
    "# Load environment variables from the .env file\n",
    "API_KEY = os.getenv(\"API_KEY\")\n",
    "client = genai.Client(api_key=API_KEY)#insert api key\n",
    "## Function to call Gemini API\n",
    "from google.genai import types\n",
    "import json\n",
    "\n",
    "# Function to get sentiment based on model output\n",
    "def gemini_predict_sentiment_trend(prompt, return_json=False):\n",
    "    try:\n",
    "        # Generate content from the model\n",
    "        response = client.models.generate_content(\n",
    "            model='gemini-2.0-flash-lite', \n",
    "            contents=prompt,\n",
    "            config=types.GenerateContentConfig(\n",
    "            system_instruction= f\"\"\"\n",
    "            You are a financial analyst specializing in both quantitative market sentiment and trend analysis. Your task is to analyze each headline and provide two precise metrics:\n",
    "\n",
    "            1. **Sentiment Score (-1.0 to 1.0)**:\n",
    "            - -1.0: Extremely negative news (bankruptcy, massive fraud, severe regulatory action)\n",
    "            - 0.0: Neutral or balanced news (mixed results, status quo maintained)\n",
    "            - 1.0: Extremely positive news (breakthrough products, industry-changing acquisitions)\n",
    "            - Consider both **direct effects on Appleâ€™s stock price** and **general market or sector trends**.\n",
    "\n",
    "            2. **Trend Strength (-1.0 to 1.0)**:\n",
    "            - -1.0: Strong downward trend (systemic issues, prolonged negative impact)\n",
    "            - 0.0: Neutral impact (unlikely to drive directional market movement)\n",
    "            - 1.0: Strong upward trend (transformative positive developments)\n",
    "            - Evaluate whether the headline indicates a short-term price reaction or a long-term trend based on Appleâ€™s role in the tech sector**.\n",
    "\n",
    "            CRITICAL INSTRUCTIONS:\n",
    "            - Differentiate Sentiment (emotional tone) vs. Trend Strength (market momentum).\n",
    "            - Evaluate Apple's stock movement within the broader tech industry context and the overall market sentiment.\n",
    "            - For ambiguous headlines, default to moderate scores (-0.5 to +0.5 range).\n",
    "            - Return ONLY the two values in JSON format like:\n",
    "            {{ \"SentimentScore\": 0.5, \"TrendStrength\": 0.6 }}\n",
    "            \"\"\"\n",
    ",\n",
    "            max_output_tokens=75,  # Label only\n",
    "            temperature=0.5,      # More flexibility\n",
    "            top_k=5,              # Limit to top 5 choices\n",
    "            top_p=0.7,            # Consider tokens covering 70% probability mass\n",
    "            response_mime_type='application/json',\n",
    "            response_schema=SentimentTrendPrediction\n",
    "          # No stop sequence to avoid premature stops\n",
    "            )\n",
    "        )\n",
    "        \n",
    "        # Check if the response is valid\n",
    "        response_text = response.text.strip()\n",
    "        if not response_text:\n",
    "            print(\"Error: No response text found.\")\n",
    "            return 'Error' if not return_json else {}\n",
    "\n",
    "        # Try parsing the response as JSON\n",
    "        try:\n",
    "            response_json = json.loads(response_text)\n",
    "            if return_json:\n",
    "                return response_json\n",
    "\n",
    "            return response_json\n",
    "\n",
    "        except json.JSONDecodeError:\n",
    "            print(f\"Error parsing JSON. Response: {response_text}\")\n",
    "            return 'Error' if not return_json else {}\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"API Error: {e}\")\n",
    "        return 'Error' if not return_json else {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For Headlines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Experiment with few-shot prompting\n",
    "def analyze_sentiment_trend(text): #alter prompt for abstract\n",
    "    prompt = f\"\"\"\n",
    "    Analyze this financial headline and provide two metrics: \n",
    "    1. Sentiment Score: from -1.0 (extremely negative) to 1.0 (extremely positive)\n",
    "    2. Trend Strength: from -1.0 (strong downward trend) to 1.0 (strong upward trend)\n",
    "\n",
    "    Return results in JSON format like:\n",
    "    {{ \"SentimentScore\": X.X, \"TrendStrength\": Y.Y }}\n",
    "\n",
    "    Here are some examples with SentimentScore and TrendStrength:\n",
    "\n",
    "    Example 1: \n",
    "    Headline: \"Company Close to Finalizing Its 40 billion dollar funding.\" \n",
    "    {{ \"SentimentScore\": 0.9, \"TrendStrength\": 0.8 }}\n",
    "\n",
    "    Example 2: \n",
    "    Headline: \"Regulatory authorities block 10% of funds for key agency in US-China Tech Race.\"\n",
    "    {{ \"SentimentScore\": -0.8, \"TrendStrength\": -0.6 }}\n",
    "\n",
    "    Example 3: \n",
    "    Headline: \"Why Company B could be a key to a Company C's Deal.\"\n",
    "    {{ \"SentimentScore\": 0.2, \"TrendStrength\": 0.1 }}\n",
    "\n",
    "    Example 4: \n",
    "    Headline: \"Artificial intelligence boom might help mitigate some tariff pain.\"\n",
    "    {{ \"SentimentScore\": 0.3, \"TrendStrength\": 0.2 }}\n",
    "\n",
    "    Example 5: \n",
    "    Headline: \"Major banks face regulatory hurdles, impacting earnings outlook.\"\n",
    "    {{ \"SentimentScore\": -0.6, \"TrendStrength\": -0.5 }}\n",
    "\n",
    "    Example 6: \n",
    "    Headline: \"Company's $32 billion deal may signal a turning point for slow IPO, M&A markets.\"\n",
    "    {{ \"SentimentScore\": 0.8, \"TrendStrength\": 0.7 }}\n",
    "\n",
    "    Example 7: \n",
    "    Headline: \"Company X enters a strategic partnership with Company Y to expand its operations in Asia.\"\n",
    "    Sentiment Score: 0.7\n",
    "    {{ \"SentimentScore\": 0.7, \"TrendStrength\": 0.6 }}\n",
    "\n",
    "    Now, analyze this headline:\n",
    "\n",
    "    Headline: \"{text}\"\n",
    "    Response (in JSON format):\n",
    "   {{ \"SentimentScore\": , \"TrendStrength\": }}\"\"\"\n",
    "    \n",
    "    result = gemini_predict_sentiment_trend(prompt)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function for news impact duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DurationPrediction(BaseModel):\n",
    "    PotentialImpactDays: int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for duration prediction\n",
    "def gemini_predict_duration(prompt, return_json=False):\n",
    "    try:\n",
    "        # Generate content from the model\n",
    "        response = client.models.generate_content(\n",
    "            model='gemini-2.0-flash-lite', \n",
    "            contents=prompt,\n",
    "            config=types.GenerateContentConfig(\n",
    "                system_instruction=\"\"\"\n",
    "                You are a financial market expert specializing in estimating the impact duration of financial news. Your task is to analyze each headline and estimate how long its impact will last on the stock market.\n",
    "\n",
    "                Consider:\n",
    "                - **1-3 days**: Short-lived news (minor developments, non-urgent reactions).\n",
    "                - **4-7 days**: Moderately impactful news (earnings reports, key regulatory actions).\n",
    "                - **8-14 days**: Significant developments (corporate mergers, product announcements).\n",
    "                - **15-30 days**: Major structural changes (industry shifts, global economic impacts).\n",
    "\n",
    "                For Apple-specific news, consider historical precedents for how similar news has impacted Apple's stock in the past. For market-wide or industry news, estimate how long the ripple effects might last, considering Apple's role in the tech sector.\n",
    "\n",
    "                Return only the result in JSON format like:\n",
    "                {{ \"PotentialImpactDays\": Z }}\n",
    "                \"\"\",\n",
    "                max_output_tokens=50,\n",
    "                temperature=0.5,\n",
    "                top_k=5,\n",
    "                top_p=0.7,\n",
    "                response_mime_type='application/json',\n",
    "                response_schema=DurationPrediction\n",
    "            )\n",
    "        )\n",
    "        \n",
    "        # Check if the response is valid\n",
    "        response_text = response.text.strip()\n",
    "        if not response_text:\n",
    "            print(\"Error: No response text found.\")\n",
    "            return 'Error' if not return_json else {}\n",
    "\n",
    "        # Try parsing the response as JSON\n",
    "        try:\n",
    "            response_json = json.loads(response_text)\n",
    "            if return_json:\n",
    "                return response_json\n",
    "\n",
    "            return response_json\n",
    "\n",
    "        except json.JSONDecodeError:\n",
    "            print(f\"Error parsing JSON. Response: {response_text}\")\n",
    "            return 'Error' if not return_json else {}\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"API Error: {e}\")\n",
    "        return 'Error' if not return_json else {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_duration(text):\n",
    "    prompt = f\"\"\"\n",
    "    Analyze this financial headline and estimate how many days (1-30) this news might impact the market.\n",
    "    Consider: \n",
    "    - 1-3 days for short-lived news\n",
    "    - 4-7 days for moderately impactful news \n",
    "    - 8-14 days for significant developments\n",
    "    - 15-30 days for major structural changes or significant corporate events\n",
    "    Additionally, for Apple-specific news (e.g., product launches, earnings results), consider the **historical reaction of Apple's stock and the potential market sentiment based on previous similar events.\n",
    "\n",
    "    For market-wide news (e.g., interest rate changes, regulatory updates), estimate how it will ripple through the tech sector and its potential impact on Apple stock.\n",
    "\n",
    "    Return result in JSON format like:\n",
    "    {{ \"PotentialImpactDays\": Z }}\n",
    "\n",
    "    Examples:\n",
    "\n",
    "    Example 1: \n",
    "    Headline: \"Company close to finalizing its 40 billion dollar funding.\" \n",
    "    {{ \"PotentialImpactDays\": 14 }}\n",
    "\n",
    "    Example 2: \n",
    "    Headline: \"Regulatory authorities block 10% of funds for key agency in US-China Tech Race.\"\n",
    "    {{ \"PotentialImpactDays\": 7 }}\n",
    "\n",
    "    Example 3: \n",
    "    Headline: \"Why Company B could be a key to a Company C's Deal.\"\n",
    "    {{ \"PotentialImpactDays\": 3 }}\n",
    "\n",
    "    Example 4: \n",
    "    Headline: \"Artificial intelligence boom might help mitigate some tariff pain.\"\n",
    "    {{ \"PotentialImpactDays\": 5 }}\n",
    "\n",
    "    Example 5: \n",
    "    Headline: \"Major banks face regulatory hurdles, impacting earnings outlook.\"\n",
    "    {{ \"PotentialImpactDays\": 10 }}\n",
    "\n",
    "    Example 6: \n",
    "    Headline: \"Company's $32 billion deal may signal a turning point for slow IPO, M&A markets.\"\n",
    "    {{ \"PotentialImpactDays\": 10 }}\n",
    "\n",
    "    Now analyze this headline:\n",
    "    Headline: \"{text}\"\n",
    "    \"\"\"\n",
    "    \n",
    "    result = gemini_predict_duration(prompt)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Sentiment & Trend: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:10<00:00,  1.00s/headline]\n",
      "Processing Duration:  20%|â–ˆâ–ˆ        | 2/10 [00:02<00:11,  1.38s/headline]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 72\u001b[0m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m df\n\u001b[0;32m     71\u001b[0m \u001b[38;5;66;03m# Apply the separate models\u001b[39;00m\n\u001b[1;32m---> 72\u001b[0m df_analyzed \u001b[38;5;241m=\u001b[39m process_headlines_with_separate_models(df_new, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mheadline\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     74\u001b[0m \u001b[38;5;66;03m# Display results\u001b[39;00m\n\u001b[0;32m     75\u001b[0m \u001b[38;5;28mprint\u001b[39m(df_analyzed[[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpub_date\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mheadline\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgemini_sentiment\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msentiment_score\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrend_strength\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimpact_days\u001b[39m\u001b[38;5;124m'\u001b[39m]])\n",
      "Cell \u001b[1;32mIn[16], line 57\u001b[0m, in \u001b[0;36mprocess_headlines_with_separate_models\u001b[1;34m(df, sentiment_column)\u001b[0m\n\u001b[0;32m     54\u001b[0m \u001b[38;5;66;03m# Process with second model (duration)\u001b[39;00m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m idx, headline \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28menumerate\u001b[39m(df[sentiment_column]), total\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(df), desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mProcessing Duration\u001b[39m\u001b[38;5;124m\"\u001b[39m, unit\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mheadline\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m     56\u001b[0m     \u001b[38;5;66;03m# Get duration prediction\u001b[39;00m\n\u001b[1;32m---> 57\u001b[0m     result \u001b[38;5;241m=\u001b[39m analyze_duration(headline)\n\u001b[0;32m     59\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(result, \u001b[38;5;28mdict\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPotentialImpactDays\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m result:\n\u001b[0;32m     60\u001b[0m         impact_days \u001b[38;5;241m=\u001b[39m result[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPotentialImpactDays\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "Cell \u001b[1;32mIn[15], line 46\u001b[0m, in \u001b[0;36manalyze_duration\u001b[1;34m(text)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21manalyze_duration\u001b[39m(text):\n\u001b[0;32m      2\u001b[0m     prompt \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;124m    Analyze this financial headline and estimate how many days (1-30) this news might impact the market.\u001b[39m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;124m    Consider: \u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     43\u001b[0m \u001b[38;5;124m    Headline: \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtext\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     44\u001b[0m \u001b[38;5;124m    \u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[1;32m---> 46\u001b[0m     result \u001b[38;5;241m=\u001b[39m gemini_predict_duration(prompt)\n\u001b[0;32m     47\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "Cell \u001b[1;32mIn[14], line 5\u001b[0m, in \u001b[0;36mgemini_predict_duration\u001b[1;34m(prompt, return_json)\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgemini_predict_duration\u001b[39m(prompt, return_json\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m      3\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m      4\u001b[0m         \u001b[38;5;66;03m# Generate content from the model\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m         response \u001b[38;5;241m=\u001b[39m client\u001b[38;5;241m.\u001b[39mmodels\u001b[38;5;241m.\u001b[39mgenerate_content(\n\u001b[0;32m      6\u001b[0m             model\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgemini-2.0-flash-lite\u001b[39m\u001b[38;5;124m'\u001b[39m, \n\u001b[0;32m      7\u001b[0m             contents\u001b[38;5;241m=\u001b[39mprompt,\n\u001b[0;32m      8\u001b[0m             config\u001b[38;5;241m=\u001b[39mtypes\u001b[38;5;241m.\u001b[39mGenerateContentConfig(\n\u001b[0;32m      9\u001b[0m                 system_instruction\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;124m                You are a financial market expert specializing in estimating the impact duration of financial news. Your task is to analyze each headline and estimate how long its impact will last on the stock market.\u001b[39m\n\u001b[0;32m     11\u001b[0m \n\u001b[0;32m     12\u001b[0m \u001b[38;5;124m                Consider:\u001b[39m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;124m                - **1-3 days**: Short-lived news (minor developments, non-urgent reactions).\u001b[39m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;124m                - **4-7 days**: Moderately impactful news (earnings reports, key regulatory actions).\u001b[39m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;124m                - **8-14 days**: Significant developments (corporate mergers, product announcements).\u001b[39m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;124m                - **15-30 days**: Major structural changes (industry shifts, global economic impacts).\u001b[39m\n\u001b[0;32m     17\u001b[0m \n\u001b[0;32m     18\u001b[0m \u001b[38;5;124m                For Apple-specific news, consider historical precedents for how similar news has impacted Apple\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ms stock in the past. For market-wide or industry news, estimate how long the ripple effects might last, considering Apple\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ms role in the tech sector.\u001b[39m\n\u001b[0;32m     19\u001b[0m \n\u001b[0;32m     20\u001b[0m \u001b[38;5;124m                Return only the result in JSON format like:\u001b[39m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;124m                \u001b[39m\u001b[38;5;124m{{\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPotentialImpactDays\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m: Z }}\u001b[39m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;124m                \u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m,\n\u001b[0;32m     23\u001b[0m                 max_output_tokens\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m50\u001b[39m,\n\u001b[0;32m     24\u001b[0m                 temperature\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.5\u001b[39m,\n\u001b[0;32m     25\u001b[0m                 top_k\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m,\n\u001b[0;32m     26\u001b[0m                 top_p\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.7\u001b[39m,\n\u001b[0;32m     27\u001b[0m                 response_mime_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mapplication/json\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m     28\u001b[0m                 response_schema\u001b[38;5;241m=\u001b[39mDurationPrediction\n\u001b[0;32m     29\u001b[0m             )\n\u001b[0;32m     30\u001b[0m         )\n\u001b[0;32m     32\u001b[0m         \u001b[38;5;66;03m# Check if the response is valid\u001b[39;00m\n\u001b[0;32m     33\u001b[0m         response_text \u001b[38;5;241m=\u001b[39m response\u001b[38;5;241m.\u001b[39mtext\u001b[38;5;241m.\u001b[39mstrip()\n",
      "File \u001b[1;32mc:\\Users\\Tammy\\anaconda3\\Lib\\site-packages\\google\\genai\\models.py:5304\u001b[0m, in \u001b[0;36mModels.generate_content\u001b[1;34m(self, model, contents, config)\u001b[0m\n\u001b[0;32m   5302\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m remaining_remote_calls_afc \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m   5303\u001b[0m   i \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m-> 5304\u001b[0m   response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate_content(\n\u001b[0;32m   5305\u001b[0m       model\u001b[38;5;241m=\u001b[39mmodel, contents\u001b[38;5;241m=\u001b[39mcontents, config\u001b[38;5;241m=\u001b[39mconfig\n\u001b[0;32m   5306\u001b[0m   )\n\u001b[0;32m   5307\u001b[0m   logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAFC remote call \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m is done.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m   5308\u001b[0m   remaining_remote_calls_afc \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\Tammy\\anaconda3\\Lib\\site-packages\\google\\genai\\models.py:4272\u001b[0m, in \u001b[0;36mModels._generate_content\u001b[1;34m(self, model, contents, config)\u001b[0m\n\u001b[0;32m   4269\u001b[0m request_dict \u001b[38;5;241m=\u001b[39m _common\u001b[38;5;241m.\u001b[39mconvert_to_dict(request_dict)\n\u001b[0;32m   4270\u001b[0m request_dict \u001b[38;5;241m=\u001b[39m _common\u001b[38;5;241m.\u001b[39mencode_unserializable_types(request_dict)\n\u001b[1;32m-> 4272\u001b[0m response_dict \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_api_client\u001b[38;5;241m.\u001b[39mrequest(\n\u001b[0;32m   4273\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpost\u001b[39m\u001b[38;5;124m'\u001b[39m, path, request_dict, http_options\n\u001b[0;32m   4274\u001b[0m )\n\u001b[0;32m   4276\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_api_client\u001b[38;5;241m.\u001b[39mvertexai:\n\u001b[0;32m   4277\u001b[0m   response_dict \u001b[38;5;241m=\u001b[39m _GenerateContentResponse_from_vertex(\n\u001b[0;32m   4278\u001b[0m       \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_api_client, response_dict\n\u001b[0;32m   4279\u001b[0m   )\n",
      "File \u001b[1;32mc:\\Users\\Tammy\\anaconda3\\Lib\\site-packages\\google\\genai\\_api_client.py:575\u001b[0m, in \u001b[0;36mBaseApiClient.request\u001b[1;34m(self, http_method, path, request_dict, http_options)\u001b[0m\n\u001b[0;32m    565\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrequest\u001b[39m(\n\u001b[0;32m    566\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    567\u001b[0m     http_method: \u001b[38;5;28mstr\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    570\u001b[0m     http_options: Optional[HttpOptionsOrDict] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    571\u001b[0m ):\n\u001b[0;32m    572\u001b[0m   http_request \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_request(\n\u001b[0;32m    573\u001b[0m       http_method, path, request_dict, http_options\n\u001b[0;32m    574\u001b[0m   )\n\u001b[1;32m--> 575\u001b[0m   response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_request(http_request, stream\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m    576\u001b[0m   json_response \u001b[38;5;241m=\u001b[39m response\u001b[38;5;241m.\u001b[39mjson\n\u001b[0;32m    577\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m json_response:\n",
      "File \u001b[1;32mc:\\Users\\Tammy\\anaconda3\\Lib\\site-packages\\google\\genai\\_api_client.py:488\u001b[0m, in \u001b[0;36mBaseApiClient._request\u001b[1;34m(self, http_request, stream)\u001b[0m\n\u001b[0;32m    484\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m HttpResponse(\n\u001b[0;32m    485\u001b[0m       response\u001b[38;5;241m.\u001b[39mheaders, response \u001b[38;5;28;01mif\u001b[39;00m stream \u001b[38;5;28;01melse\u001b[39;00m [response\u001b[38;5;241m.\u001b[39mtext]\n\u001b[0;32m    486\u001b[0m   )\n\u001b[0;32m    487\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 488\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_request_unauthorized(http_request, stream)\n",
      "File \u001b[1;32mc:\\Users\\Tammy\\anaconda3\\Lib\\site-packages\\google\\genai\\_api_client.py:503\u001b[0m, in \u001b[0;36mBaseApiClient._request_unauthorized\u001b[1;34m(self, http_request, stream)\u001b[0m\n\u001b[0;32m    500\u001b[0m     data \u001b[38;5;241m=\u001b[39m http_request\u001b[38;5;241m.\u001b[39mdata\n\u001b[0;32m    502\u001b[0m http_session \u001b[38;5;241m=\u001b[39m requests\u001b[38;5;241m.\u001b[39mSession()\n\u001b[1;32m--> 503\u001b[0m response \u001b[38;5;241m=\u001b[39m http_session\u001b[38;5;241m.\u001b[39mrequest(\n\u001b[0;32m    504\u001b[0m     method\u001b[38;5;241m=\u001b[39mhttp_request\u001b[38;5;241m.\u001b[39mmethod,\n\u001b[0;32m    505\u001b[0m     url\u001b[38;5;241m=\u001b[39mhttp_request\u001b[38;5;241m.\u001b[39murl,\n\u001b[0;32m    506\u001b[0m     headers\u001b[38;5;241m=\u001b[39mhttp_request\u001b[38;5;241m.\u001b[39mheaders,\n\u001b[0;32m    507\u001b[0m     data\u001b[38;5;241m=\u001b[39mdata,\n\u001b[0;32m    508\u001b[0m     timeout\u001b[38;5;241m=\u001b[39mhttp_request\u001b[38;5;241m.\u001b[39mtimeout,\n\u001b[0;32m    509\u001b[0m     stream\u001b[38;5;241m=\u001b[39mstream,\n\u001b[0;32m    510\u001b[0m )\n\u001b[0;32m    511\u001b[0m errors\u001b[38;5;241m.\u001b[39mAPIError\u001b[38;5;241m.\u001b[39mraise_for_response(response)\n\u001b[0;32m    512\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m HttpResponse(\n\u001b[0;32m    513\u001b[0m     response\u001b[38;5;241m.\u001b[39mheaders, response \u001b[38;5;28;01mif\u001b[39;00m stream \u001b[38;5;28;01melse\u001b[39;00m [response\u001b[38;5;241m.\u001b[39mtext]\n\u001b[0;32m    514\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\Tammy\\anaconda3\\Lib\\site-packages\\requests\\sessions.py:589\u001b[0m, in \u001b[0;36mSession.request\u001b[1;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[0;32m    584\u001b[0m send_kwargs \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m    585\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimeout\u001b[39m\u001b[38;5;124m\"\u001b[39m: timeout,\n\u001b[0;32m    586\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow_redirects\u001b[39m\u001b[38;5;124m\"\u001b[39m: allow_redirects,\n\u001b[0;32m    587\u001b[0m }\n\u001b[0;32m    588\u001b[0m send_kwargs\u001b[38;5;241m.\u001b[39mupdate(settings)\n\u001b[1;32m--> 589\u001b[0m resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msend(prep, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39msend_kwargs)\n\u001b[0;32m    591\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "File \u001b[1;32mc:\\Users\\Tammy\\anaconda3\\Lib\\site-packages\\requests\\sessions.py:703\u001b[0m, in \u001b[0;36mSession.send\u001b[1;34m(self, request, **kwargs)\u001b[0m\n\u001b[0;32m    700\u001b[0m start \u001b[38;5;241m=\u001b[39m preferred_clock()\n\u001b[0;32m    702\u001b[0m \u001b[38;5;66;03m# Send the request\u001b[39;00m\n\u001b[1;32m--> 703\u001b[0m r \u001b[38;5;241m=\u001b[39m adapter\u001b[38;5;241m.\u001b[39msend(request, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    705\u001b[0m \u001b[38;5;66;03m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[0;32m    706\u001b[0m elapsed \u001b[38;5;241m=\u001b[39m preferred_clock() \u001b[38;5;241m-\u001b[39m start\n",
      "File \u001b[1;32mc:\\Users\\Tammy\\anaconda3\\Lib\\site-packages\\requests\\adapters.py:667\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[1;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[0;32m    664\u001b[0m     timeout \u001b[38;5;241m=\u001b[39m TimeoutSauce(connect\u001b[38;5;241m=\u001b[39mtimeout, read\u001b[38;5;241m=\u001b[39mtimeout)\n\u001b[0;32m    666\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 667\u001b[0m     resp \u001b[38;5;241m=\u001b[39m conn\u001b[38;5;241m.\u001b[39murlopen(\n\u001b[0;32m    668\u001b[0m         method\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mmethod,\n\u001b[0;32m    669\u001b[0m         url\u001b[38;5;241m=\u001b[39murl,\n\u001b[0;32m    670\u001b[0m         body\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mbody,\n\u001b[0;32m    671\u001b[0m         headers\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mheaders,\n\u001b[0;32m    672\u001b[0m         redirect\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    673\u001b[0m         assert_same_host\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    674\u001b[0m         preload_content\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    675\u001b[0m         decode_content\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    676\u001b[0m         retries\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_retries,\n\u001b[0;32m    677\u001b[0m         timeout\u001b[38;5;241m=\u001b[39mtimeout,\n\u001b[0;32m    678\u001b[0m         chunked\u001b[38;5;241m=\u001b[39mchunked,\n\u001b[0;32m    679\u001b[0m     )\n\u001b[0;32m    681\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (ProtocolError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m    682\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m(err, request\u001b[38;5;241m=\u001b[39mrequest)\n",
      "File \u001b[1;32mc:\\Users\\Tammy\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py:789\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[0;32m    786\u001b[0m response_conn \u001b[38;5;241m=\u001b[39m conn \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m release_conn \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    788\u001b[0m \u001b[38;5;66;03m# Make the request on the HTTPConnection object\u001b[39;00m\n\u001b[1;32m--> 789\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_request(\n\u001b[0;32m    790\u001b[0m     conn,\n\u001b[0;32m    791\u001b[0m     method,\n\u001b[0;32m    792\u001b[0m     url,\n\u001b[0;32m    793\u001b[0m     timeout\u001b[38;5;241m=\u001b[39mtimeout_obj,\n\u001b[0;32m    794\u001b[0m     body\u001b[38;5;241m=\u001b[39mbody,\n\u001b[0;32m    795\u001b[0m     headers\u001b[38;5;241m=\u001b[39mheaders,\n\u001b[0;32m    796\u001b[0m     chunked\u001b[38;5;241m=\u001b[39mchunked,\n\u001b[0;32m    797\u001b[0m     retries\u001b[38;5;241m=\u001b[39mretries,\n\u001b[0;32m    798\u001b[0m     response_conn\u001b[38;5;241m=\u001b[39mresponse_conn,\n\u001b[0;32m    799\u001b[0m     preload_content\u001b[38;5;241m=\u001b[39mpreload_content,\n\u001b[0;32m    800\u001b[0m     decode_content\u001b[38;5;241m=\u001b[39mdecode_content,\n\u001b[0;32m    801\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mresponse_kw,\n\u001b[0;32m    802\u001b[0m )\n\u001b[0;32m    804\u001b[0m \u001b[38;5;66;03m# Everything went great!\u001b[39;00m\n\u001b[0;32m    805\u001b[0m clean_exit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Tammy\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py:536\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[1;34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[0m\n\u001b[0;32m    534\u001b[0m \u001b[38;5;66;03m# Receive the response from the server\u001b[39;00m\n\u001b[0;32m    535\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 536\u001b[0m     response \u001b[38;5;241m=\u001b[39m conn\u001b[38;5;241m.\u001b[39mgetresponse()\n\u001b[0;32m    537\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (BaseSSLError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    538\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_raise_timeout(err\u001b[38;5;241m=\u001b[39me, url\u001b[38;5;241m=\u001b[39murl, timeout_value\u001b[38;5;241m=\u001b[39mread_timeout)\n",
      "File \u001b[1;32mc:\\Users\\Tammy\\anaconda3\\Lib\\site-packages\\urllib3\\connection.py:507\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    504\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mresponse\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m HTTPResponse\n\u001b[0;32m    506\u001b[0m \u001b[38;5;66;03m# Get the response from http.client.HTTPConnection\u001b[39;00m\n\u001b[1;32m--> 507\u001b[0m httplib_response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mgetresponse()\n\u001b[0;32m    509\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    510\u001b[0m     assert_header_parsing(httplib_response\u001b[38;5;241m.\u001b[39mmsg)\n",
      "File \u001b[1;32mc:\\Users\\Tammy\\anaconda3\\Lib\\http\\client.py:1428\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1426\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1427\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1428\u001b[0m         response\u001b[38;5;241m.\u001b[39mbegin()\n\u001b[0;32m   1429\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m:\n\u001b[0;32m   1430\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[1;32mc:\\Users\\Tammy\\anaconda3\\Lib\\http\\client.py:331\u001b[0m, in \u001b[0;36mHTTPResponse.begin\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    329\u001b[0m \u001b[38;5;66;03m# read until we get a non-100 response\u001b[39;00m\n\u001b[0;32m    330\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m--> 331\u001b[0m     version, status, reason \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_read_status()\n\u001b[0;32m    332\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m status \u001b[38;5;241m!=\u001b[39m CONTINUE:\n\u001b[0;32m    333\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Tammy\\anaconda3\\Lib\\http\\client.py:292\u001b[0m, in \u001b[0;36mHTTPResponse._read_status\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    291\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_read_status\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m--> 292\u001b[0m     line \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfp\u001b[38;5;241m.\u001b[39mreadline(_MAXLINE \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124miso-8859-1\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    293\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(line) \u001b[38;5;241m>\u001b[39m _MAXLINE:\n\u001b[0;32m    294\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m LineTooLong(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstatus line\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Tammy\\anaconda3\\Lib\\socket.py:720\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[1;34m(self, b)\u001b[0m\n\u001b[0;32m    718\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m    719\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 720\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sock\u001b[38;5;241m.\u001b[39mrecv_into(b)\n\u001b[0;32m    721\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[0;32m    722\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout_occurred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Tammy\\anaconda3\\Lib\\ssl.py:1251\u001b[0m, in \u001b[0;36mSSLSocket.recv_into\u001b[1;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[0;32m   1247\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m flags \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m   1248\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1249\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[0;32m   1250\u001b[0m           \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m)\n\u001b[1;32m-> 1251\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mread(nbytes, buffer)\n\u001b[0;32m   1252\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1253\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mrecv_into(buffer, nbytes, flags)\n",
      "File \u001b[1;32mc:\\Users\\Tammy\\anaconda3\\Lib\\ssl.py:1103\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[1;34m(self, len, buffer)\u001b[0m\n\u001b[0;32m   1101\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1102\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m buffer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1103\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sslobj\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;28mlen\u001b[39m, buffer)\n\u001b[0;32m   1104\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1105\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sslobj\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;28mlen\u001b[39m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "def process_headlines_with_separate_models(df, sentiment_column):\n",
    "    sentiment_list = []\n",
    "    sentiment_score_list = []\n",
    "    trend_strength_list = []\n",
    "    impact_days_list = []\n",
    "    \n",
    "    # Process with first model (sentiment and trend)\n",
    "    for idx, headline in tqdm(enumerate(df[sentiment_column]), total=len(df), desc=\"Processing Sentiment & Trend\", unit=\"headline\"):\n",
    "        # Get sentiment and trend predictions\n",
    "        result = analyze_sentiment_trend(headline)\n",
    "        \n",
    "        if isinstance(result, dict) and 'SentimentScore' in result:\n",
    "            sentiment_score = result['SentimentScore']\n",
    "            trend_strength = result['TrendStrength']\n",
    "            \n",
    "            # Store values\n",
    "            sentiment_score_list.append(sentiment_score)\n",
    "            trend_strength_list.append(trend_strength)\n",
    "            \n",
    "            # Determine categorical sentiment\n",
    "            if sentiment_score == 1.0:\n",
    "                sentiment = 'Extremely Positive'\n",
    "            elif sentiment_score >= 0.8:\n",
    "                sentiment = 'Very Positive'\n",
    "            elif sentiment_score >= 0.5:\n",
    "                sentiment = 'Moderately Positive'\n",
    "            elif sentiment_score >= 0.2:\n",
    "                sentiment = 'Slightly Positive'\n",
    "            elif sentiment_score == 0.0:\n",
    "                sentiment = 'Neutral'\n",
    "            elif sentiment_score >= -0.2:\n",
    "                sentiment = 'Slightly Negative'\n",
    "            elif sentiment_score >= -0.5:\n",
    "                sentiment = 'Moderately Negative'\n",
    "            elif sentiment_score >= -0.8:\n",
    "                sentiment = 'Very Negative'\n",
    "            else:\n",
    "                sentiment = 'Extremely Negative'\n",
    "            \n",
    "            sentiment_list.append(sentiment)\n",
    "        else:\n",
    "            # Handle error case\n",
    "            sentiment_list.append('Error')\n",
    "            sentiment_score_list.append(None)\n",
    "            trend_strength_list.append(None)\n",
    "    \n",
    "    # Add sentiment and trend to DataFrame\n",
    "    df['gemini_sentiment'] = sentiment_list\n",
    "    df['sentiment_score'] = sentiment_score_list\n",
    "    df['trend_strength'] = trend_strength_list\n",
    "    \n",
    "    # Process with second model (duration)\n",
    "    for idx, headline in tqdm(enumerate(df[sentiment_column]), total=len(df), desc=\"Processing Duration\", unit=\"headline\"):\n",
    "        # Get duration prediction\n",
    "        result = analyze_duration(headline)\n",
    "        \n",
    "        if isinstance(result, dict) and 'PotentialImpactDays' in result:\n",
    "            impact_days = result['PotentialImpactDays']\n",
    "            impact_days_list.append(impact_days)\n",
    "        else:\n",
    "            # Handle error case\n",
    "            impact_days_list.append(None)\n",
    "    \n",
    "    # Add duration to DataFrame\n",
    "    df['impact_days'] = impact_days_list\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Apply the separate models\n",
    "df_analyzed = process_headlines_with_separate_models(df_new, 'headline')\n",
    "\n",
    "# Display results\n",
    "print(df_analyzed[['pub_date', 'headline', 'gemini_sentiment', 'sentiment_score', 'trend_strength', 'impact_days']])\n",
    "\n",
    "# Save to CSV\n",
    "df_analyzed.to_csv('gemini_headline_features_predictions.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
