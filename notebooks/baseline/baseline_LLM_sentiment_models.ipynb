{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modeling (LLM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setup\n",
    "(Only general setup, model specific imports are done within sections for the models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# General (modify where necessary)\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../../data/cleaned/Apple_Inc_text_data.csv')\n",
    "\n",
    "# format datetime again\n",
    "df['pub_date'] = pd.to_datetime(df['pub_date']) \n",
    "df['pub_date'] = df['pub_date'].dt.date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Copy of df for sentiment analysis, may not actually be necessary, copied from previous nb\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m sentiment_df\u001b[38;5;241m=\u001b[39mdf\u001b[38;5;241m.\u001b[39mcopy() \u001b[38;5;66;03m#save the df first \u001b[39;00m\n\u001b[0;32m      3\u001b[0m df\u001b[38;5;241m.\u001b[39minfo()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "# Copy of df for sentiment analysis, may not actually be necessary, copied from previous nb\n",
    "sentiment_df=df.copy() #save the df first \n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LLM: Gemini\n",
    "nerfed by api limit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install -U -q \"google-genai\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Necessary packages\n",
    "import os\n",
    "from google import genai\n",
    "# client = genai.Client(api_key='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>headline</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2114</th>\n",
       "      <td>The Tech That Needs Fixing in 2024, and What G...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2115</th>\n",
       "      <td>The True Price of Apple’s $3,500 Vision Pro Is...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2116</th>\n",
       "      <td>Why Making Face Computers Cool Isn’t Easy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2117</th>\n",
       "      <td>How to Cut Down Your Screen Time but Still Get...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2118</th>\n",
       "      <td>Apple to Offer Rare Discount on iPhones in China</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               headline\n",
       "2114  The Tech That Needs Fixing in 2024, and What G...\n",
       "2115  The True Price of Apple’s $3,500 Vision Pro Is...\n",
       "2116          Why Making Face Computers Cool Isn’t Easy\n",
       "2117  How to Cut Down Your Screen Time but Still Get...\n",
       "2118   Apple to Offer Rare Discount on iPhones in China"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = sentiment_df[['headline']].tail(10)\n",
    "test.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               headline gemini_sentiment\n",
      "2114  The Tech That Needs Fixing in 2024, and What G...          Neutral\n",
      "2115  The True Price of Apple’s $3,500 Vision Pro Is...         Negative\n",
      "2116          Why Making Face Computers Cool Isn’t Easy         Negative\n",
      "2117  How to Cut Down Your Screen Time but Still Get...          Neutral\n",
      "2118   Apple to Offer Rare Discount on iPhones in China          Neutral\n",
      "2119  Apple Takes a Humble Approach to Launching Its...          Neutral\n",
      "2120  Apple Overhauls App Store in Europe, in Respon...          Neutral\n",
      "2121  The Apple Vision Pro Is a Marvel. But Who Will...          Neutral\n",
      "2122  U.S. Moves Closer to Filing Sweeping Antitrust...         Negative\n",
      "2123                  Charms Can Personalize Your Watch          Neutral\n"
     ]
    }
   ],
   "source": [
    "import google.genai as genai\n",
    "import pandas as pd\n",
    "import time\n",
    "# Initialize the client\n",
    "# client = genai.Client()\n",
    "\n",
    "# Function to get sentiment based on model output\n",
    "def gemini_predict(prompt):\n",
    "    # Generate content from the model\n",
    "    response = client.models.generate_content(\n",
    "        model='gemini-2.0-flash', \n",
    "        contents=prompt\n",
    "    )\n",
    "    \n",
    "    # Assuming the model output is a sentiment label (e.g., Positive, Negative)\n",
    "    # You may need to adjust based on the actual format of the response\n",
    "    sentiment = response.text.strip()\n",
    "    \n",
    "    # Return the sentiment label, default to 'Neutral' if the model is uncertain\n",
    "    if sentiment not in ['Positive', 'Negative']:\n",
    "        sentiment = 'Neutral'\n",
    "    \n",
    "    return sentiment\n",
    "\n",
    "# Function to apply sentiment classification using the prompt for headlines\n",
    "def find_sentiment_zero_shot(text):\n",
    "    prompt = f\"\"\"Evaluate the sentiment conveyed by the headline with respect from an investment perspective. \n",
    "    Assign one of the following sentiment labels:\n",
    "    Positive: For headlines with positive implications.\n",
    "    Negative: For headlines with negative implications.\n",
    "    Neutral: For headlines with unclear or neutral implications.\n",
    "    \n",
    "    Headline: {text}\n",
    "    Sentiment: \"\"\"\n",
    "    \n",
    "    # Get sentiment from the model\n",
    "    sentiment = gemini_predict(prompt)\n",
    "    return sentiment\n",
    "\n",
    "def apply_with_delay(df, sentiment_column, delay=4):\n",
    "    sentiment_list = []\n",
    "    \n",
    "    for headline in df[sentiment_column]:\n",
    "        # Apply sentiment classification\n",
    "        sentiment = find_sentiment_zero_shot(headline)\n",
    "        sentiment_list.append(sentiment)\n",
    "        \n",
    "        # Delay to respect the RPM limit\n",
    "        time.sleep(delay)  # Delay in seconds (delay = 4 seconds to stay within 15 requests per minute)\n",
    "    \n",
    "    # Add the results to the dataframe\n",
    "    df['gemini_sentiment'] = sentiment_list\n",
    "    return df\n",
    "\n",
    "# Apply the function with delay to the sentiment DataFrame\n",
    "test_df = apply_with_delay(test, 'headline')\n",
    "\n",
    "# Display the results\n",
    "print(test_df[['headline', 'gemini_sentiment']])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2124 entries, 0 to 2123\n",
      "Data columns (total 9 columns):\n",
      " #   Column            Non-Null Count  Dtype \n",
      "---  ------            --------------  ----- \n",
      " 0   pub_date          2124 non-null   object\n",
      " 1   abstract          2124 non-null   object\n",
      " 2   lead_para         2124 non-null   object\n",
      " 3   headline          2124 non-null   object\n",
      " 4   doc_type          2124 non-null   object\n",
      " 5   section_name      2124 non-null   object\n",
      " 6   type_of_material  2124 non-null   object\n",
      " 7   rank              2124 non-null   int64 \n",
      " 8   web_url           2124 non-null   object\n",
      "dtypes: int64(1), object(8)\n",
      "memory usage: 149.5+ KB\n"
     ]
    }
   ],
   "source": [
    "sentiment_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LLM: Llama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Headline: The stock market surged today, hitting record highs due to strong earnings reports.\n",
      "Sentiment: POSITIVE\n",
      "Probability: 0.9\n"
     ]
    }
   ],
   "source": [
    "import asyncio\n",
    "from pydantic import BaseModel\n",
    "from ollama import AsyncClient\n",
    "\n",
    "# Define the schema for sentiment analysis result\n",
    "class SentimentInfo(BaseModel):\n",
    "    sentiment: str  # 'positive', 'neutral', or 'negative'\n",
    "    probability: float  # Probability score of the sentiment\n",
    "\n",
    "class SentimentResponse(BaseModel):\n",
    "    headline: str\n",
    "    sentiment_info: SentimentInfo\n",
    "\n",
    "async def main():\n",
    "    client = AsyncClient()\n",
    "\n",
    "    # Replace with the news headline you want to analyze\n",
    "    news_headline = \"The stock market surged today, hitting record highs due to strong earnings reports.\"\n",
    "\n",
    "    # Request sentiment analysis from the model\n",
    "    response = await client.chat(\n",
    "        model='llama3.1',\n",
    "        messages=[{'role': 'user', 'content': f'Analyze the sentiment of this news headline: \"{news_headline}\" and return it in JSON format.'}],\n",
    "        format=SentimentResponse.model_json_schema(),  # Use Pydantic to generate the schema for response\n",
    "        options={'temperature': 0},  # Make responses more deterministic\n",
    "    )\n",
    "\n",
    "    # Validate and parse the response\n",
    "    sentiment_response = SentimentResponse.model_validate_json(response.message.content)\n",
    "\n",
    "    # Print the sentiment analysis result\n",
    "    print(f\"Headline: {sentiment_response.headline}\")\n",
    "    print(f\"Sentiment: {sentiment_response.sentiment_info.sentiment}\")\n",
    "    print(f\"Probability: {sentiment_response.sentiment_info.probability}\")\n",
    "\n",
    "# Run the asynchronous function using asyncio in Jupyter\n",
    "await main()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Headline: The stock market surged today, hitting record highs due to strong earnings reports.\n",
      "Sentiment: positive\n",
      "Probability: 0.92\n"
     ]
    }
   ],
   "source": [
    "import asyncio\n",
    "from pydantic import BaseModel\n",
    "from ollama import AsyncClient\n",
    "\n",
    "# Define the schema for sentiment analysis result\n",
    "class SentimentInfo(BaseModel):\n",
    "    sentiment: str  # 'positive', 'neutral', or 'negative'\n",
    "    probability: float  # Probability score of the sentiment\n",
    "\n",
    "class SentimentResponse(BaseModel):\n",
    "    headline: str\n",
    "    sentiment_info: SentimentInfo\n",
    "\n",
    "async def main():\n",
    "    client = AsyncClient()\n",
    "\n",
    "    # Few-shot examples (Replace with real examples)\n",
    "    few_shot_examples = [\n",
    "        {\"headline\": \"The stock market surged today, hitting record highs due to strong earnings reports.\", \"sentiment\": \"positive\", \"probability\": 0.92},\n",
    "        {\"headline\": \"The economy faces significant downturns as inflation rates rise.\", \"sentiment\": \"negative\", \"probability\": 0.87},\n",
    "        {\"headline\": \"The new government policy has sparked mixed reactions, with some praising the changes while others remain skeptical.\", \"sentiment\": \"neutral\", \"probability\": 0.55},\n",
    "    ]\n",
    "\n",
    "    # Create a prompt that includes the few-shot examples\n",
    "    prompt = \"Analyze the sentiment of the following news headlines and return the sentiment label (positive, negative, or neutral) along with the probability score.\\n\\n\"\n",
    "    \n",
    "    # Add few-shot examples to the prompt\n",
    "    for example in few_shot_examples:\n",
    "        prompt += f\"Headline: {example['headline']}\\nSentiment: {example['sentiment']}\\nProbability: {example['probability']}\\n\\n\"\n",
    "    \n",
    "    # Now, ask for the sentiment of the actual news headline\n",
    "    news_headline = \"The stock market surged today, hitting record highs due to strong earnings reports.\"\n",
    "    prompt += f\"Headline: {news_headline}\\nSentiment:\"\n",
    "\n",
    "    # Request sentiment analysis from the model\n",
    "    response = await client.chat(\n",
    "        model='llama3.1',  # Replace with the appropriate model name if necessary\n",
    "        messages=[{'role': 'user', 'content': prompt}],\n",
    "        format=SentimentResponse.model_json_schema(),  # Use Pydantic to generate the schema for response\n",
    "        options={'temperature': 0},  # Make responses more deterministic\n",
    "    )\n",
    "\n",
    "    # Validate and parse the response\n",
    "    sentiment_response = SentimentResponse.model_validate_json(response.message.content)\n",
    "\n",
    "    # Print the sentiment analysis result\n",
    "    print(f\"Headline: {sentiment_response.headline}\")\n",
    "    print(f\"Sentiment: {sentiment_response.sentiment_info.sentiment}\")\n",
    "    print(f\"Probability: {sentiment_response.sentiment_info.probability}\")\n",
    "\n",
    "# Run the asynchronous function using asyncio in Jupyter\n",
    "await main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LLM: DeepSeek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO DO"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
